{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 89659,
          "databundleVersionId": 11735795,
          "sourceType": "competition"
        },
        {
          "sourceId": 224423433,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 230023475,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 230023480,
          "sourceType": "kernelVersion"
        },
        {
          "sourceId": 4527,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3319,
          "modelId": 971
        },
        {
          "sourceId": 263093,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 225001,
          "modelId": 164716
        },
        {
          "sourceId": 289299,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 247861,
          "modelId": 269379
        },
        {
          "sourceId": 289308,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 247869,
          "modelId": 269387
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "practice",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "ds6BNsMBNrvr"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "drawing_with_llms_path = kagglehub.competition_download('drawing-with-llms')\n",
        "metric_svg_constraints_path = kagglehub.package_import('metric/svg-constraints')\n",
        "packagemanager_pm_78722149_at_03_27_2025_14_04_14_path = kagglehub.notebook_output_download('packagemanager/pm-78722149-at-03-27-2025-14-04-14')\n",
        "jiazhuang_svg_image_fidelity_path = kagglehub.package_import('jiazhuang/svg-image-fidelity')\n",
        "stabilityai_stable_diffusion_v2_pytorch_1_1_path = kagglehub.model_download('stabilityai/stable-diffusion-v2/PyTorch/1/1')\n",
        "google_paligemma_2_transformers_paligemma2_10b_mix_448_1_path = kagglehub.model_download('google/paligemma-2/Transformers/paligemma2-10b-mix-448/1')\n",
        "jiazhuang_sac_logos_ava1_l14_linearmse_transformers_default_1_path = kagglehub.model_download('jiazhuang/sac-logos-ava1-l14-linearmse/Transformers/default/1')\n",
        "jiazhuang_clip_vit_large_patch14_transformers_default_1_path = kagglehub.model_download('jiazhuang/clip-vit-large-patch14/Transformers/default/1')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "v7a2MZPRNrvs"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion -> SVG\n",
        "\n",
        "add metric optimize: max(orc_score x aes_score)"
      ],
      "metadata": {
        "id": "Ij96_lshNrvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| default_exp core"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T06:04:44.290834Z",
          "iopub.execute_input": "2025-05-19T06:04:44.291099Z",
          "iopub.status.idle": "2025-05-19T06:04:44.294823Z",
          "shell.execute_reply.started": "2025-05-19T06:04:44.291078Z",
          "shell.execute_reply": "2025-05-19T06:04:44.293809Z"
        },
        "id": "DWCcCRw2Nrvt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T06:11:24.628948Z",
          "iopub.execute_input": "2025-05-19T06:11:24.629242Z",
          "iopub.status.idle": "2025-05-19T06:12:32.374141Z",
          "shell.execute_reply.started": "2025-05-19T06:11:24.629221Z",
          "shell.execute_reply": "2025-05-19T06:12:32.373254Z"
        },
        "id": "AdPKPMrENrvu",
        "outputId": "f3748614-80ca-4529-ef05-92cf2e0fc8d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.4)\n\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6e64de1810>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/bitsandbytes/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6e64de1b40>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/bitsandbytes/\u001b[0m\u001b[33m\n\u001b[0mCollecting bitsandbytes\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\n  Attempting uninstall: bitsandbytes\n    Found existing installation: bitsandbytes 0.45.4\n    Uninstalling bitsandbytes-0.45.4:\n      Successfully uninstalled bitsandbytes-0.45.4\nSuccessfully installed bitsandbytes-0.45.5\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "import os\n",
        "import io\n",
        "import re\n",
        "import random\n",
        "import base64\n",
        "from io import BytesIO\n",
        "\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from transformers import AutoProcessor, AutoModel\n",
        "\n",
        "metric = kagglehub.package_import('jiazhuang/svg-image-fidelity')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-19T06:15:40.683126Z",
          "iopub.execute_input": "2025-05-19T06:15:40.683453Z",
          "iopub.status.idle": "2025-05-19T06:15:40.864015Z",
          "shell.execute_reply.started": "2025-05-19T06:15:40.683426Z",
          "shell.execute_reply": "2025-05-19T06:15:40.863205Z"
        },
        "id": "7n9Y-h1SNrvv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Competition Metric Helpers"
      ],
      "metadata": {
        "id": "-UxaMfkLNrvv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also want to evaluate metrics of the original bitmap before converting to svg. Let’s implement it using [metric package](https://www.kaggle.com/code/jiazhuang/svg-image-fidelity)."
      ],
      "metadata": {
        "id": "c-jfbHboNrvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import statistics\n",
        "import pandas as pd\n",
        "\n",
        "def image_resize(image, size=(384, 384)):\n",
        "    return image.convert('RGB').resize(size)\n",
        "\n",
        "def bitmap_score_instance_impl(multiple_choice_qa, image, random_seed=42):\n",
        "    rng = np.random.RandomState(random_seed)\n",
        "    group_seed = rng.randint(0, np.iinfo(np.int32).max)\n",
        "    image_processor = metric.ImageProcessor(image=image_resize(image), seed=group_seed).apply()\n",
        "    image = image_processor.image.copy()\n",
        "    questions = multiple_choice_qa['question']\n",
        "    choices = multiple_choice_qa['choices']\n",
        "    answers = multiple_choice_qa['answer']\n",
        "    aesthetic_score = metric.aesthetic_evaluator.score(image)\n",
        "    vqa_score = metric.vqa_evaluator.score(questions, choices, answers, image)\n",
        "    image_processor.reset().apply_random_crop_resize().apply_jpeg_compression(quality=90)\n",
        "    ocr_score = metric.vqa_evaluator.ocr(image_processor.image)\n",
        "    instance_score = metric.harmonic_mean(vqa_score, aesthetic_score, beta=0.5) * ocr_score\n",
        "    return instance_score, vqa_score, ocr_score, aesthetic_score\n",
        "\n",
        "def bitmap_score_instance(multiple_choice_qa, image, random_seed=42):\n",
        "    is_single = not isinstance(image, list)\n",
        "    if is_single:\n",
        "        multiple_choice_qa = [multiple_choice_qa]\n",
        "        image = [image]\n",
        "\n",
        "    assert len(multiple_choice_qa) == len(image)\n",
        "\n",
        "    results = []\n",
        "    score_df = []\n",
        "    for one_image, one_multiple_choice_qa in zip(image, multiple_choice_qa, strict=True):\n",
        "        instance_score, vqa_score, ocr_score, aesthetic_score = bitmap_score_instance_impl(one_multiple_choice_qa, one_image, random_seed=42)\n",
        "        results.append(instance_score)\n",
        "        score_df.append([instance_score, vqa_score, ocr_score, aesthetic_score])\n",
        "\n",
        "    fidelity = statistics.mean(results)\n",
        "    score_df = pd.DataFrame(score_df, columns=['competition_score', 'vqa_score', 'ocr_score', 'aesthetic_score'])\n",
        "    if is_single:\n",
        "        return score_df.iloc[0].to_dict()\n",
        "    else:\n",
        "        return float(fidelity), score_df"
      ],
      "metadata": {
        "trusted": true,
        "id": "HcByPcYlNrvw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "import random\n",
        "import re\n",
        "from colorsys import rgb_to_hls, hls_to_rgb\n",
        "\n",
        "# Added from richolson/let-s-defeat-ocr-easy-lb-boost notebook\n",
        "def add_ocr_decoy_svg(svg_code: str) -> str:\n",
        "    \"\"\"\n",
        "    Adds nested circles with second darkest and second brightest colors from the existing SVG,\n",
        "    positioned in one of the four corners (randomly selected) but positioned to avoid being\n",
        "    cropped out during image processing.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    svg_code : str\n",
        "        The original SVG string\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        Modified SVG with the nested circles added\n",
        "    \"\"\"\n",
        "    modified_svg = svg_code\n",
        "    try:\n",
        "        # Check if SVG has a closing tag\n",
        "        if \"</svg>\" not in svg_code:\n",
        "            return svg_code\n",
        "\n",
        "        # Extract viewBox if it exists to understand the dimensions\n",
        "        viewbox_match = re.search(r'viewBox=[\"\\'](.*?)[\"\\']', svg_code)\n",
        "        if viewbox_match:\n",
        "            viewbox = viewbox_match.group(1).split()\n",
        "            try:\n",
        "                x, y, width, height = map(float, viewbox)\n",
        "            except ValueError:\n",
        "                # Default dimensions if we can't parse viewBox\n",
        "                width, height = 384, 384\n",
        "        else:\n",
        "            # Default dimensions if viewBox not found\n",
        "            width, height = 384, 384\n",
        "\n",
        "        # Function to convert hex color to RGB\n",
        "        def hex_to_rgb(hex_color):\n",
        "            hex_color = hex_color.lstrip('#')\n",
        "            if len(hex_color) == 3:\n",
        "                hex_color = ''.join([c*2 for c in hex_color])\n",
        "            return tuple(int(hex_color[i:i+2], 16)/255 for i in (0, 2, 4))\n",
        "\n",
        "        # Function to convert RGB to hex\n",
        "        def rgb_to_hex(rgb):\n",
        "            return '#{:02x}{:02x}{:02x}'.format(\n",
        "                int(rgb[0] * 255),\n",
        "                int(rgb[1] * 255),\n",
        "                int(rgb[2] * 255)\n",
        "            )\n",
        "\n",
        "        # Function to calculate color lightness\n",
        "        def get_lightness(color):\n",
        "            # Handle different color formats\n",
        "            if color.startswith('#'):\n",
        "                rgb = hex_to_rgb(color)\n",
        "                return rgb_to_hls(*rgb)[1]  # Lightness is the second value in HLS\n",
        "            elif color.startswith('rgb'):\n",
        "                rgb_match = re.search(r'rgb\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)', color)\n",
        "                if rgb_match:\n",
        "                    r, g, b = map(lambda x: int(x)/255, rgb_match.groups())\n",
        "                    return rgb_to_hls(r, g, b)[1]\n",
        "            return 0.5  # Default lightness if we can't parse\n",
        "\n",
        "        # Extract all colors from the SVG\n",
        "        color_matches = re.findall(r'(?:fill|stroke)=\"(#[0-9A-Fa-f]{3,6}|rgb\\(\\d+,\\s*\\d+,\\s*\\d+\\))\"', svg_code)\n",
        "\n",
        "        # Default colors in case we don't find enough\n",
        "        second_darkest_color = \"#333333\"  # Default to dark gray\n",
        "        second_brightest_color = \"#CCCCCC\"  # Default to light gray\n",
        "\n",
        "        if color_matches:\n",
        "            # Remove duplicates and get unique colors\n",
        "            unique_colors = list(set(color_matches))\n",
        "\n",
        "            # Calculate lightness for each unique color\n",
        "            colors_with_lightness = [(color, get_lightness(color)) for color in unique_colors]\n",
        "\n",
        "            # Sort by lightness (brightness)\n",
        "            sorted_colors = sorted(colors_with_lightness, key=lambda x: x[1])\n",
        "\n",
        "            # Handle different scenarios based on number of unique colors\n",
        "            if len(sorted_colors) >= 4:\n",
        "                # We have at least 4 unique colors - use 2nd darkest and 2nd brightest\n",
        "                second_darkest_color = sorted_colors[1][0]\n",
        "                second_brightest_color = sorted_colors[-2][0]\n",
        "            elif len(sorted_colors) == 3:\n",
        "                # We have 3 unique colors - use 2nd darkest and brightest\n",
        "                second_darkest_color = sorted_colors[1][0]\n",
        "                second_brightest_color = sorted_colors[2][0]\n",
        "            elif len(sorted_colors) == 2:\n",
        "                # We have only 2 unique colors - use the darkest and brightest\n",
        "                second_darkest_color = sorted_colors[0][0]\n",
        "                second_brightest_color = sorted_colors[1][0]\n",
        "            elif len(sorted_colors) == 1:\n",
        "                # Only one color - use it for second_darkest and a derived lighter version\n",
        "                base_color = sorted_colors[0][0]\n",
        "                base_lightness = sorted_colors[0][1]\n",
        "                second_darkest_color = base_color\n",
        "\n",
        "                # Create a lighter color variant if the base is dark, or darker if base is light\n",
        "                if base_lightness < 0.5:\n",
        "                    # Base is dark, create lighter variant\n",
        "                    second_brightest_color = \"#CCCCCC\"\n",
        "                else:\n",
        "                    # Base is light, create darker variant\n",
        "                    second_darkest_color = \"#333333\"\n",
        "\n",
        "        # Ensure the colors are different\n",
        "        if second_darkest_color == second_brightest_color:\n",
        "            # If they ended up the same, modify one of them\n",
        "            if get_lightness(second_darkest_color) < 0.5:\n",
        "                # It's a dark color, make the bright one lighter\n",
        "                second_brightest_color = \"#CCCCCC\"\n",
        "            else:\n",
        "                # It's a light color, make the dark one darker\n",
        "                second_darkest_color = \"#333333\"\n",
        "\n",
        "        # Base size for the outer circle\n",
        "        base_outer_radius = width * 0.023\n",
        "\n",
        "        # Randomize size by ±10%\n",
        "        size_variation = base_outer_radius * 0.1\n",
        "        outer_radius = base_outer_radius + random.uniform(-size_variation, size_variation)\n",
        "\n",
        "        # Define radii for inner circles based on outer radius\n",
        "        middle_radius = outer_radius * 0.80\n",
        "        inner_radius = middle_radius * 0.65\n",
        "\n",
        "        # Calculate the maximum crop margin based on the image processing (5% of dimensions)\n",
        "        # Add 20% extra margin for safety\n",
        "        crop_margin_w = int(width * 0.05 * 1.2)\n",
        "        crop_margin_h = int(height * 0.05 * 1.2)\n",
        "\n",
        "        # Calculate center point based on the outer radius to ensure the entire circle stays visible\n",
        "        safe_offset = outer_radius + max(crop_margin_w, crop_margin_h)\n",
        "\n",
        "        # Choose a random corner (0: top-left, 1: top-right, 2: bottom-left, 3: bottom-right)\n",
        "        corner = random.randint(0, 3)\n",
        "\n",
        "        # Position the circle in the chosen corner, accounting for crop margin\n",
        "        if corner == 0:  # Top-left\n",
        "            center_x = safe_offset\n",
        "            center_y = safe_offset\n",
        "        elif corner == 1:  # Top-right\n",
        "            center_x = width - safe_offset\n",
        "            center_y = safe_offset\n",
        "        elif corner == 2:  # Bottom-left\n",
        "            center_x = safe_offset\n",
        "            center_y = height - safe_offset\n",
        "        else:  # Bottom-right\n",
        "            center_x = width - safe_offset\n",
        "            center_y = height - safe_offset\n",
        "\n",
        "        # Add a small random offset (±10% of safe_offset) to make positioning less predictable\n",
        "        random_offset = safe_offset * 0.1\n",
        "        center_x += random.uniform(-random_offset, random_offset)\n",
        "        center_y += random.uniform(-random_offset, random_offset)\n",
        "\n",
        "        # Round to 1 decimal place to keep file size down\n",
        "        outer_radius = round(outer_radius, 1)\n",
        "        middle_radius = round(middle_radius, 1)\n",
        "        inner_radius = round(inner_radius, 1)\n",
        "        center_x = round(center_x, 1)\n",
        "        center_y = round(center_y, 1)\n",
        "\n",
        "        # Create the nested circles\n",
        "        outer_circle = f'<circle cx=\"{center_x}\" cy=\"{center_y}\" r=\"{outer_radius}\" fill=\"{second_darkest_color}\" />'\n",
        "        middle_circle = f'<circle cx=\"{center_x}\" cy=\"{center_y}\" r=\"{middle_radius}\" fill=\"{second_brightest_color}\" />'\n",
        "        inner_circle = f'<circle cx=\"{center_x}\" cy=\"{center_y}\" r=\"{inner_radius}\" fill=\"{second_darkest_color}\" />'\n",
        "\n",
        "        # Create a group element that contains all three circles\n",
        "        group_element = f'<g>{outer_circle}{middle_circle}{inner_circle}</g>'\n",
        "\n",
        "        # Insert the group element just before the closing SVG tag\n",
        "        modified_svg = svg_code.replace(\"</svg>\", f\"{group_element}</svg>\")\n",
        "\n",
        "        # Calculate and add a comment with the byte size information\n",
        "        outer_bytes = len(outer_circle.encode('utf-8'))\n",
        "        middle_bytes = len(middle_circle.encode('utf-8'))\n",
        "        inner_bytes = len(inner_circle.encode('utf-8'))\n",
        "        total_bytes = outer_bytes + middle_bytes + inner_bytes\n",
        "\n",
        "        corner_names = [\"top-left\", \"top-right\", \"bottom-left\", \"bottom-right\"]\n",
        "        byte_info = f'<!-- Circle bytes: outer={outer_bytes}, middle={middle_bytes}, ' \\\n",
        "                    f'inner={inner_bytes}, total={total_bytes}, ' \\\n",
        "                    f'colors: dark={second_darkest_color}, light={second_brightest_color}, ' \\\n",
        "                    f'position: {corner_names[corner]} -->'\n",
        "\n",
        "        modified_svg = modified_svg.replace(\"</svg>\", f\"{byte_info}</svg>\")\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    return modified_svg"
      ],
      "metadata": {
        "trusted": true,
        "id": "fwWg2r5PNrvx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Stable Diffusion"
      ],
      "metadata": {
        "id": "CfjAlUm5Nrvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "# Ensure GPU is being used and optimize for speed\n",
        "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "\n",
        "# Load with optimized scheduler and half precision\n",
        "stable_diffusion_path = kagglehub.model_download(\"stabilityai/stable-diffusion-v2/pytorch/1/1\")\n",
        "\n",
        "scheduler = DDIMScheduler.from_pretrained(stable_diffusion_path, subfolder=\"scheduler\")\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    stable_diffusion_path,\n",
        "    scheduler=scheduler,\n",
        "    torch_dtype=torch.float16,  # Use half precision\n",
        "    safety_checker=None         # Disable safety checker for speed\n",
        ")\n",
        "\n",
        "# Move to GPU and apply optimizations\n",
        "pipe.to(device)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "F6N1OwjONrvy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "5lvCOEOPNrvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "trusted": true,
        "id": "izrlHVk2Nrvy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "drawing_with_llms_path = kagglehub.competition_download('drawing-with-llms')\n",
        "train_df = pd.read_csv(f'{drawing_with_llms_path}/train.csv')\n",
        "train_question_df = pd.read_parquet(f'{drawing_with_llms_path}/questions.parquet')"
      ],
      "metadata": {
        "trusted": true,
        "id": "QQG5HBQnNrvy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_question_df = train_question_df.groupby('id').apply(lambda df: df.to_dict(orient='list'))\n",
        "train_question_df = train_question_df.reset_index(name='qa')\n",
        "\n",
        "train_question_df['question'] = train_question_df.qa.apply(lambda qa: json.dumps(qa['question'], ensure_ascii=False))\n",
        "\n",
        "train_question_df['choices'] = train_question_df.qa.apply(\n",
        "    lambda qa: json.dumps(\n",
        "        [x.tolist() for x in qa['choices']], ensure_ascii=False\n",
        "    )\n",
        ")\n",
        "\n",
        "train_question_df['answer'] = train_question_df.qa.apply(lambda qa: json.dumps(qa['answer'], ensure_ascii=False))\n",
        "\n",
        "train_df = pd.merge(train_df, train_question_df, how='left', on='id')\n",
        "\n",
        "train_df['multiple_choice_qa'] = train_df.apply(\n",
        "    lambda r: {\n",
        "    'question': json.loads(r.question),\n",
        "    'choices': json.loads(r.choices),\n",
        "    'answer': json.loads(r.answer)\n",
        "    },\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ZclOIH-gNrvz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bitmap Generation\n",
        "* Inference steps (more for better quality / slower)\n",
        "* Guidance scale (how tightly to follow prompts)"
      ],
      "metadata": {
        "id": "NzqvOqKnNrvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "def generate_bitmap(prompt, negative_prompt=\"\", num_inference_steps=20, guidance_scale=15):\n",
        "\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "    ).images[0]\n",
        "\n",
        "    return image"
      ],
      "metadata": {
        "trusted": true,
        "id": "qhPjwNFGNrvz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_prefix = \"Simple, classic image of\"\n",
        "prompt_suffix = \"with flat color blocks, beautiful, minimal details, solid colors only\"\n",
        "negative_prompt = \"lines, framing, hatching, background, textures, patterns, details, outlines\""
      ],
      "metadata": {
        "trusted": true,
        "id": "ZmXAeGL5Nrvz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "r = train_df.iloc[2]\n",
        "description = r.description\n",
        "print(description)"
      ],
      "metadata": {
        "trusted": true,
        "id": "-0Zoc6eeNrvz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f'{prompt_prefix} {description} {prompt_suffix}'\n",
        "print(prompt)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ip0_EC2INrvz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "image = generate_bitmap(prompt, negative_prompt=negative_prompt)\n",
        "image"
      ],
      "metadata": {
        "trusted": true,
        "id": "L9p3www7Nrvz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "bitmap_score_instance(r.multiple_choice_qa, image, random_seed=42)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q6B_1LFrNrv0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image -> SVG\n",
        "\n",
        "* Did a bunch of work here trying to get good results.."
      ],
      "metadata": {
        "id": "tKNDux3-Nrv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "def compress_hex_color(hex_color):\n",
        "    \"\"\"Convert hex color to shortest possible representation\"\"\"\n",
        "    r, g, b = int(hex_color[1:3], 16), int(hex_color[3:5], 16), int(hex_color[5:7], 16)\n",
        "    if r % 17 == 0 and g % 17 == 0 and b % 17 == 0:\n",
        "        return f'#{r//17:x}{g//17:x}{b//17:x}'\n",
        "    return hex_color\n",
        "\n",
        "def extract_features_by_scale(img_np, num_colors=16):\n",
        "    \"\"\"\n",
        "    Extract image features hierarchically by scale\n",
        "\n",
        "    Args:\n",
        "        img_np (np.ndarray): Input image\n",
        "        num_colors (int): Number of colors to quantize\n",
        "\n",
        "    Returns:\n",
        "        list: Hierarchical features sorted by importance\n",
        "    \"\"\"\n",
        "    # Convert to RGB if needed\n",
        "    if len(img_np.shape) == 3 and img_np.shape[2] > 1:\n",
        "        img_rgb = img_np\n",
        "    else:\n",
        "        img_rgb = cv2.cvtColor(img_np, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Convert to grayscale for processing\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    height, width = gray.shape\n",
        "\n",
        "    # Perform color quantization\n",
        "    pixels = img_rgb.reshape(-1, 3).astype(np.float32)\n",
        "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "    _, labels, centers = cv2.kmeans(pixels, num_colors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "    # Quantized image\n",
        "    palette = centers.astype(np.uint8)\n",
        "    quantized = palette[labels.flatten()].reshape(img_rgb.shape)\n",
        "\n",
        "    # Hierarchical feature extraction\n",
        "    hierarchical_features = []\n",
        "\n",
        "    # Sort colors by frequency\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    sorted_indices = np.argsort(-counts)\n",
        "    sorted_colors = [palette[i] for i in sorted_indices]\n",
        "\n",
        "    # Center point for importance calculations\n",
        "    center_x, center_y = width/2, height/2\n",
        "\n",
        "    for color in sorted_colors:\n",
        "        # Create color mask\n",
        "        color_mask = cv2.inRange(quantized, color, color)\n",
        "\n",
        "        # Find contours\n",
        "        contours, _ = cv2.findContours(color_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        # Sort contours by area (largest first)\n",
        "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
        "\n",
        "        # Convert RGB to compressed hex\n",
        "        hex_color = compress_hex_color(f'#{color[0]:02x}{color[1]:02x}{color[2]:02x}')\n",
        "\n",
        "        color_features = []\n",
        "        for contour in contours:\n",
        "            # Skip tiny contours\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area < 20:\n",
        "                continue\n",
        "\n",
        "            # Calculate contour center\n",
        "            m = cv2.moments(contour)\n",
        "            if m[\"m00\"] == 0:\n",
        "                continue\n",
        "\n",
        "            cx = int(m[\"m10\"] / m[\"m00\"])\n",
        "            cy = int(m[\"m01\"] / m[\"m00\"])\n",
        "\n",
        "            # Distance from image center (normalized)\n",
        "            dist_from_center = np.sqrt(((cx - center_x) / width)**2 + ((cy - center_y) / height)**2)\n",
        "\n",
        "            # Simplify contour\n",
        "            epsilon = 0.02 * cv2.arcLength(contour, True)\n",
        "            approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            # Generate points string\n",
        "            points = \" \".join([f\"{pt[0][0]:.1f},{pt[0][1]:.1f}\" for pt in approx])\n",
        "\n",
        "            # Calculate importance (area, proximity to center, complexity)\n",
        "            importance = (\n",
        "                area *\n",
        "                (1 - dist_from_center) *\n",
        "                (1 / (len(approx) + 1))\n",
        "            )\n",
        "\n",
        "            color_features.append({\n",
        "                'points': points,\n",
        "                'color': hex_color,\n",
        "                'area': area,\n",
        "                'importance': importance,\n",
        "                'point_count': len(approx),\n",
        "                'original_contour': approx  # Store original contour for adaptive simplification\n",
        "            })\n",
        "\n",
        "        # Sort features by importance within this color\n",
        "        color_features.sort(key=lambda x: x['importance'], reverse=True)\n",
        "        hierarchical_features.extend(color_features)\n",
        "\n",
        "    # Final sorting by overall importance\n",
        "    hierarchical_features.sort(key=lambda x: x['importance'], reverse=True)\n",
        "\n",
        "    return hierarchical_features\n",
        "\n",
        "def simplify_polygon(points_str, simplification_level):\n",
        "    \"\"\"\n",
        "    Simplify a polygon by reducing coordinate precision or number of points\n",
        "\n",
        "    Args:\n",
        "        points_str (str): Space-separated \"x,y\" coordinates\n",
        "        simplification_level (int): Level of simplification (0-3)\n",
        "\n",
        "    Returns:\n",
        "        str: Simplified points string\n",
        "    \"\"\"\n",
        "    if simplification_level == 0:\n",
        "        return points_str\n",
        "\n",
        "    points = points_str.split()\n",
        "\n",
        "    # Level 1: Round to 1 decimal place\n",
        "    if simplification_level == 1:\n",
        "        return \" \".join([f\"{float(p.split(',')[0]):.1f},{float(p.split(',')[1]):.1f}\" for p in points])\n",
        "\n",
        "    # Level 2: Round to integer\n",
        "    if simplification_level == 2:\n",
        "        return \" \".join([f\"{float(p.split(',')[0]):.0f},{float(p.split(',')[1]):.0f}\" for p in points])\n",
        "\n",
        "    # Level 3: Reduce number of points (keep every other point, but ensure at least 3 points)\n",
        "    if simplification_level == 3:\n",
        "        if len(points) <= 4:\n",
        "            # If 4 or fewer points, just round to integer\n",
        "            return \" \".join([f\"{float(p.split(',')[0]):.0f},{float(p.split(',')[1]):.0f}\" for p in points])\n",
        "        else:\n",
        "            # Keep approximately half the points, but maintain at least 3\n",
        "            step = min(2, len(points) // 3)\n",
        "            reduced_points = [points[i] for i in range(0, len(points), step)]\n",
        "            # Ensure we keep at least 3 points and the last point\n",
        "            if len(reduced_points) < 3:\n",
        "                reduced_points = points[:3]\n",
        "            if points[-1] not in reduced_points:\n",
        "                reduced_points.append(points[-1])\n",
        "            return \" \".join([f\"{float(p.split(',')[0]):.0f},{float(p.split(',')[1]):.0f}\" for p in reduced_points])\n",
        "\n",
        "    return points_str\n",
        "\n",
        "def bitmap_to_svg_layered(image, max_size_bytes=10000, resize=True, target_size=(384, 384),\n",
        "                         adaptive_fill=True, num_colors=None):\n",
        "    \"\"\"\n",
        "    Convert bitmap to SVG using layered feature extraction with optimized space usage\n",
        "\n",
        "    Args:\n",
        "        image: Input image (PIL.Image)\n",
        "        max_size_bytes (int): Maximum SVG size\n",
        "        resize (bool): Whether to resize the image before processing\n",
        "        target_size (tuple): Target size for resizing (width, height)\n",
        "        adaptive_fill (bool): Whether to adaptively fill available space\n",
        "        num_colors (int): Number of colors to quantize, if None uses adaptive selection\n",
        "\n",
        "    Returns:\n",
        "        str: SVG representation\n",
        "    \"\"\"\n",
        "    # Adaptive color selection based on image complexity\n",
        "    if num_colors is None:\n",
        "        # Simple heuristic: more colors for complex images\n",
        "        if resize:\n",
        "            pixel_count = target_size[0] * target_size[1]\n",
        "        else:\n",
        "            pixel_count = image.size[0] * image.size[1]\n",
        "\n",
        "        if pixel_count < 65536:  # 256x256\n",
        "            num_colors = 8\n",
        "        elif pixel_count < 262144:  # 512x512\n",
        "            num_colors = 12\n",
        "        else:\n",
        "            num_colors = 16\n",
        "\n",
        "    # Resize the image if requested\n",
        "    if resize:\n",
        "        original_size = image.size\n",
        "        image = image.resize(target_size, Image.LANCZOS)\n",
        "    else:\n",
        "        original_size = image.size\n",
        "\n",
        "    # Convert to numpy array\n",
        "    img_np = np.array(image)\n",
        "\n",
        "    # Get image dimensions\n",
        "    height, width = img_np.shape[:2]\n",
        "\n",
        "    # Calculate average background color\n",
        "    if len(img_np.shape) == 3 and img_np.shape[2] == 3:\n",
        "        avg_bg_color = np.mean(img_np, axis=(0,1)).astype(int)\n",
        "        bg_hex_color = compress_hex_color(f'#{avg_bg_color[0]:02x}{avg_bg_color[1]:02x}{avg_bg_color[2]:02x}')\n",
        "    else:\n",
        "        bg_hex_color = '#fff'\n",
        "\n",
        "    # Start building SVG\n",
        "    # Use original dimensions in viewBox for proper scaling when displayed\n",
        "    orig_width, orig_height = original_size\n",
        "    svg_header = f'<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"{orig_width}\" height=\"{orig_height}\" viewBox=\"0 0 {width} {height}\">\\n'\n",
        "    svg_bg = f'<rect width=\"{width}\" height=\"{height}\" fill=\"{bg_hex_color}\"/>\\n'\n",
        "    svg_base = svg_header + svg_bg\n",
        "    svg_footer = '</svg>'\n",
        "\n",
        "    # Calculate base size\n",
        "    base_size = len((svg_base + svg_footer).encode('utf-8'))\n",
        "    available_bytes = max_size_bytes - base_size\n",
        "\n",
        "    # Extract hierarchical features\n",
        "    features = extract_features_by_scale(img_np, num_colors=num_colors)\n",
        "\n",
        "    # If not using adaptive fill, just add features until we hit the limit\n",
        "    if not adaptive_fill:\n",
        "        svg = svg_base\n",
        "        for feature in features:\n",
        "            # Try adding the feature\n",
        "            feature_svg = f'<polygon points=\"{feature[\"points\"]}\" fill=\"{feature[\"color\"]}\" />\\n'\n",
        "\n",
        "            # Check if adding this feature exceeds size limit\n",
        "            if len((svg + feature_svg + svg_footer).encode('utf-8')) > max_size_bytes:\n",
        "                break\n",
        "\n",
        "            # Add the feature\n",
        "            svg += feature_svg\n",
        "\n",
        "        # Close SVG\n",
        "        svg += svg_footer\n",
        "        return svg\n",
        "\n",
        "    # For adaptive fill, use binary search to find optimal simplification level\n",
        "\n",
        "    # First attempt: calculate size of all features at different simplification levels\n",
        "    feature_sizes = []\n",
        "    for feature in features:\n",
        "        feature_sizes.append({\n",
        "            'original': len(f'<polygon points=\"{feature[\"points\"]}\" fill=\"{feature[\"color\"]}\" />\\n'.encode('utf-8')),\n",
        "            'level1': len(f'<polygon points=\"{simplify_polygon(feature[\"points\"], 1)}\" fill=\"{feature[\"color\"]}\" />\\n'.encode('utf-8')),\n",
        "            'level2': len(f'<polygon points=\"{simplify_polygon(feature[\"points\"], 2)}\" fill=\"{feature[\"color\"]}\" />\\n'.encode('utf-8')),\n",
        "            'level3': len(f'<polygon points=\"{simplify_polygon(feature[\"points\"], 3)}\" fill=\"{feature[\"color\"]}\" />\\n'.encode('utf-8'))\n",
        "        })\n",
        "\n",
        "    # Two-pass approach: first add most important features, then fill remaining space\n",
        "    svg = svg_base\n",
        "    bytes_used = base_size\n",
        "    added_features = set()\n",
        "\n",
        "    # Pass 1: Add most important features at original quality\n",
        "    for i, feature in enumerate(features):\n",
        "        feature_svg = f'<polygon points=\"{feature[\"points\"]}\" fill=\"{feature[\"color\"]}\" />\\n'\n",
        "        feature_size = feature_sizes[i]['original']\n",
        "\n",
        "        if bytes_used + feature_size <= max_size_bytes:\n",
        "            svg += feature_svg\n",
        "            bytes_used += feature_size\n",
        "            added_features.add(i)\n",
        "\n",
        "    # Pass 2: Try to add remaining features with progressive simplification\n",
        "    for level in range(1, 4):  # Try simplification levels 1-3\n",
        "        for i, feature in enumerate(features):\n",
        "            if i in added_features:\n",
        "                continue\n",
        "\n",
        "            feature_size = feature_sizes[i][f'level{level}']\n",
        "            if bytes_used + feature_size <= max_size_bytes:\n",
        "                feature_svg = f'<polygon points=\"{simplify_polygon(feature[\"points\"], level)}\" fill=\"{feature[\"color\"]}\" />\\n'\n",
        "                svg += feature_svg\n",
        "                bytes_used += feature_size\n",
        "                added_features.add(i)\n",
        "\n",
        "    # Finalize SVG\n",
        "    svg += svg_footer\n",
        "\n",
        "    # Double check we didn't exceed limit\n",
        "    final_size = len(svg.encode('utf-8'))\n",
        "    if final_size > max_size_bytes:\n",
        "        # If we somehow went over, return basic SVG\n",
        "        return f'<svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 {width} {height}\"><rect width=\"{width}\" height=\"{height}\" fill=\"{bg_hex_color}\"/></svg>'\n",
        "\n",
        "    # Calculate space utilization\n",
        "    utilization = (final_size / max_size_bytes) * 100\n",
        "\n",
        "    # Return the SVG with efficient space utilization\n",
        "    return svg"
      ],
      "metadata": {
        "trusted": true,
        "id": "or83NvbnNrv0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG"
      ],
      "metadata": {
        "trusted": true,
        "id": "r4sGx1plNrv0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "svg_content = bitmap_to_svg_layered(image)\n",
        "SVG(svg_content)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FQnufpqeNrv0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "metric.score_instance(r.multiple_choice_qa, svg_content, random_seed=42)"
      ],
      "metadata": {
        "trusted": true,
        "id": "wDAhTk9bNrv0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "def get_vqa_aes_and_ocr_score(svg_content, questions_template, prompt):\n",
        "    svg_to_png_converted = metric.svg_to_png(svg_content)\n",
        "    image_processor = metric.ImageProcessor(image=svg_to_png_converted, seed=33).apply()\n",
        "    image = image_processor.image.copy()\n",
        "\n",
        "    p_fidelity = metric.vqa_evaluator.score_yes_no(questions_template['fidelity'].format(prompt), image)\n",
        "    vqa_score = p_fidelity\n",
        "\n",
        "    # aesthetic_score = metric.aesthetic_evaluator.score(image)\n",
        "    aesthetic_score = 1\n",
        "    image_processor.reset().apply_random_crop_resize().apply_jpeg_compression(quality=90)\n",
        "    ocr_score = metric.vqa_evaluator.ocr(image_processor.image)\n",
        "\n",
        "    return vqa_score, aesthetic_score, ocr_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "BQOKLbIJNrv1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement the package Model class"
      ],
      "metadata": {
        "id": "S1r_ZxTgNrv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#| export\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.default_svg = \"\"\"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\" /></svg>\"\"\"\n",
        "        self.prompt_prefix = \"Simple, classic image of\"\n",
        "        self.prompt_suffix = \"with flat color blocks, beautiful, minimal details, solid colors only\"\n",
        "        # self.negative_prompt = \"lines, framing, hatching, background, textures, patterns, details, outlines\"\n",
        "\n",
        "        self.prompt_templates = [\n",
        "            \"Stylized representation of {description} using clean shapes and no background elements\",\n",
        "            \"Simple, classic image of {description} with flat colors, beautiful, minimal details\",\n",
        "            \"Simple, classic, aesthetic representation of {description} using clean shapes and no background elements\"\n",
        "        ]\n",
        "        self.negative_prompt = \"framing, hatching, background, details\"\n",
        "        self.questions_template = {\n",
        "                'fidelity': 'Does <image> portray \"SVG illustration of {}\"? Answer yes or no.'\n",
        "        }\n",
        "        self.num_inference_steps = 25\n",
        "        self.guidance_scale = 20\n",
        "        self.num_attempt = 3\n",
        "\n",
        "    def gen_bitmap(self, prompt):\n",
        "        # prompt = f'{self.prompt_prefix} {description} {self.prompt_suffix}'\n",
        "        bitmap = generate_bitmap(prompt, self.negative_prompt, self.num_inference_steps, self.guidance_scale)\n",
        "        return bitmap\n",
        "\n",
        "    def predict_impl(self, description: str) -> str:\n",
        "        best_score = 0.0\n",
        "        best_svg = None\n",
        "        best_img = None\n",
        "\n",
        "        for i in range(self.num_attempt):\n",
        "            prompt_template = self.prompt_templates[i]\n",
        "            prompt = prompt_template.format(description=description)\n",
        "            bitmap = self.gen_bitmap(prompt)\n",
        "            svg = bitmap_to_svg_layered(bitmap, max_size_bytes=9650)\n",
        "            svg = add_ocr_decoy_svg(svg)\n",
        "            vqa_score, aesthetic_score, ocr_score = get_vqa_aes_and_ocr_score(svg, self.questions_template, description)\n",
        "            score = vqa_score * ocr_score\n",
        "            # score = metric.harmonic_mean(vqa_score, aesthetic_score, beta=0.5) * ocr_score\n",
        "\n",
        "            if score >= best_score:\n",
        "                best_score = score\n",
        "                best_svg = svg\n",
        "                best_img = bitmap\n",
        "                print('update score:', best_score)\n",
        "\n",
        "        if best_svg is None:\n",
        "            best_svg = self.default_svg\n",
        "\n",
        "        return best_svg, best_img\n",
        "\n",
        "    def predict(self, prompt: str) -> str:\n",
        "        svg, img = self.predict_impl(prompt)\n",
        "        return svg"
      ],
      "metadata": {
        "trusted": true,
        "id": "wiK4okaqNrv1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ljJyYF_jNrv1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "svg = model.predict(description)\n",
        "SVG(svg)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bpYYP0DYNrv1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metric.score_instance(r.multiple_choice_qa, svg, random_seed=42)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_P2X4a68Nrv1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate on train dataset (LB prediction!)"
      ],
      "metadata": {
        "id": "sb5WAu5aNrv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "trusted": true,
        "id": "vAAzbQXlNrv2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Jtn4wrdpNrv2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df = train_df[:3]"
      ],
      "metadata": {
        "trusted": true,
        "id": "OQESIhkBNrv2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "id": "6NtXQem2Nrv2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_df['raw_res'] = train_df.description.progress_apply(model.predict_impl)"
      ],
      "metadata": {
        "trusted": true,
        "id": "rOs3qqwiNrv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['svg'] = train_df.raw_res.apply(lambda x: x[0])\n",
        "train_df['bitmap'] = train_df.raw_res.apply(lambda x: x[1])"
      ],
      "metadata": {
        "trusted": true,
        "id": "pwN-J84uNrv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['bitmap_score'] = train_df.progress_apply(\n",
        "    lambda r: bitmap_score_instance(r.multiple_choice_qa, r.bitmap, random_seed=42),\n",
        "    axis=1,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "9X1PY1LsNrv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['svg_score'] = train_df.progress_apply(\n",
        "    lambda r: metric.score_instance(r.multiple_choice_qa, r.svg, random_seed=42),\n",
        "    axis=1,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "IL5sP3x5Nrv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for r in train_df.itertuples():\n",
        "    b_score = r.bitmap_score['competition_score']\n",
        "    b_vqa = r.bitmap_score['vqa_score']\n",
        "    b_ocr = r.bitmap_score['ocr_score']\n",
        "    b_aesthetic = r.bitmap_score['aesthetic_score']\n",
        "\n",
        "    s_score = r.svg_score['competition_score']\n",
        "    s_vqa = r.svg_score['vqa_score']\n",
        "    s_ocr = r.svg_score['ocr_score']\n",
        "    s_aesthetic = r.svg_score['aesthetic_score']\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.suptitle(r.description, y=0.93)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(np.array(r.bitmap))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'bitmap: score={b_score:.2f}, vqa={b_vqa:.2f}, ocr={b_ocr:.2f}, aes={b_aesthetic:.2f}')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(metric.svg_to_png(r.svg))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'svg: score={s_score:.2f}, vqa={s_vqa:.2f}, ocr={s_ocr:.2f}, aes={s_aesthetic:.2f}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "Wc9bQiN6Nrv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mean_bitmap_score = pd.DataFrame(train_df['bitmap_score'].tolist()).mean(axis=0)\n",
        "mean_bitmap_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "kdz0c8aTNrv6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "mean_svg_score = pd.DataFrame(train_df['svg_score'].tolist()).mean(axis=0)\n",
        "mean_svg_score"
      ],
      "metadata": {
        "trusted": true,
        "id": "R6TGe6qbNrv7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Original bitmap score: {mean_bitmap_score.competition_score}')\n",
        "print(f'Final svg score: {mean_svg_score.competition_score}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "8DYgZkUZNrv7"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "pUVjNiR4Nrv7"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}