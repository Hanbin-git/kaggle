{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1bxmOMmVytUxLmHZUR3dzl95CPxgxnmxd",
      "authorship_tag": "ABX9TyMhcBbRwb0bO7XQyIGnn9Yw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/%EC%A0%84%EC%B2%98%EB%A6%AC_%EB%B0%8F_%ED%95%99%EC%8A%B502.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# 1. Driveì—ì„œ ë¡œì»¬ë¡œ ë³µì‚¬ (ë¹ ë¦„)\n",
        "shutil.copy(\"/content/drive/MyDrive/open.zip\", \"/content/open.zip\")\n",
        "\n",
        "# 2. ì••ì¶• í’€ê¸°\n",
        "with zipfile.ZipFile(\"/content/open.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# 3. í™•ì¸\n",
        "!ls /content/train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvI7mVJCKMb7",
        "outputId": "5ec3e7a7-2330-495e-a61c-144d2e6e8437"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì»¨í‹°ë„¨íƒˆ_10ì„¸ëŒ€_2017_2019\t     A_í´ë˜ìŠ¤_W177_2020_2025\n",
            "ì–´ì½”ë“œ_10ì„¸ëŒ€_2018_2022\t\t     B_í´ë˜ìŠ¤_W246_2013_2018\n",
            "1ì‹œë¦¬ì¦ˆ_F20_2013_2015\t\t     ë‰´_ìŠ¤íƒ€ì¼_ì½”ë€ë„_C_2017_2019\n",
            "1ì‹œë¦¬ì¦ˆ_F20_2016_2019\t\t     í”„ë¦¬ìš°ìŠ¤_C_2018_2020\n",
            "1ì‹œë¦¬ì¦ˆ_F40_2020_2024\t\t     ë‰´_CC_2012_2016\n",
            "ê·¸ëœë“œì¹´ë‹ˆë°œ_2006_2010\t\t     CLA_í´ë˜ìŠ¤_C117_2014_2019\n",
            "2008_2015_2017\t\t\t     CLA_í´ë˜ìŠ¤_C118_2020_2025\n",
            "ì—ì¿ ìŠ¤_ì‹ í˜•_2010_2015\t\t     CLE_í´ë˜ìŠ¤_C236_2024_2025\n",
            "íŒŒë‚˜ë©”ë¼_2010_2016\t\t     CLS_í´ë˜ìŠ¤_C257_2019_2023\n",
            "ë‰´_ì œíƒ€_2011_2016\t\t     CLS_í´ë˜ìŠ¤_W218_2012_2017\n",
            "ë‰´_ì¹´ì´ì—”_2011_2018\t\t     ì•„ë°˜ë–¼_í•˜ì´ë¸Œë¦¬ë“œ_CN7_2021_2023\n",
            "ì—‘ì„¼íŠ¸_ì‹ í˜•_2011_2019\t\t     ì•„ë°˜ë–¼_CN7_2021_2023\n",
            "ìŠ¤íŒŒí¬_2012_2015\t\t     ë”_ë‰´_ì•„ë°˜ë–¼_CN7_2023_2025\n",
            "ì¿ í¼_ì»¨íŠ¸ë¦¬ë§¨_2012_2015\t\t     CT6_2016_2018\n",
            "ì˜¬_ë‰´_ëª¨ë‹_2012_2015\t\t     C_í´ë˜ìŠ¤_W204_2008_2015\n",
            "ì•„ë² ì˜¤_2012_2016\t\t     C_í´ë˜ìŠ¤_W205_2015_2021\n",
            "ë§ë¦¬ë¶€_2012_2016\t\t     C_í´ë˜ìŠ¤_W206_2022_2024\n",
            "ë‰´_í‹°êµ¬ì•ˆ_2012_2016\t\t     ì œë„¤ì‹œìŠ¤_DH_2014_2016\n",
            "ë ˆì´_2012_2017\t\t\t     ì˜ë‚˜íƒ€_DN8_2020_2023\n",
            "ì˜¬ë€ë„_2012_2018\t\t     ì˜ë‚˜íƒ€_ë””_ì—£ì§€_DN8_2024_2025\n",
            "ë”_ë‰´_íŒŒì‚¬íŠ¸_2012_2019\t\t     e_íŠ¸ë¡ _2020_2023\n",
            "íŠ¸ë™ìŠ¤_2013_2016\t\t     E_PACE_2018_2020\n",
            "ì½°íŠ¸ë¡œí¬ë¥´í…Œ_2014_2016\t\t     EQ900_2016_2018\n",
            "ë”_ë‰´_ì•„ë°˜ë–¼_2014_2016\t\t     EQA_H243_2021_2024\n",
            "ë§ˆì¹¸_2014_2018\t\t\t     EQE_V295_2022_2024\n",
            "ê·¸ëœë“œ_ì²´ë¡œí‚¤_2014_2020\t\t     EQS_V297_2022_2023\n",
            "ê¸°ë¸”ë¦¬_2014_2023\t\t     ë‰´_ES300h_2013_2015\n",
            "ë”_ë‰´_ëª¨ë‹_2015_2016\t\t     ë‰´_ES300h_2016_2018\n",
            "ë ˆë‹ˆê²Œì´ë“œ_2015_2017\t\t     ES300h_7ì„¸ëŒ€_2019_2026\n",
            "ì˜¬_ë‰´_ì˜ë Œí† _2015_2017\t\t     ë””_ì˜¬ë‰´ë‹ˆë¡œEV_2023_2024\n",
            "ì•„ìŠ¬ë€_2015_2018\t\t     ë”_ê¸°ì•„_ë ˆì´_EV_2024_2025\n",
            "í‹°ë³¼ë¦¬_2015_2018\t\t     EV6_2022_2024\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_ìŠ¤í¬ì¸ _2015_2019\t     EV9_2024_2025\n",
            "ì˜¬_ë‰´_ì¹´ë‹ˆë°œ_2015_2019\t\t     E_í´ë˜ìŠ¤_W212_2010_2016\n",
            "ì—ìŠ¤ì»¬ë ˆì´ë“œ_2015_2020\t\t     E_í´ë˜ìŠ¤_W213_2017_2020\n",
            "ë¨¸ìŠ¤íƒ±_2015_2023\t\t     E_í´ë˜ìŠ¤_W213_2021_2023\n",
            "ìµìŠ¤í”Œë¡œëŸ¬_2016_2017\t\t     E_í´ë˜ìŠ¤_W214_2024_2025\n",
            "ê·¸ëœë“œ_ìŠ¤íƒ€ë ‰ìŠ¤_2016_2018\t     F150_2004_2021\n",
            "ì‹¼íƒ€í˜_ë”_í”„ë¼ì„_2016_2018\t     F_PACE_2017_2019\n",
            "ë”_ë„¥ìŠ¤íŠ¸_ìŠ¤íŒŒí¬_2016_2018\t     G4_ë ‰ìŠ¤í„´_2018_2020\n",
            "ë”_ë‰´_ë§¥ìŠ¤í¬ë£¨ì¦ˆ_2016_2018\t     G70_2018_2020\n",
            "ë”_ë‰´_ì½”ë€ë„_ìŠ¤í¬ì¸ _2016_2018\t     ë”_ë‰´_G70_2021_2025\n",
            "ë ˆì¸ì§€ë¡œë²„_ì´ë³´í¬_2016_2019\t     G80_2017_2020\n",
            "ì•„ì´ì˜¤ë‹‰_í•˜ì´ë¸Œë¦¬ë“œ_2016_2019\t     ë”_ì˜¬ë‰´G80_2021_2024\n",
            "í‹°ë³¼ë¦¬_ì—ì–´_2016_2019\t\t     ë‰´_G80_2025_2026\n",
            "ì„íŒ”ë¼_2016_2019\t\t     G80_RG3_2021_2023\n",
            "ì¿ í¼_ì»¨íŠ¸ë¦¬ë§¨_2016_2024\t\t     G80_RG3_2025\n",
            "ì¿ í¼_ì»¨ë²„í„°ë¸”_2016_2024\t\t     G90_2019_2022\n",
            "ì¿ í¼_í´ëŸ½ë§¨_2016_2024\t\t     G90_RS4_2022_2025\n",
            "ì•Œí‹°ë§ˆ_2017_2018\t\t     GLA_í´ë˜ìŠ¤_H247_2020_2025\n",
            "ì˜¬_ë‰´_ì¹´ë§ˆë¡œ_2017_2018\t\t     GLA_í´ë˜ìŠ¤_X156_2015_2019\n",
            "ì˜¬_ë‰´_ë§ë¦¬ë¶€_2017_2018\t\t     GLB_í´ë˜ìŠ¤_X247_2020_2023\n",
            "ë‹ˆë¡œ_2017_2019\t\t\t     GLC_í´ë˜ìŠ¤_X253_2017_2019\n",
            "ë”_ë‰´_ëª¨í•˜ë¹„_2017_2019\t\t     GLC_í´ë˜ìŠ¤_X253_2020_2022\n",
            "ì½°íŠ¸ë¡œí¬ë¥´í…Œ_2017_2022\t\t     GLC_í´ë˜ìŠ¤_X253_2023\n",
            "ë¥´ë°˜ë–¼_2017_2022\t\t     GLC_í´ë˜ìŠ¤_X254_2023_2025\n",
            "ë”_ë‰´_íŠ¸ë™ìŠ¤_2017_2022\t\t     GLE_í´ë˜ìŠ¤_W166_2016_2018\n",
            "ë ˆì¸ì§€ë¡œë²„_ë²¨ë¼_2018_2019\t     GLE_í´ë˜ìŠ¤_W167_2019_2024\n",
            "ìµìŠ¤í”Œë¡œëŸ¬_2018_2019\t\t     GLS_í´ë˜ìŠ¤_X166_2017_2019\n",
            "í‹°ë³¼ë¦¬_ì•„ë¨¸_2018_2019\t\t     GLS_í´ë˜ìŠ¤_X167_2020_2024\n",
            "ì˜ë‚˜íƒ€_ë‰´_ë¼ì´ì¦ˆ_2018_2019\t     ê·¸ëœì €_GN7_2023_2025\n",
            "ìŠ¤í† ë‹‰_2018_2020\t\t     ì»¨í‹°ë„¨íƒˆ_GT_2ì„¸ëŒ€_2012_2017\n",
            "ìŠ¤íŒ…ì–´_2018_2020\t\t     ì»¨í‹°ë„¨íƒˆ_GT_3ì„¸ëŒ€_2018_2023\n",
            "ì½”ë‚˜_2018_2020\t\t\t     íŒŒì‚¬íŠ¸_GT_B8_2018_2022\n",
            "ë”_ë‰´_ì˜ë Œí† _2018_2020\t\t     GV70_2021_2023\n",
            "ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _2018_2021\t\t     ì¼ë ‰íŠ¸ë¦¬íŒŒì´ë“œ_GV70_2022_2024\n",
            "ë”_ë‰´_ê·¸ëœë“œ_ìŠ¤íƒ€ë ‰ìŠ¤_2018_2021      GV80_2020_2022\n",
            "ë”_ë‰´_ë ˆì´_2018_2022\t\t     ë‰´_GV80_2024_2025\n",
            "í‹°êµ¬ì•ˆ_ì˜¬ìŠ¤í˜ì´ìŠ¤_2018_2023\t     GV80_2024_2025\n",
            "ì•„í…Œì˜¨_2018_2023\t\t     G_í´ë˜ìŠ¤_W463_2009_2017\n",
            "ë„¥ì˜_2018_2024\t\t\t     G_í´ë˜ìŠ¤_W463b_2019_2025\n",
            "ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _ì¹¸_2019_2020\t     ê·¸ëœì €_HG_2011_2014\n",
            "ë”_ë‰´_ì¹´ë‹ˆë°œ_2019_2020\t\t     ê·¸ëœì €_HG_2015_2017\n",
            "ë§ˆì¹¸_2019_2021\t\t\t     i30_PD_2017_2018\n",
            "íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022\t\t     i4_2022_2024\n",
            "ìŠ¤í¬í‹°ì§€_ë”_ë³¼ë“œ_2019_2022\t     ê·¸ëœì €_IG_2017_2019\n",
            "ë”_ë‰´_ë§ë¦¬ë¶€_2019_2022\t\t     ë”_ë‰´_ê·¸ëœì €_IG_2020_2023\n",
            "ë”_ë‰´_ìŠ¤íŒŒí¬_2019_2022\t\t     iX_2022_2024\n",
            "ë ˆë‹ˆê²Œì´ë“œ_2019_2023\t\t     ì˜¬_ë‰´_ëª¨ë‹_JA_2017_2020\n",
            "ë·°í‹°í’€_ì½”ë€ë„_2019_2024\t\t     ëª¨ë‹_ì–´ë°˜_JA_2021_2023\n",
            "ë”_ë‰´_ì•„ì´ì˜¤ë‹‰_í•˜ì´ë¸Œë¦¬ë“œ_2020\t     ë”_ë‰´_ëª¨ë‹_JA_2024_2025\n",
            "ì½œë¡œë¼ë„_2020_2020\t\t     ë­ê¸€ëŸ¬_JK_2009_2017\n",
            "ì½”ì„¸ì–´_2020_2022\t\t     ë­ê¸€ëŸ¬_JL_2018_2024\n",
            "ë”_ë‰´_ë‹ˆë¡œ_2020_2022\t\t     ë²¨ë¡œìŠ¤í„°_JS_2018_2020\n",
            "íŠ¸ë˜ë²„ìŠ¤_2020_2023\t\t     ê¸€ë˜ë””ì—ì´í„°_JT_2020_2023\n",
            "ì…€í† ìŠ¤_2020_2023\t\t     K3_2013_2015\n",
            "ë² ë¦¬_ë‰´_í‹°ë³¼ë¦¬_2020_2023\t     ë”_ë‰´_K3_2016_2018\n",
            "ëª¨í•˜ë¹„_ë”_ë§ˆìŠ¤í„°_2020_2024\t     ì˜¬_ë‰´_K3_2019_2021\n",
            "ë² ë‰´_2020_2024\t\t\t     ë”_ë‰´_K3_2ì„¸ëŒ€_2022_2024\n",
            "íŠ¸ë ˆì¼ë¸”ë ˆì´ì €_2021_2022\t     K5_2ì„¸ëŒ€_2016_2018\n",
            "í‹°ë³¼ë¦¬_ì—ì–´_2021_2022\t\t     ë”_ë‰´_K5_2ì„¸ëŒ€_2019_2020\n",
            "ë¦¬ì–¼_ë‰´_ì½œë¡œë¼ë„_2021_2022\t     K5_3ì„¸ëŒ€_í•˜ì´ë¸Œë¦¬ë“œ_2020_2022\n",
            "ìŠ¤íŒ…ì–´_ë§ˆì´ìŠ¤í„°_2021_2023\t     K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2020_2023\n",
            "ë”_ì˜¬ë‰´íˆ¬ì‹¼_í•˜ì´ë¸Œë¦¬ë“œ_2021_2023     K5_3ì„¸ëŒ€_2020_2023\n",
            "ë”_ë‰´_ì‹¼íƒ€í˜_2021_2023\t\t     ë”_ë‰´_K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2023_2025\n",
            "ë”_ë‰´_ì½”ë‚˜_2021_2023\t\t     ë”_ë‰´_K5_3ì„¸ëŒ€_2024_2025\n",
            "íƒ€ì´ì¹¸_2021_2025\t\t     ë”_ë‰´_K7_2013_2016\n",
            "ë”_ë‰´_ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _ì¹¸_2021_2025     ì˜¬_ë‰´_K7_2016_2019\n",
            "ë”_ë‰´_ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _2021_2025\t     ì˜¬_ë‰´_K7_í•˜ì´ë¸Œë¦¬ë“œ_2017_2019\n",
            "ì˜¬_ë‰´_ë ‰ìŠ¤í„´_2021_2025\t\t     K7_í”„ë¦¬ë¯¸ì–´_í•˜ì´ë¸Œë¦¬ë“œ_2020_2021\n",
            "ìºìŠ¤í¼_2022_2024\t\t     K7_í”„ë¦¬ë¯¸ì–´_2020_2021\n",
            "ë§ˆì¹¸_2022_2024\t\t\t     K8_í•˜ì´ë¸Œë¦¬ë“œ_2022_2024\n",
            "ë””_ì˜¬_ë‰´_ìŠ¤í¬í‹°ì§€_2022_2024\t     K8_2022_2024\n",
            "ìŠ¤íƒ€ë¦¬ì•„_2022_2025\t\t     ë”_K9_2019_2021\n",
            "ë””_ì˜¬ë‰´ë‹ˆë¡œ_2022_2025\t\t     ë”_ë‰´_K9_2ì„¸ëŒ€_2022_2025\n",
            "ë”_ë‰´_ê¸°ì•„_ë ˆì´_2022_2025\t     ì²´ë¡œí‚¤_KL_2019_2023\n",
            "ë””_ì˜¬_ë‰´_ë‹ˆë¡œ_2022_2025\t\t     ë””íœë”_L663_2020_2025\n",
            "íŠ¸ë ˆì¼ë¸”ë ˆì´ì €_2023\t\t     LF_ì˜ë‚˜íƒ€_2015_2017\n",
            "ë”_ë‰´_íŒ°ë¦¬ì„¸ì´ë“œ_2023_2024\t     íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025\n",
            "í† ë ˆìŠ¤_2023_2025\t\t     M2_F87_2016_2021\n",
            "ë””_ì˜¬ë‰´ê·¸ëœì €_2023_2025\t\t     M4_F82_2015_2020\n",
            "ë””_ì˜¬ë‰´ì½”ë‚˜_2023_2025\t\t     M5_F90_2018_2023\n",
            "ë”_ë‰´_ì…€í† ìŠ¤_2023_2025\t\t     ì•„ë°˜ë–¼_MD_2011_2014\n",
            "íŠ¸ë™ìŠ¤_í¬ë¡œìŠ¤ì˜¤ë²„_2024_2025\t     MKC_2015_2018\n",
            "ë””_ì˜¬ë‰´ì‹¼íƒ€í˜_2024_2025\t\t     ë‰´_MKZ_2017_2020\n",
            "ê·¸ë‘_ì½œë ˆì˜¤ìŠ¤_2025\t\t     ì‹¼íƒ€í˜_MX5_2024_2025\n",
            "ë ˆì¸ì§€ë¡œë²„_ìŠ¤í¬ì¸ _2ì„¸ëŒ€_2013_2017    ì•„ë°˜ë–¼_N_2022_2023\n",
            "ë ˆì¸ì§€ë¡œë²„_ìŠ¤í¬ì¸ _2ì„¸ëŒ€_2018_2022    New_XF_2012_2015\n",
            "ì»´íŒ¨ìŠ¤_2ì„¸ëŒ€_2018_2022\t\t     íˆ¬ì‹¼_NX4_2021_2023\n",
            "ë ˆì¸ì§€ë¡œë²„_ì´ë³´í¬_2ì„¸ëŒ€_2020_2022    ë”_ë‰´_íˆ¬ì‹¼_NX4_2023_2025\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_ìŠ¤í¬ì¸ _2ì„¸ëŒ€_2020_2025    ì¹´ì´ì—”_PO536_2019_2023\n",
            "ì—ë¹„ì—ì´í„°_2ì„¸ëŒ€_2020_2025\t     Q30_2017_2019\n",
            "ë ˆì¸ì§€ë¡œë²„_ì´ë³´í¬_2ì„¸ëŒ€_2023_2024    Q3_F3_2020_2024\n",
            "ì•¡í‹°ì–¸_2ì„¸ëŒ€_2025\t\t     Q50_2014_2017\n",
            "2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024\t     Q5_FY_2020\n",
            "2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021  Q5_FY_2021_2024\n",
            "2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024  Q7_4M_2016_2019\n",
            "3008_2ì„¸ëŒ€_2018_2023\t\t     Q7_4M_2020_2023\n",
            "íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018\t\t     Q8_4M_2020_2025\n",
            "ëª¨ë¸_3_2019_2022\t\t     QM3_2014_2017\n",
            "íˆ¬ì•„ë ‰_3ì„¸ëŒ€_2020_2023\t\t     ë‰´QM3_2018_2019\n",
            "ëª¨ë¸_3_2024_2025\t\t     ë‰´_QM5_2012_2014\n",
            "3ì‹œë¦¬ì¦ˆ_E90_2005_2012\t\t     QM6_2017_2019\n",
            "3ì‹œë¦¬ì¦ˆ_F30_2013_2018\t\t     ë”_ë‰´_QM6_2020_2023\n",
            "3ì‹œë¦¬ì¦ˆ_G20_2019_2022\t\t     ë‰´_QM6_2021_2023\n",
            "3ì‹œë¦¬ì¦ˆ_G20_2023_2025\t\t     ë”_ë‰´_QM6_2024_2025\n",
            "3ì‹œë¦¬ì¦ˆ_GT_F34_2014_2021\t     QX60_2016_2018\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_4_2010_2016\t\t     ë‰´ì˜ë Œí† _R_2013_2014\n",
            "ë ˆì¸ì§€ë¡œë²„_4ì„¸ëŒ€_2014_2017\t     ë”_ë‰´ìŠ¤í¬í‹°ì§€R_2014_2016\n",
            "ëª¬ë°ì˜¤_4ì„¸ëŒ€_2015_2020\t\t     RAV4_2016_2018\n",
            "í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018\t     RAV4_5ì„¸ëŒ€_2019_2024\n",
            "ìŠ¤í¬í‹°ì§€_4ì„¸ëŒ€_2016_2018\t     S60_3ì„¸ëŒ€_2020_2024\n",
            "ë ˆì¸ì§€ë¡œë²„_4ì„¸ëŒ€_2018_2022\t     S90_2017_2020\n",
            "í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022\t     S90_2021_2025\n",
            "ì¹´ë‹ˆë°œ_4ì„¸ëŒ€_2021\t\t     SM3_ë„¤ì˜¤_2015_2019\n",
            "ì˜ë Œí† _4ì„¸ëŒ€_2021_2023\t\t     ë‰´_SM5_ì„í”„ë ˆì…˜_2008_2010\n",
            "ì‹œì—ë‚˜_4ì„¸ëŒ€_2021_2024\t\t     ë‰´_SM5_í”Œë˜í‹°ë„˜_2013_2014\n",
            "ì¹´ë‹ˆë°œ_4ì„¸ëŒ€_2022_2023\t\t     SM5_ë…¸ë°”_2015_2019\n",
            "ë”_ë‰´_ì¹´ë‹ˆë°œ_4ì„¸ëŒ€_2024_2025\t     SM6_2016_2020\n",
            "ë”_ë‰´_ì˜ë Œí† _4ì„¸ëŒ€_2024_2025\t     ë”_ë‰´_SM6_2021_2024\n",
            "ë¼ë¸Œ4_4ì„¸ëŒ€_2013_2018\t\t     SM7_ë‰´ì•„íŠ¸_2008_2011\n",
            "ë¼ë¸Œ4_5ì„¸ëŒ€_2019_2024\t\t     SM7_ë…¸ë°”_2015_2019\n",
            "4ì‹œë¦¬ì¦ˆ_F32_2014_2020\t\t     S_í´ë˜ìŠ¤_W221_2006_2013\n",
            "4ì‹œë¦¬ì¦ˆ_G22_2021_2023\t\t     S_í´ë˜ìŠ¤_W222_2014_2020\n",
            "4ì‹œë¦¬ì¦ˆ_G22_2024_2025\t\t     S_í´ë˜ìŠ¤_W223_2021_2025\n",
            "5008_2ì„¸ëŒ€_2018_2019\t\t     ì½”ë‚˜_SX2_2023_2025\n",
            "5008_2ì„¸ëŒ€_2021_2024\t\t     ê·¸ëœì €TG_2007_2008\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_5_2017_2020\t\t     ì˜¬_ë‰´_íˆ¬ì‹¼_TL_2016_2018\n",
            "ì—ìŠ¤ì»¬ë ˆì´ë“œ_5ì„¸ëŒ€_2021_2024\t     ì˜¬_ë‰´_íˆ¬ì‹¼_TL_2019_2020\n",
            "ì•„ì´ì˜¤ë‹‰5_2022_2023\t\t     ì‹¼íƒ€í˜_TM_2019_2020\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_5_2022_2024\t\t     UX250h_2019_2024\n",
            "ìŠ¤í¬í‹°ì§€_5ì„¸ëŒ€_2022_2024\t     V40_2015_2018\n",
            "ë ˆì¸ì§€ë¡œë²„_5ì„¸ëŒ€_2023_2024\t     V60_í¬ë¡œìŠ¤ì»¨íŠ¸ë¦¬_2ì„¸ëŒ€_2020_2025\n",
            "5ì‹œë¦¬ì¦ˆ_F10_2010_2016\t\t     V90_í¬ë¡œìŠ¤ì»¨íŠ¸ë¦¬_2018_2024\n",
            "5ì‹œë¦¬ì¦ˆ_G30_2017_2023\t\t     ë‰´_ì²´ì–´ë§¨_W_2012_2016\n",
            "5ì‹œë¦¬ì¦ˆ_G60_2024_2025\t\t     ê·¸ëœë“œ_ì²´ë¡œí‚¤_WL_2021_2023\n",
            "5ì‹œë¦¬ì¦ˆ_GT_F07_2010_2017\t     X1_F48_2016_2019\n",
            "ìµìŠ¤í”Œë¡œëŸ¬_6ì„¸ëŒ€_2020_2025\t     X1_F48_2020_2022\n",
            "ì•„ì´ì˜¤ë‹‰6_2023_2025\t\t     X1_U11_2023_2024\n",
            "6ì‹œë¦¬ì¦ˆ_F12_2011_2018\t\t     X2_F39_2018_2023\n",
            "6ì‹œë¦¬ì¦ˆ_GT_G32_2018_2020\t     X3_G01_2018_2021\n",
            "6ì‹œë¦¬ì¦ˆ_GT_G32_2021_2024\t     X3_G01_2022_2024\n",
            "ë°•ìŠ¤í„°_718_2017_2024\t\t     X4_F26_2015_2018\n",
            "718_ì¹´ì´ë§¨_2017_2024\t\t     X4_G02_2019_2021\n",
            "718_ë°•ìŠ¤í„°_2017_2024\t\t     X4_G02_2022_2025\n",
            "ê³¨í”„_7ì„¸ëŒ€_2013_2016\t\t     X5_F15_2014_2018\n",
            "7ì‹œë¦¬ì¦ˆ_F01_2009_2015\t\t     X5_G05_2019_2023\n",
            "7ì‹œë¦¬ì¦ˆ_G11_2016_2018\t\t     X5_G05_2024_2025\n",
            "7ì‹œë¦¬ì¦ˆ_G11_2019_2022\t\t     X6_F16_2015_2019\n",
            "7ì‹œë¦¬ì¦ˆ_G70_2023_2025\t\t     X6_G06_2020_2023\n",
            "8ì‹œë¦¬ì¦ˆ_G15_2020_2024\t\t     X6_G06_2024_2025\n",
            "911_2003_2019\t\t\t     X7_G07_2019_2022\n",
            "911_992_2020_2024\t\t     X7_G07_2023_2025\n",
            "íŒŒë‚˜ë©”ë¼_971_2017_2023\t\t     XC40_2019_2022\n",
            "A4_B9_2016_2019\t\t\t     XC60_2ì„¸ëŒ€_2018_2021\n",
            "A4_B9_2020_2024\t\t\t     XC60_2ì„¸ëŒ€_2022_2025\n",
            "A5_F5_2019_2024\t\t\t     XC90_2ì„¸ëŒ€_2017_2019\n",
            "ë‰´_A6_2012_2014\t\t\t     XC90_2ì„¸ëŒ€_2020_2025\n",
            "ë‰´_A6_2015_2018\t\t\t     XE_2016_2019\n",
            "A6_C8_2019_2025\t\t\t     XF_X260_2016_2020\n",
            "A7_2012_2016\t\t\t     XJ_8ì„¸ëŒ€_2010_2019\n",
            "A7_4K_2020_2024\t\t\t     XM3_2020_2023\n",
            "A8_D5_2018_2023\t\t\t     XM3_2024\n",
            "ì•„ë°˜ë–¼_AD_2016_2018\t\t     ìº ë¦¬_XV70_2018_2024\n",
            "ë”_ë‰´_ì•„ë°˜ë–¼_AD_2019_2020\t     ëª¨ë¸_Y_2021_2025\n",
            "All_New_XJ_2016_2019\t\t     YFì˜ë‚˜íƒ€_2009_2012\n",
            "AMG_GT_2016_2024\t\t     YFì˜ë‚˜íƒ€_í•˜ì´ë¸Œë¦¬ë“œ_2011_2015\n",
            "A_í´ë˜ìŠ¤_W176_2015_2018\t\t     Z4_G29_2019_2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "metadata": {
        "id": "u-I8s06qKuH6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train ê²½ë¡œ\n",
        "train_dir = '/content/train'\n",
        "\n",
        "# test ê²½ë¡œ\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# sample_submission (ì¶”ë¡  ë•Œ ì‚¬ìš©)\n",
        "sample_submission_path = '/content/sample_submission.csv'\n"
      ],
      "metadata": {
        "id": "OQ1A1tv5KvQS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB ë‹¨ìœ„\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB ë‹¨ìœ„\n",
        "    print(f\"ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# í˜„ì¬ CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "if torch.cuda.is_available():\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU ìºì‹œ ë° ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\nğŸ§¹ GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"âŒ CUDA ì‚¬ìš© ë¶ˆê°€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYqAIlh8Kw_6",
        "outputId": "3c241357-5f25-4474-9d43-0ed6d882fb7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” ì´ˆê¸°í™” ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = 0.00 MB | Reserved = 0.00 MB\n",
            "\n",
            "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\n",
            "ğŸ” ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = 0.00 MB | Reserved = 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ crop\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# ì›ë³¸ ë° crop ì €ì¥ ê²½ë¡œ\n",
        "input_root = \"/content/train\"\n",
        "output_root = \"/content/train_crop\"\n",
        "\n",
        "# ë¶€ìœ„ë³„ crop í•¨ìˆ˜ ì •ì˜\n",
        "def crop_views(image):\n",
        "    w, h = image.size\n",
        "    return {\n",
        "        \"original\": image,\n",
        "        \"logo\": image.crop((w*0.3, h*0.0, w*0.7, h*0.25)),      # ìƒë‹¨ ë¡œê³ \n",
        "        \"wheel\": image.crop((w*0.1, h*0.6, w*0.9, h*0.95)),     # í•˜ë‹¨ íœ \n",
        "        \"interior\": image.crop((w*0.25, h*0.3, w*0.85, h*0.8))  # ëŒ€ëµì ì¸ ì‹¤ë‚´\n",
        "    }\n",
        "\n",
        "# ì „ì²˜ë¦¬ ë£¨í”„\n",
        "for class_dir in os.listdir(input_root):\n",
        "    img_paths = glob.glob(os.path.join(input_root, class_dir, \"*.jpg\"))\n",
        "    for img_path in img_paths:\n",
        "        try:\n",
        "            image = Image.open(img_path).convert(\"RGB\")\n",
        "            cropped = crop_views(image)\n",
        "            for view_name, view_img in cropped.items():\n",
        "                save_dir = os.path.join(output_root, view_name, class_dir)\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "                fname = os.path.basename(img_path)\n",
        "                view_img.save(os.path.join(save_dir, fname))\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ ì—ëŸ¬ ë°œìƒ: {img_path} - {e}\")\n"
      ],
      "metadata": {
        "id": "1wzcY-vFNEhf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class MultiViewDatasetWithColor(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.views = [\"original\", \"logo\", \"wheel\", \"interior\"]\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_info = []\n",
        "        for label_idx, class_name in enumerate(sorted(os.listdir(os.path.join(root_dir, \"original\")))):\n",
        "            for fname in os.listdir(os.path.join(root_dir, \"original\", class_name)):\n",
        "                sample = {\n",
        "                    \"views\": {view: os.path.join(root_dir, view, class_name, fname) for view in self.views},\n",
        "                    \"label\": label_idx\n",
        "                }\n",
        "                self.image_info.append(sample)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.image_info[idx]\n",
        "        images = {view: Image.open(path).convert(\"RGB\") for view, path in sample[\"views\"].items()}\n",
        "\n",
        "        color_feats = []\n",
        "        if self.transform:\n",
        "            for view, img in images.items():\n",
        "                transformed_img = self.transform(img)\n",
        "                images[view] = transformed_img\n",
        "                mean_rgb = transformed_img.view(3, -1).mean(dim=1)  # [3]\n",
        "                color_feats.append(mean_rgb)\n",
        "\n",
        "        color_feat = torch.cat(color_feats, dim=0)  # [12]\n",
        "\n",
        "        return images, color_feat, sample[\"label\"]\n",
        "\n",
        "# âœ… Transform ì •ì˜\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… Dataset ë° DataLoader ì´ˆê¸°í™”\n",
        "dataset = MultiViewDatasetWithColor(root_dir=\"/content/train_crop\", transform=transform)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "RmAmdibaNyoO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class MultiInputEffNetB5_WithColor(nn.Module):\n",
        "    def __init__(self, num_classes=396, pretrained=True):\n",
        "        super(MultiInputEffNetB5_WithColor, self).__init__()\n",
        "        self.views = [\"original\", \"logo\", \"wheel\", \"interior\"]\n",
        "\n",
        "        # ê° viewë§ˆë‹¤ EfficientNet-B5 encoder (num_classes=0: feature extractorë¡œ ì‚¬ìš©)\n",
        "        self.encoders = nn.ModuleDict({\n",
        "            view: timm.create_model(\"efficientnet_b5\", pretrained=pretrained, num_classes=0)\n",
        "            for view in self.views\n",
        "        })\n",
        "\n",
        "        # ìµœì¢… classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(len(self.views) * (2048 + 3), 1024),  # 2051 x 4 = 8204\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, images, rgb_means):  # rgb_means: [B, 12]\n",
        "        B = rgb_means.size(0)\n",
        "        feats = []\n",
        "\n",
        "        for i, view in enumerate(self.views):\n",
        "            img_feat = self.encoders[view](images[view])             # [B, 2048]\n",
        "            rgb_feat = rgb_means[:, i*3:(i+1)*3].to(img_feat.device) # [B, 3]\n",
        "            concat_feat = torch.cat([img_feat, rgb_feat], dim=1)     # [B, 2051]\n",
        "            feats.append(concat_feat)\n",
        "\n",
        "        all_feat = torch.cat(feats, dim=1)  # [B, 8204]\n",
        "        out = self.classifier(all_feat)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "sRvp0xRiOUTE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "\n",
        "class CustomMultiViewDataset(Dataset):\n",
        "    def __init__(self, root_dir, view_names, transform=None):\n",
        "        self.root_dir = root_dir  # e.g., '/content/train_crop'\n",
        "        self.view_names = view_names  # e.g., ['original', 'logo', 'wheel', 'interior']\n",
        "        self.transform = transform\n",
        "\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(os.path.join(root_dir, view_names[0])))\n",
        "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(root_dir, view_names[0], cls)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                if img_name.endswith(\".jpg\"):\n",
        "                    self.image_paths.append(img_name)\n",
        "                    self.labels.append(self.class_to_idx[cls])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        views = {}\n",
        "        rgb_features = []\n",
        "\n",
        "        for view in self.view_names:\n",
        "            img_path = os.path.join(self.root_dir, view, self.classes[label], img_name)\n",
        "            img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "            # RGB í‰ê· ê°’ ê³„ì‚° (transform ì ìš© ì „)\n",
        "            np_img = np.array(img) / 255.0  # [H, W, 3], normalize to 0-1\n",
        "            mean_rgb = np_img.mean(axis=(0, 1))  # shape: (3,)\n",
        "            rgb_features.extend(mean_rgb.tolist())\n",
        "\n",
        "            # transform ì ìš©\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            views[view] = img\n",
        "\n",
        "        # RGB í‰ê· ê°’ì„ torch.Tensorë¡œ ë³€í™˜ [12]\n",
        "        rgb_tensor = torch.tensor(rgb_features, dtype=torch.float32)\n",
        "\n",
        "        return views, rgb_tensor, label\n"
      ],
      "metadata": {
        "id": "m66vCX7GPMU-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ğŸ”§ EfficientNet-B5ì— ë§ì¶˜ ì „ì²˜ë¦¬\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((456, 456)),  # EfficientNet-B5 ì…ë ¥ ì‚¬ì´ì¦ˆ\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… RGB í‰ê·  í¬í•¨ Custom Dataset ìƒì„±\n",
        "train_dataset = CustomMultiViewDataset(\n",
        "    root_dir='/content/train_crop',\n",
        "    view_names=['original', 'logo', 'wheel', 'interior'],\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "# âœ… DataLoader ì„¤ì •\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2,         # ë©”ëª¨ë¦¬ ì—¬ìœ  ì‹œ 8 ì´ìƒìœ¼ë¡œ ê°€ëŠ¥\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True       # ì„±ëŠ¥ í–¥ìƒ (ê°€ëŠ¥í•  ê²½ìš°)\n",
        ")\n",
        "\n",
        "# âœ… ë°°ì¹˜ unpacking ì˜ˆì‹œ\n",
        "# for views, rgb_tensor, labels in train_loader:\n",
        "#     print(views['original'].shape)  # torch.Size([4, 3, 456, 456])\n",
        "#     print(rgb_tensor.shape)         # torch.Size([4, 12])\n",
        "#     print(labels.shape)             # torch.Size([4])\n"
      ],
      "metadata": {
        "id": "oTGIBE13PT_N"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class MultiInputEffNetB5_WithColor(nn.Module):\n",
        "    def __init__(self, num_classes=396, pretrained=True):\n",
        "        super(MultiInputEffNetB5_WithColor, self).__init__()\n",
        "        self.views = [\"original\", \"logo\", \"wheel\", \"interior\"]\n",
        "\n",
        "        self.encoders = nn.ModuleDict({\n",
        "            view: timm.create_model(\"efficientnet_b5\", pretrained=pretrained, num_classes=0)\n",
        "            for view in self.views\n",
        "        })\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(len(self.views) * 2051, 1024),  # 2048 feature + 3 RGB í‰ê· \n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, images, rgb_means):\n",
        "        feats = []\n",
        "        for view in self.views:\n",
        "            img_feat = self.encoders[view](images[view])              # [B, 2048]\n",
        "            start_idx = self.views.index(view) * 3\n",
        "            end_idx = start_idx + 3\n",
        "            rgb_feat = rgb_means[:, start_idx:end_idx].to(img_feat.device)  # [B, 3]\n",
        "            feat_concat = torch.cat([img_feat, rgb_feat], dim=1)      # [B, 2051]\n",
        "            feats.append(feat_concat)\n",
        "        all_feats = torch.cat(feats, dim=1)                           # [B, 8204]\n",
        "        return self.classifier(all_feats)\n",
        "\n"
      ],
      "metadata": {
        "id": "6j-thznhWbQu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
        "    print(f\"ğŸ“Š GPU ë©”ëª¨ë¦¬: Allocated = {allocated:.2f}MB | Reserved = {reserved:.2f}MB\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” ì „ ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"âœ… GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” í›„ ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j_xLRm-W4nr",
        "outputId": "e3a2c9b4-061c-48d4-f3b4-3379dd6fadd5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” ì´ˆê¸°í™” ì „ ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š GPU ë©”ëª¨ë¦¬: Allocated = 39678.02MB | Reserved = 39994.00MB\n",
            "âœ… GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\n",
            "ğŸ” ì´ˆê¸°í™” í›„ ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š GPU ë©”ëª¨ë¦¬: Allocated = 19309.58MB | Reserved = 39994.00MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… CUDAê°€ ê°€ëŠ¥í•œ ê²½ìš° GPU ì‚¬ìš©\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ì´í›„ì— model ì„ ì–¸\n",
        "model = MultiInputEffNetB5_WithColor(num_classes=396, pretrained=True).to(device)\n"
      ],
      "metadata": {
        "id": "_MFqe1vdWtbk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ì†ì‹¤ í•¨ìˆ˜\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ì˜µí‹°ë§ˆì´ì €\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "\n",
        "# (ì„ íƒ) learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
        "\n",
        "# âœ… ìˆ˜ì •ëœ í•™ìŠµ í•¨ìˆ˜\n",
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for views, rgb_tensor, labels in dataloader:\n",
        "        # ì´ë¯¸ì§€ì™€ RGB í‰ê·  ëª¨ë‘ deviceë¡œ ì´ë™\n",
        "        for key in views:\n",
        "            views[key] = views[key].to(device)\n",
        "        rgb_tensor = rgb_tensor.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # ëª¨ë¸ forward\n",
        "        outputs = model(views, rgb_tensor)\n",
        "\n",
        "        # ì†ì‹¤ ê³„ì‚° ë° ì—­ì „íŒŒ\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # í†µê³„ ê¸°ë¡\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct / total\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "vyz6VSSKPkAt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15  # ìµœëŒ€ epoch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Early Stopping ì„¤ì •\n",
        "best_loss = float('inf')\n",
        "patience = 5  # ì„±ëŠ¥ì´ í–¥ìƒë˜ì§€ ì•Šì•„ë„ ì°¸ëŠ” íšŸìˆ˜\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] âœ… Loss: {train_loss:.4f} | Accuracy: {train_acc:.4f}\")\n",
        "\n",
        "    # Early stopping ì¡°ê±´ í™•ì¸\n",
        "    if train_loss < best_loss - 1e-4:  # ìµœì†Œ ê°œì„ ëŸ‰\n",
        "        best_loss = train_loss\n",
        "        counter = 0\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")  # ëª¨ë¸ ì €ì¥\n",
        "        print(\"ğŸ“Œ Model improved. Saved!\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"â³ No improvement. EarlyStopping patience: {counter}/{patience}\")\n",
        "        if counter >= patience:\n",
        "            print(\"ğŸ›‘ Early stopping triggered.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "dvFpE8r7Pqpj",
        "outputId": "33e09136-9eb2-4a30-de72-fad58761bdaa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d44e24bebd11>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-c089abb72ed6>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# ì†ì‹¤ ê³„ì‚° ë° ì—­ì „íŒŒ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}