{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1-9OTJscy8wBvMXN5KiMYpWEnbvJ1PhpG",
      "authorship_tag": "ABX9TyOov9rfgYoGk5N5Yym9rtUz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/TTA%20%EC%A0%81%EC%9A%A9(%EC%84%B1%EB%8A%A5%20%EB%96%A8%EC%96%B4%EC%A7%90).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# 1. Drive에서 로컬로 복사 (빠름)\n",
        "shutil.copy(\"/content/drive/MyDrive/open.zip\", \"/content/open.zip\")\n",
        "\n",
        "# 2. 압축 풀기\n",
        "with zipfile.ZipFile(\"/content/open.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# 3. 확인\n",
        "!ls /content/train\n"
      ],
      "metadata": {
        "id": "VGLGwzmFf9U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8995b5f5-db59-4f5d-cbf3-78c3c76510af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "컨티넨탈_10세대_2017_2019\t     A_클래스_W177_2020_2025\n",
            "어코드_10세대_2018_2022\t\t     B_클래스_W246_2013_2018\n",
            "1시리즈_F20_2013_2015\t\t     뉴_스타일_코란도_C_2017_2019\n",
            "1시리즈_F20_2016_2019\t\t     프리우스_C_2018_2020\n",
            "1시리즈_F40_2020_2024\t\t     뉴_CC_2012_2016\n",
            "그랜드카니발_2006_2010\t\t     CLA_클래스_C117_2014_2019\n",
            "2008_2015_2017\t\t\t     CLA_클래스_C118_2020_2025\n",
            "에쿠스_신형_2010_2015\t\t     CLE_클래스_C236_2024_2025\n",
            "파나메라_2010_2016\t\t     CLS_클래스_C257_2019_2023\n",
            "뉴_제타_2011_2016\t\t     CLS_클래스_W218_2012_2017\n",
            "뉴_카이엔_2011_2018\t\t     아반떼_하이브리드_CN7_2021_2023\n",
            "엑센트_신형_2011_2019\t\t     아반떼_CN7_2021_2023\n",
            "스파크_2012_2015\t\t     더_뉴_아반떼_CN7_2023_2025\n",
            "쿠퍼_컨트리맨_2012_2015\t\t     CT6_2016_2018\n",
            "올_뉴_모닝_2012_2015\t\t     C_클래스_W204_2008_2015\n",
            "말리부_2012_2016\t\t     C_클래스_W205_2015_2021\n",
            "아베오_2012_2016\t\t     C_클래스_W206_2022_2024\n",
            "뉴_티구안_2012_2016\t\t     제네시스_DH_2014_2016\n",
            "레이_2012_2017\t\t\t     쏘나타_DN8_2020_2023\n",
            "올란도_2012_2018\t\t     쏘나타_디_엣지_DN8_2024_2025\n",
            "더_뉴_파사트_2012_2019\t\t     e_트론_2020_2023\n",
            "트랙스_2013_2016\t\t     E_PACE_2018_2020\n",
            "콰트로포르테_2014_2016\t\t     EQ900_2016_2018\n",
            "더_뉴_아반떼_2014_2016\t\t     EQA_H243_2021_2024\n",
            "마칸_2014_2018\t\t\t     EQE_V295_2022_2024\n",
            "그랜드_체로키_2014_2020\t\t     EQS_V297_2022_2023\n",
            "기블리_2014_2023\t\t     뉴_ES300h_2013_2015\n",
            "더_뉴_모닝_2015_2016\t\t     뉴_ES300h_2016_2018\n",
            "레니게이드_2015_2017\t\t     ES300h_7세대_2019_2026\n",
            "올_뉴_쏘렌토_2015_2017\t\t     디_올뉴니로EV_2023_2024\n",
            "아슬란_2015_2018\t\t     더_기아_레이_EV_2024_2025\n",
            "티볼리_2015_2018\t\t     EV6_2022_2024\n",
            "디스커버리_스포츠_2015_2019\t     EV9_2024_2025\n",
            "올_뉴_카니발_2015_2019\t\t     E_클래스_W212_2010_2016\n",
            "에스컬레이드_2015_2020\t\t     E_클래스_W213_2017_2020\n",
            "머스탱_2015_2023\t\t     E_클래스_W213_2021_2023\n",
            "익스플로러_2016_2017\t\t     E_클래스_W214_2024_2025\n",
            "그랜드_스타렉스_2016_2018\t     F150_2004_2021\n",
            "싼타페_더_프라임_2016_2018\t     F_PACE_2017_2019\n",
            "더_넥스트_스파크_2016_2018\t     G4_렉스턴_2018_2020\n",
            "더_뉴_맥스크루즈_2016_2018\t     G70_2018_2020\n",
            "더_뉴_코란도_스포츠_2016_2018\t     더_뉴_G70_2021_2025\n",
            "레인지로버_이보크_2016_2019\t     G80_2017_2020\n",
            "아이오닉_하이브리드_2016_2019\t     더_올뉴G80_2021_2024\n",
            "티볼리_에어_2016_2019\t\t     뉴_G80_2025_2026\n",
            "임팔라_2016_2019\t\t     G80_RG3_2021_2023\n",
            "쿠퍼_컨트리맨_2016_2024\t\t     G80_RG3_2025\n",
            "쿠퍼_컨버터블_2016_2024\t\t     G90_2019_2022\n",
            "쿠퍼_클럽맨_2016_2024\t\t     G90_RS4_2022_2025\n",
            "알티마_2017_2018\t\t     GLA_클래스_H247_2020_2025\n",
            "올_뉴_말리부_2017_2018\t\t     GLA_클래스_X156_2015_2019\n",
            "올_뉴_카마로_2017_2018\t\t     GLB_클래스_X247_2020_2023\n",
            "니로_2017_2019\t\t\t     GLC_클래스_X253_2017_2019\n",
            "더_뉴_모하비_2017_2019\t\t     GLC_클래스_X253_2020_2022\n",
            "콰트로포르테_2017_2022\t\t     GLC_클래스_X253_2023\n",
            "르반떼_2017_2022\t\t     GLC_클래스_X254_2023_2025\n",
            "더_뉴_트랙스_2017_2022\t\t     GLE_클래스_W166_2016_2018\n",
            "레인지로버_벨라_2018_2019\t     GLE_클래스_W167_2019_2024\n",
            "익스플로러_2018_2019\t\t     GLS_클래스_X166_2017_2019\n",
            "티볼리_아머_2018_2019\t\t     GLS_클래스_X167_2020_2024\n",
            "쏘나타_뉴_라이즈_2018_2019\t     그랜저_GN7_2023_2025\n",
            "스팅어_2018_2020\t\t     컨티넨탈_GT_2세대_2012_2017\n",
            "스토닉_2018_2020\t\t     컨티넨탈_GT_3세대_2018_2023\n",
            "코나_2018_2020\t\t\t     파사트_GT_B8_2018_2022\n",
            "더_뉴_쏘렌토_2018_2020\t\t     GV70_2021_2023\n",
            "렉스턴_스포츠_2018_2021\t\t     일렉트리파이드_GV70_2022_2024\n",
            "더_뉴_그랜드_스타렉스_2018_2021      GV80_2020_2022\n",
            "더_뉴_레이_2018_2022\t\t     뉴_GV80_2024_2025\n",
            "티구안_올스페이스_2018_2023\t     GV80_2024_2025\n",
            "아테온_2018_2023\t\t     G_클래스_W463_2009_2017\n",
            "넥쏘_2018_2024\t\t\t     G_클래스_W463b_2019_2025\n",
            "렉스턴_스포츠_칸_2019_2020\t     그랜저_HG_2011_2014\n",
            "더_뉴_카니발_2019_2020\t\t     그랜저_HG_2015_2017\n",
            "마칸_2019_2021\t\t\t     i30_PD_2017_2018\n",
            "팰리세이드_2019_2022\t\t     i4_2022_2024\n",
            "스포티지_더_볼드_2019_2022\t     그랜저_IG_2017_2019\n",
            "더_뉴_말리부_2019_2022\t\t     더_뉴_그랜저_IG_2020_2023\n",
            "더_뉴_스파크_2019_2022\t\t     iX_2022_2024\n",
            "레니게이드_2019_2023\t\t     올_뉴_모닝_JA_2017_2020\n",
            "뷰티풀_코란도_2019_2024\t\t     모닝_어반_JA_2021_2023\n",
            "더_뉴_아이오닉_하이브리드_2020\t     더_뉴_모닝_JA_2024_2025\n",
            "콜로라도_2020_2020\t\t     랭글러_JK_2009_2017\n",
            "코세어_2020_2022\t\t     랭글러_JL_2018_2024\n",
            "더_뉴_니로_2020_2022\t\t     벨로스터_JS_2018_2020\n",
            "트래버스_2020_2023\t\t     글래디에이터_JT_2020_2023\n",
            "셀토스_2020_2023\t\t     K3_2013_2015\n",
            "베리_뉴_티볼리_2020_2023\t     더_뉴_K3_2016_2018\n",
            "모하비_더_마스터_2020_2024\t     올_뉴_K3_2019_2021\n",
            "베뉴_2020_2024\t\t\t     더_뉴_K3_2세대_2022_2024\n",
            "트레일블레이저_2021_2022\t     K5_2세대_2016_2018\n",
            "티볼리_에어_2021_2022\t\t     더_뉴_K5_2세대_2019_2020\n",
            "리얼_뉴_콜로라도_2021_2022\t     K5_3세대_하이브리드_2020_2022\n",
            "스팅어_마이스터_2021_2023\t     K5_하이브리드_3세대_2020_2023\n",
            "더_올뉴투싼_하이브리드_2021_2023     K5_3세대_2020_2023\n",
            "더_뉴_싼타페_2021_2023\t\t     더_뉴_K5_하이브리드_3세대_2023_2025\n",
            "더_뉴_코나_2021_2023\t\t     더_뉴_K5_3세대_2024_2025\n",
            "타이칸_2021_2025\t\t     더_뉴_K7_2013_2016\n",
            "더_뉴_렉스턴_스포츠_칸_2021_2025     올_뉴_K7_2016_2019\n",
            "더_뉴_렉스턴_스포츠_2021_2025\t     올_뉴_K7_하이브리드_2017_2019\n",
            "올_뉴_렉스턴_2021_2025\t\t     K7_프리미어_하이브리드_2020_2021\n",
            "캐스퍼_2022_2024\t\t     K7_프리미어_2020_2021\n",
            "마칸_2022_2024\t\t\t     K8_하이브리드_2022_2024\n",
            "디_올_뉴_스포티지_2022_2024\t     K8_2022_2024\n",
            "스타리아_2022_2025\t\t     더_K9_2019_2021\n",
            "디_올뉴니로_2022_2025\t\t     더_뉴_K9_2세대_2022_2025\n",
            "더_뉴_기아_레이_2022_2025\t     체로키_KL_2019_2023\n",
            "디_올_뉴_니로_2022_2025\t\t     디펜더_L663_2020_2025\n",
            "트레일블레이저_2023\t\t     LF_쏘나타_2015_2017\n",
            "더_뉴_팰리세이드_2023_2024\t     팰리세이드_LX3_2025\n",
            "토레스_2023_2025\t\t     M2_F87_2016_2021\n",
            "디_올뉴그랜저_2023_2025\t\t     M4_F82_2015_2020\n",
            "디_올뉴코나_2023_2025\t\t     M5_F90_2018_2023\n",
            "더_뉴_셀토스_2023_2025\t\t     아반떼_MD_2011_2014\n",
            "트랙스_크로스오버_2024_2025\t     MKC_2015_2018\n",
            "디_올뉴싼타페_2024_2025\t\t     뉴_MKZ_2017_2020\n",
            "그랑_콜레오스_2025\t\t     싼타페_MX5_2024_2025\n",
            "레인지로버_스포츠_2세대_2013_2017    아반떼_N_2022_2023\n",
            "레인지로버_스포츠_2세대_2018_2022    New_XF_2012_2015\n",
            "컴패스_2세대_2018_2022\t\t     투싼_NX4_2021_2023\n",
            "레인지로버_이보크_2세대_2020_2022    더_뉴_투싼_NX4_2023_2025\n",
            "디스커버리_스포츠_2세대_2020_2025    카이엔_PO536_2019_2023\n",
            "에비에이터_2세대_2020_2025\t     Q30_2017_2019\n",
            "레인지로버_이보크_2세대_2023_2024    Q3_F3_2020_2024\n",
            "액티언_2세대_2025\t\t     Q50_2014_2017\n",
            "2시리즈_그란쿠페_F44_2020_2024\t     Q5_FY_2020\n",
            "2시리즈_액티브_투어러_F45_2019_2021  Q5_FY_2021_2024\n",
            "2시리즈_액티브_투어러_U06_2022_2024  Q7_4M_2016_2019\n",
            "3008_2세대_2018_2023\t\t     Q7_4M_2020_2023\n",
            "파일럿_3세대_2016_2018\t\t     Q8_4M_2020_2025\n",
            "모델_3_2019_2022\t\t     QM3_2014_2017\n",
            "투아렉_3세대_2020_2023\t\t     뉴QM3_2018_2019\n",
            "모델_3_2024_2025\t\t     뉴_QM5_2012_2014\n",
            "3시리즈_E90_2005_2012\t\t     QM6_2017_2019\n",
            "3시리즈_F30_2013_2018\t\t     더_뉴_QM6_2020_2023\n",
            "3시리즈_G20_2019_2022\t\t     뉴_QM6_2021_2023\n",
            "3시리즈_G20_2023_2025\t\t     더_뉴_QM6_2024_2025\n",
            "3시리즈_GT_F34_2014_2021\t     QX60_2016_2018\n",
            "디스커버리_4_2010_2016\t\t     뉴쏘렌토_R_2013_2014\n",
            "레인지로버_4세대_2014_2017\t     더_뉴스포티지R_2014_2016\n",
            "몬데오_4세대_2015_2020\t\t     RAV4_2016_2018\n",
            "스포티지_4세대_2016_2018\t     RAV4_5세대_2019_2024\n",
            "프리우스_4세대_2016_2018\t     S60_3세대_2020_2024\n",
            "레인지로버_4세대_2018_2022\t     S90_2017_2020\n",
            "프리우스_4세대_2019_2022\t     S90_2021_2025\n",
            "카니발_4세대_2021\t\t     SM3_네오_2015_2019\n",
            "쏘렌토_4세대_2021_2023\t\t     뉴_SM5_임프레션_2008_2010\n",
            "시에나_4세대_2021_2024\t\t     뉴_SM5_플래티넘_2013_2014\n",
            "카니발_4세대_2022_2023\t\t     SM5_노바_2015_2019\n",
            "더_뉴_쏘렌토_4세대_2024_2025\t     SM6_2016_2020\n",
            "더_뉴_카니발_4세대_2024_2025\t     더_뉴_SM6_2021_2024\n",
            "라브4_4세대_2013_2018\t\t     SM7_뉴아트_2008_2011\n",
            "라브4_5세대_2019_2024\t\t     SM7_노바_2015_2019\n",
            "4시리즈_F32_2014_2020\t\t     S_클래스_W221_2006_2013\n",
            "4시리즈_G22_2021_2023\t\t     S_클래스_W222_2014_2020\n",
            "4시리즈_G22_2024_2025\t\t     S_클래스_W223_2021_2025\n",
            "5008_2세대_2018_2019\t\t     코나_SX2_2023_2025\n",
            "5008_2세대_2021_2024\t\t     그랜저TG_2007_2008\n",
            "디스커버리_5_2017_2020\t\t     올_뉴_투싼_TL_2016_2018\n",
            "에스컬레이드_5세대_2021_2024\t     올_뉴_투싼_TL_2019_2020\n",
            "아이오닉5_2022_2023\t\t     싼타페_TM_2019_2020\n",
            "디스커버리_5_2022_2024\t\t     UX250h_2019_2024\n",
            "스포티지_5세대_2022_2024\t     V40_2015_2018\n",
            "레인지로버_5세대_2023_2024\t     V60_크로스컨트리_2세대_2020_2025\n",
            "5시리즈_F10_2010_2016\t\t     V90_크로스컨트리_2018_2024\n",
            "5시리즈_G30_2017_2023\t\t     뉴_체어맨_W_2012_2016\n",
            "5시리즈_G60_2024_2025\t\t     그랜드_체로키_WL_2021_2023\n",
            "5시리즈_GT_F07_2010_2017\t     X1_F48_2016_2019\n",
            "익스플로러_6세대_2020_2025\t     X1_F48_2020_2022\n",
            "아이오닉6_2023_2025\t\t     X1_U11_2023_2024\n",
            "6시리즈_F12_2011_2018\t\t     X2_F39_2018_2023\n",
            "6시리즈_GT_G32_2018_2020\t     X3_G01_2018_2021\n",
            "6시리즈_GT_G32_2021_2024\t     X3_G01_2022_2024\n",
            "박스터_718_2017_2024\t\t     X4_F26_2015_2018\n",
            "718_카이맨_2017_2024\t\t     X4_G02_2019_2021\n",
            "718_박스터_2017_2024\t\t     X4_G02_2022_2025\n",
            "골프_7세대_2013_2016\t\t     X5_F15_2014_2018\n",
            "7시리즈_F01_2009_2015\t\t     X5_G05_2019_2023\n",
            "7시리즈_G11_2016_2018\t\t     X5_G05_2024_2025\n",
            "7시리즈_G11_2019_2022\t\t     X6_F16_2015_2019\n",
            "7시리즈_G70_2023_2025\t\t     X6_G06_2020_2023\n",
            "8시리즈_G15_2020_2024\t\t     X6_G06_2024_2025\n",
            "911_2003_2019\t\t\t     X7_G07_2019_2022\n",
            "911_992_2020_2024\t\t     X7_G07_2023_2025\n",
            "파나메라_971_2017_2023\t\t     XC40_2019_2022\n",
            "A4_B9_2016_2019\t\t\t     XC60_2세대_2018_2021\n",
            "A4_B9_2020_2024\t\t\t     XC60_2세대_2022_2025\n",
            "A5_F5_2019_2024\t\t\t     XC90_2세대_2017_2019\n",
            "뉴_A6_2012_2014\t\t\t     XC90_2세대_2020_2025\n",
            "뉴_A6_2015_2018\t\t\t     XE_2016_2019\n",
            "A6_C8_2019_2025\t\t\t     XF_X260_2016_2020\n",
            "A7_2012_2016\t\t\t     XJ_8세대_2010_2019\n",
            "A7_4K_2020_2024\t\t\t     XM3_2020_2023\n",
            "A8_D5_2018_2023\t\t\t     XM3_2024\n",
            "아반떼_AD_2016_2018\t\t     캠리_XV70_2018_2024\n",
            "더_뉴_아반떼_AD_2019_2020\t     모델_Y_2021_2025\n",
            "All_New_XJ_2016_2019\t\t     YF쏘나타_2009_2012\n",
            "AMG_GT_2016_2024\t\t     YF쏘나타_하이브리드_2011_2015\n",
            "A_클래스_W176_2015_2018\t\t     Z4_G29_2019_2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "metadata": {
        "id": "eyLBp4j3i6F1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 경로\n",
        "train_dir = '/content/train'\n",
        "\n",
        "# test 경로\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# sample_submission (추론 때 사용)\n",
        "sample_submission_path = '/content/sample_submission.csv'\n"
      ],
      "metadata": {
        "id": "Ybtf0x5si9CE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB 단위\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB 단위\n",
        "    print(f\"📊 현재 GPU 메모리 상태: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# 현재 CUDA 사용 가능 여부 확인\n",
        "if torch.cuda.is_available():\n",
        "    print(\"🔍 초기화 전 GPU 메모리 상태:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU 캐시 및 메모리 초기화\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\n🧹 GPU 메모리 초기화 완료\")\n",
        "    print(\"🔍 초기화 후 GPU 메모리 상태:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"❌ CUDA 사용 불가\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxuQLgBAmkIm",
        "outputId": "3d51c253-72a5-4582-8a0c-0017e7d0dbff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 초기화 전 GPU 메모리 상태:\n",
            "📊 현재 GPU 메모리 상태: Allocated = 113.37 MB | Reserved = 136.00 MB\n",
            "\n",
            "🧹 GPU 메모리 초기화 완료\n",
            "🔍 초기화 후 GPU 메모리 상태:\n",
            "📊 현재 GPU 메모리 상태: Allocated = 113.37 MB | Reserved = 136.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CarImageDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # 🚗 Step 1: Load Image (RGB 고정)\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        # 🚗 Step 2: Apply Transform (Augmentation or Normalize)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 🚗 Step 3: Extract label (CLASS_NAME)\n",
        "        class_name = os.path.basename(os.path.dirname(path))\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "rtI0lYOuJZt5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# ✅ 전체 JPG 파일 불러오기 (Train) → 경로 수정!\n",
        "file_list = glob.glob('/content/train/*/*.jpg')\n",
        "\n",
        "# ✅ 클래스명 추출 (폴더명)\n",
        "def extract_class_name_jpg(path):\n",
        "    return os.path.basename(os.path.dirname(path))\n",
        "\n",
        "class_names = sorted(set(extract_class_name_jpg(f) for f in file_list))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"✅ 클래스 수: {len(class_to_idx)}\")  # 396개 나와야 정상\n",
        "\n",
        "# ✅ 라벨 생성\n",
        "labels = [class_to_idx[extract_class_name_jpg(f)] for f in file_list]\n",
        "\n",
        "# ✅ Train/Val Split\n",
        "train_files, val_files = train_test_split(file_list, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "# ✅ Transform 정의\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ✅ Dataset 클래스\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CarJPGDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        class_name = extract_class_name_jpg(path)\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# ✅ Dataset 정의\n",
        "train_dataset = CarJPGDataset(train_files, class_to_idx, train_transform)\n",
        "val_dataset = CarJPGDataset(val_files, class_to_idx, val_transform)\n",
        "\n",
        "# ✅ DataLoader 정의\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "u2DB9tCSJcmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f9a46a-46a9-426f-de0f-0ac0e43ff3f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 클래스 수: 396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tNalQaGrKS5u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AdamW + weight_decay 추가 추천 (EffNet 계열에 많이 사용)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "JNIgNO9AKcl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import copy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# ✅ device 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ 전체 jpg 파일\n",
        "file_list = glob.glob('/content/train/*/*.jpg')\n",
        "\n",
        "# ✅ 클래스명 추출\n",
        "def extract_class_name_jpg(path):\n",
        "    return os.path.basename(os.path.dirname(path))\n",
        "\n",
        "class_names = sorted(set(extract_class_name_jpg(f) for f in file_list))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"✅ 클래스 수: {len(class_to_idx)}\")\n",
        "\n",
        "# ✅ 라벨 생성\n",
        "labels = [class_to_idx[extract_class_name_jpg(f)] for f in file_list]\n",
        "\n",
        "# ✅ transform 정의\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ✅ Dataset 클래스 정의 (JPG용)\n",
        "class CarJPGDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        class_name = extract_class_name_jpg(path)\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# ✅ StratifiedKFold 정의\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ✅ 5-Fold 루프 시작\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(file_list, labels)):\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"🔁 Fold {fold + 1} / 5\")\n",
        "    print(f\"==============================\\n\")\n",
        "\n",
        "    # ✅ Fold별 split\n",
        "    train_files = [file_list[i] for i in train_idx]\n",
        "    val_files = [file_list[i] for i in val_idx]\n",
        "\n",
        "    # ✅ Fold별 Dataset & DataLoader\n",
        "    train_dataset = CarJPGDataset(train_files, class_to_idx, train_transform)\n",
        "    val_dataset = CarJPGDataset(val_files, class_to_idx, val_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "    # ✅ Fold별 model / criterion / optimizer 초기화\n",
        "    model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    # ✅ EarlyStopping 변수 초기화\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # ✅ Epoch 루프\n",
        "    for epoch in range(1, 31):\n",
        "        print(f\"\\n📌 Fold {fold+1} | Epoch {epoch}\")\n",
        "\n",
        "        # === 학습 ===\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Train Fold {fold+1}\", leave=False)\n",
        "        for X, y in loop:\n",
        "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * X.size(0)\n",
        "            train_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        # === 검증 ===\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "\n",
        "        val_loop = tqdm(val_loader, desc=f\"Valid Fold {fold+1}\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loop:\n",
        "                X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "                outputs = model(X)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "                val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # === 로그 출력 ===\n",
        "        print(f\"✅ Fold {fold+1} | Epoch {epoch} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "        print(f\"✅ Fold {fold+1} | Epoch {epoch} | Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # === EarlyStopping ===\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            save_path = f\"/content/drive/MyDrive/team_models/EffNetB5_fold{fold+1}.pth\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"📦 Best model saved for Fold {fold+1}!\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"⚠️ EarlyStopping patience: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(\"⛔ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # ✅ Fold 끝나고 Best 모델 로드\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print(f\"✅ Fold {fold+1} Best model loaded.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZJkMSSKeiG",
        "outputId": "729ffb29-b31d-497c-8ae2-58adaa420657"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 클래스 수: 396\n",
            "\n",
            "==============================\n",
            "🔁 Fold 1 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 1 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 1 | Train Loss: 2.0615 | Acc: 0.5875\n",
            "✅ Fold 1 | Epoch 1 | Val   Loss: 0.3311 | Acc: 0.8953\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 2 | Train Loss: 0.2802 | Acc: 0.9170\n",
            "✅ Fold 1 | Epoch 2 | Val   Loss: 0.2141 | Acc: 0.9286\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 3 | Train Loss: 0.1840 | Acc: 0.9404\n",
            "✅ Fold 1 | Epoch 3 | Val   Loss: 0.2265 | Acc: 0.9335\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 1 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 4 | Train Loss: 0.1458 | Acc: 0.9522\n",
            "✅ Fold 1 | Epoch 4 | Val   Loss: 0.2448 | Acc: 0.9301\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 1 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 5 | Train Loss: 0.1334 | Acc: 0.9570\n",
            "✅ Fold 1 | Epoch 5 | Val   Loss: 0.1665 | Acc: 0.9513\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 6 | Train Loss: 0.1132 | Acc: 0.9631\n",
            "✅ Fold 1 | Epoch 6 | Val   Loss: 0.1809 | Acc: 0.9461\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 1 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 7 | Train Loss: 0.1058 | Acc: 0.9667\n",
            "✅ Fold 1 | Epoch 7 | Val   Loss: 0.1613 | Acc: 0.9519\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 8 | Train Loss: 0.0967 | Acc: 0.9697\n",
            "✅ Fold 1 | Epoch 8 | Val   Loss: 0.1443 | Acc: 0.9564\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 9 | Train Loss: 0.0885 | Acc: 0.9718\n",
            "✅ Fold 1 | Epoch 9 | Val   Loss: 0.1814 | Acc: 0.9520\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 1 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 10 | Train Loss: 0.0816 | Acc: 0.9747\n",
            "✅ Fold 1 | Epoch 10 | Val   Loss: 0.1787 | Acc: 0.9508\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 1 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 11 | Train Loss: 0.0766 | Acc: 0.9757\n",
            "✅ Fold 1 | Epoch 11 | Val   Loss: 0.1550 | Acc: 0.9561\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 1 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 2 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 2 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 1 | Train Loss: 1.9681 | Acc: 0.6030\n",
            "✅ Fold 2 | Epoch 1 | Val   Loss: 0.3350 | Acc: 0.8950\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 2 | Train Loss: 0.2807 | Acc: 0.9153\n",
            "✅ Fold 2 | Epoch 2 | Val   Loss: 0.2455 | Acc: 0.9240\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 3 | Train Loss: 0.1769 | Acc: 0.9432\n",
            "✅ Fold 2 | Epoch 3 | Val   Loss: 0.2056 | Acc: 0.9386\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 4 | Train Loss: 0.1500 | Acc: 0.9515\n",
            "✅ Fold 2 | Epoch 4 | Val   Loss: 0.2226 | Acc: 0.9369\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 5 | Train Loss: 0.1269 | Acc: 0.9586\n",
            "✅ Fold 2 | Epoch 5 | Val   Loss: 0.1973 | Acc: 0.9467\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 6 | Train Loss: 0.1167 | Acc: 0.9622\n",
            "✅ Fold 2 | Epoch 6 | Val   Loss: 0.1991 | Acc: 0.9445\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 7 | Train Loss: 0.1070 | Acc: 0.9655\n",
            "✅ Fold 2 | Epoch 7 | Val   Loss: 0.1579 | Acc: 0.9516\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 8 | Train Loss: 0.0899 | Acc: 0.9713\n",
            "✅ Fold 2 | Epoch 8 | Val   Loss: 0.1736 | Acc: 0.9498\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 9 | Train Loss: 0.0840 | Acc: 0.9725\n",
            "✅ Fold 2 | Epoch 9 | Val   Loss: 0.1472 | Acc: 0.9588\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 10 | Train Loss: 0.0847 | Acc: 0.9724\n",
            "✅ Fold 2 | Epoch 10 | Val   Loss: 0.1822 | Acc: 0.9528\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 11 | Train Loss: 0.0811 | Acc: 0.9727\n",
            "✅ Fold 2 | Epoch 11 | Val   Loss: 0.1875 | Acc: 0.9464\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 2 | Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 12 | Train Loss: 0.0759 | Acc: 0.9757\n",
            "✅ Fold 2 | Epoch 12 | Val   Loss: 0.2044 | Acc: 0.9523\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 2 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 3 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 3 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 1 | Train Loss: 1.9614 | Acc: 0.6133\n",
            "✅ Fold 3 | Epoch 1 | Val   Loss: 0.3429 | Acc: 0.8929\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 2 | Train Loss: 0.2707 | Acc: 0.9178\n",
            "✅ Fold 3 | Epoch 2 | Val   Loss: 0.2313 | Acc: 0.9282\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 3 | Train Loss: 0.1725 | Acc: 0.9450\n",
            "✅ Fold 3 | Epoch 3 | Val   Loss: 0.2562 | Acc: 0.9255\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 3 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 4 | Train Loss: 0.1406 | Acc: 0.9553\n",
            "✅ Fold 3 | Epoch 4 | Val   Loss: 0.2290 | Acc: 0.9333\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 5 | Train Loss: 0.1332 | Acc: 0.9573\n",
            "✅ Fold 3 | Epoch 5 | Val   Loss: 0.1838 | Acc: 0.9467\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 6 | Train Loss: 0.1132 | Acc: 0.9629\n",
            "✅ Fold 3 | Epoch 6 | Val   Loss: 0.1911 | Acc: 0.9439\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 3 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 7 | Train Loss: 0.1065 | Acc: 0.9658\n",
            "✅ Fold 3 | Epoch 7 | Val   Loss: 0.1763 | Acc: 0.9534\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 8 | Train Loss: 0.0923 | Acc: 0.9702\n",
            "✅ Fold 3 | Epoch 8 | Val   Loss: 0.2087 | Acc: 0.9476\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 3 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 9 | Train Loss: 0.0900 | Acc: 0.9707\n",
            "✅ Fold 3 | Epoch 9 | Val   Loss: 0.1570 | Acc: 0.9565\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 10 | Train Loss: 0.0874 | Acc: 0.9724\n",
            "✅ Fold 3 | Epoch 10 | Val   Loss: 0.1662 | Acc: 0.9532\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 3 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 11 | Train Loss: 0.0770 | Acc: 0.9750\n",
            "✅ Fold 3 | Epoch 11 | Val   Loss: 0.1665 | Acc: 0.9540\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 3 | Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 12 | Train Loss: 0.0670 | Acc: 0.9779\n",
            "✅ Fold 3 | Epoch 12 | Val   Loss: 0.1698 | Acc: 0.9549\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 3 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 4 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 4 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 1 | Train Loss: 1.9470 | Acc: 0.6087\n",
            "✅ Fold 4 | Epoch 1 | Val   Loss: 0.3522 | Acc: 0.8960\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 2 | Train Loss: 0.2785 | Acc: 0.9147\n",
            "✅ Fold 4 | Epoch 2 | Val   Loss: 0.2645 | Acc: 0.9211\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 3 | Train Loss: 0.1811 | Acc: 0.9425\n",
            "✅ Fold 4 | Epoch 3 | Val   Loss: 0.2256 | Acc: 0.9330\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 4 | Train Loss: 0.1473 | Acc: 0.9515\n",
            "✅ Fold 4 | Epoch 4 | Val   Loss: 0.2039 | Acc: 0.9419\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 5 | Train Loss: 0.1259 | Acc: 0.9588\n",
            "✅ Fold 4 | Epoch 5 | Val   Loss: 0.1749 | Acc: 0.9501\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 6 | Train Loss: 0.1163 | Acc: 0.9617\n",
            "✅ Fold 4 | Epoch 6 | Val   Loss: 0.1834 | Acc: 0.9473\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 4 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 7 | Train Loss: 0.1008 | Acc: 0.9673\n",
            "✅ Fold 4 | Epoch 7 | Val   Loss: 0.1764 | Acc: 0.9516\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 4 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 8 | Train Loss: 0.0976 | Acc: 0.9681\n",
            "✅ Fold 4 | Epoch 8 | Val   Loss: 0.1607 | Acc: 0.9543\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 9 | Train Loss: 0.0957 | Acc: 0.9686\n",
            "✅ Fold 4 | Epoch 9 | Val   Loss: 0.1667 | Acc: 0.9534\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 4 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 10 | Train Loss: 0.0779 | Acc: 0.9733\n",
            "✅ Fold 4 | Epoch 10 | Val   Loss: 0.1808 | Acc: 0.9547\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 4 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 11 | Train Loss: 0.0780 | Acc: 0.9753\n",
            "✅ Fold 4 | Epoch 11 | Val   Loss: 0.1692 | Acc: 0.9559\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 4 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 5 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 5 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 1 | Train Loss: 1.9365 | Acc: 0.6128\n",
            "✅ Fold 5 | Epoch 1 | Val   Loss: 0.3256 | Acc: 0.8987\n",
            "📦 Best model saved for Fold 5!\n",
            "\n",
            "📌 Fold 5 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 2 | Train Loss: 0.2752 | Acc: 0.9161\n",
            "✅ Fold 5 | Epoch 2 | Val   Loss: 0.2435 | Acc: 0.9255\n",
            "📦 Best model saved for Fold 5!\n",
            "\n",
            "📌 Fold 5 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 3 | Train Loss: 0.1774 | Acc: 0.9422\n",
            "✅ Fold 5 | Epoch 3 | Val   Loss: 0.2121 | Acc: 0.9325\n",
            "📦 Best model saved for Fold 5!\n",
            "\n",
            "📌 Fold 5 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 4 | Train Loss: 0.1448 | Acc: 0.9528\n",
            "✅ Fold 5 | Epoch 4 | Val   Loss: 0.1811 | Acc: 0.9436\n",
            "📦 Best model saved for Fold 5!\n",
            "\n",
            "📌 Fold 5 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 5 | Train Loss: 0.1266 | Acc: 0.9593\n",
            "✅ Fold 5 | Epoch 5 | Val   Loss: 0.1842 | Acc: 0.9485\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 5 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 6 | Train Loss: 0.1114 | Acc: 0.9634\n",
            "✅ Fold 5 | Epoch 6 | Val   Loss: 0.1884 | Acc: 0.9445\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 5 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 7 | Train Loss: 0.1050 | Acc: 0.9650\n",
            "✅ Fold 5 | Epoch 7 | Val   Loss: 0.1713 | Acc: 0.9499\n",
            "📦 Best model saved for Fold 5!\n",
            "\n",
            "📌 Fold 5 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 8 | Train Loss: 0.1002 | Acc: 0.9680\n",
            "✅ Fold 5 | Epoch 8 | Val   Loss: 0.1670 | Acc: 0.9491\n",
            "📦 Best model saved for Fold 5!\n",
            "\n",
            "📌 Fold 5 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 9 | Train Loss: 0.0802 | Acc: 0.9731\n",
            "✅ Fold 5 | Epoch 9 | Val   Loss: 0.1696 | Acc: 0.9508\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 5 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 10 | Train Loss: 0.0842 | Acc: 0.9727\n",
            "✅ Fold 5 | Epoch 10 | Val   Loss: 0.1773 | Acc: 0.9520\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 5 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 5 | Epoch 11 | Train Loss: 0.0749 | Acc: 0.9752\n",
            "✅ Fold 5 | Epoch 11 | Val   Loss: 0.1852 | Acc: 0.9531\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 5 Best model loaded.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 앙상블 Inference 예시 (5개 모델 평균 - JPG용)\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 설정\n",
        "FOLD_MODEL_PATHS = [\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold1.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold2.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold3.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold4.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold5.pth\",\n",
        "]\n",
        "\n",
        "TEST_DIR = \"/content/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/sample_submission.csv\"\n",
        "SAVE_SUBMISSION_PATH = \"/content/drive/MyDrive/team_models/submission_fold5_ensemble.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# 샘플 제출 파일에서 클래스명 추출\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' 제외\n",
        "\n",
        "# ✅ Transform (JPG용)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ✅ 테스트용 Dataset (JPG용)\n",
        "class TestJPGDataset(Dataset):\n",
        "    def __init__(self, img_root, transform=None):\n",
        "        self.file_list = []\n",
        "        for file in os.listdir(img_root):\n",
        "            if file.endswith('.jpg'):\n",
        "                self.file_list.append(os.path.join(img_root, file))\n",
        "        self.file_list.sort()  # 반드시 정렬 (TEST_00001.jpg → TEST_00002.jpg ...)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "        return image, fname\n",
        "\n",
        "# ✅ DataLoader\n",
        "test_dataset = TestJPGDataset(TEST_DIR, transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=4\n",
        ")\n",
        "\n",
        "# ✅ 앙상블 결과 초기화\n",
        "ensemble_outputs = []\n",
        "\n",
        "# ✅ 각 Fold 모델 순서대로 추론\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for fold_idx, model_path in enumerate(FOLD_MODEL_PATHS):\n",
        "    print(f\"\\n🚀 Inference with Fold {fold_idx + 1} Model: {model_path}\")\n",
        "\n",
        "    # 모델 로드\n",
        "    model = timm.create_model('efficientnet_b5', pretrained=False, num_classes=NUM_CLASSES)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # fold별 output 저장\n",
        "    fold_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in tqdm(test_loader, desc=f\"🔍 Fold {fold_idx + 1} Inference\"):\n",
        "            imgs = imgs.to(device)\n",
        "            outputs = model(imgs)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "    fold_probs = np.concatenate(fold_probs, axis=0)\n",
        "    ensemble_outputs.append(fold_probs)\n",
        "\n",
        "# ✅ 앙상블 평균\n",
        "ensemble_outputs = np.stack(ensemble_outputs, axis=0)  # (num_folds, num_samples, num_classes)\n",
        "mean_outputs = np.mean(ensemble_outputs, axis=0)       # (num_samples, num_classes)\n",
        "\n",
        "# ✅ 결과 저장\n",
        "results = []\n",
        "for idx, path in enumerate(test_dataset.file_list):\n",
        "    fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "    row = {\"ID\": fname}\n",
        "    row.update({class_name: mean_outputs[idx, i] for i, class_name in enumerate(column_names)})\n",
        "    results.append(row)\n",
        "\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "submission_df.to_csv(SAVE_SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"\\n✅ 앙상블 서브미션 저장 완료: {SAVE_SUBMISSION_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "k61x77gkNSDG",
        "outputId": "ee5b24a5-448c-4d07-b594-6211fd64b1f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_submission.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c55a3c26f451>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# 샘플 제출 파일에서 클래스명 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSAMPLE_SUB_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 'ID' 제외\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_submission.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 다운로드할 경로 지정 (네가 저장한 경로 그대로 사용!)\n",
        "files.download('/content/drive/MyDrive/team_models/submission_fold5_ensemble.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "G8IEkAgaXKJ0",
        "outputId": "95157bc0-1070-455c-a569-41dc31652cd8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e22e2f4f-ff35-49f3-9404-ed6203424540\", \"submission_fold5_ensemble.csv\", 44649632)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블이랑 TTA 적용한 것\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "# 설정\n",
        "FOLD_MODEL_PATHS = [\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold1.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold2.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold3.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold4.pth\",\n",
        "    \"/content/drive/MyDrive/team_models/EffNetB5_fold5.pth\",\n",
        "]\n",
        "\n",
        "TEST_DIR = \"/content/drive/MyDrive/open/clean_test/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/drive/MyDrive/open/sample_submission.csv\"\n",
        "SAVE_SUBMISSION_PATH = \"/content/drive/MyDrive/team_models/submission_fold5_tta.csv\"\n",
        "NUM_CLASSES = 396\n",
        "TTA_TIMES = 3   # ✅ TTA 반복 횟수 (가볍게 3~5 추천)\n",
        "\n",
        "# 샘플 제출 파일에서 클래스명 추출\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' 제외\n",
        "\n",
        "# ✅ Transform 정의 (여기서 TTA용 transform을 리스트로 만들 예정)\n",
        "# 기본 Normalize\n",
        "base_transform = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                      std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# ✅ TTA용 transform list\n",
        "tta_transforms = [\n",
        "    transforms.Compose([base_transform]),  # 원본\n",
        "    transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=1.0),  # Flip\n",
        "        base_transform\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "        base_transform\n",
        "    ]),\n",
        "    # 필요시 더 추가 가능 (주의: 과하면 성능 저하)\n",
        "]\n",
        "\n",
        "# ✅ 테스트용 Dataset\n",
        "class TestNPYDataset(Dataset):\n",
        "    def __init__(self, npy_root):\n",
        "        self.file_list = []\n",
        "        for root, dirs, files in os.walk(npy_root):\n",
        "            for file in files:\n",
        "                if file.endswith('.npy'):\n",
        "                    self.file_list.append(os.path.join(root, file))\n",
        "        self.file_list.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = np.load(path, mmap_mode='r').copy()\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image = image.repeat(3, 1, 1)\n",
        "        image = image.contiguous()\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".npy\", \"\")\n",
        "        return image, fname\n",
        "\n",
        "# ✅ DataLoader 고정\n",
        "test_dataset = TestNPYDataset(TEST_DIR)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=4\n",
        ")\n",
        "\n",
        "# ✅ 전체 Fold 앙상블 결과 초기화\n",
        "ensemble_outputs = []\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ Fold별 모델 반복\n",
        "for fold_idx, model_path in enumerate(FOLD_MODEL_PATHS):\n",
        "    print(f\"\\n🚀 Inference with Fold {fold_idx + 1} Model: {model_path}\")\n",
        "\n",
        "    # 모델 로드\n",
        "    model = timm.create_model('efficientnet_b5', pretrained=False, num_classes=NUM_CLASSES)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Fold별 output 저장\n",
        "    fold_probs = []\n",
        "\n",
        "    # ✅ TTA 반복\n",
        "    for tta_idx in range(TTA_TIMES):\n",
        "        print(f\"📢 TTA Round {tta_idx + 1} / {TTA_TIMES} for Fold {fold_idx + 1}\")\n",
        "\n",
        "        # TTA transform 선택 (순환)\n",
        "        tta_transform = tta_transforms[tta_idx % len(tta_transforms)]\n",
        "\n",
        "        # fold + TTA round별 확률 저장\n",
        "        tta_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, names in tqdm(test_loader, desc=f\"🔍 Fold {fold_idx + 1} | TTA {tta_idx + 1}\"):\n",
        "                imgs = imgs.to(device)\n",
        "                # ✅ transform 적용\n",
        "                imgs = torch.stack([tta_transform(img) for img in imgs])\n",
        "\n",
        "                outputs = model(imgs)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                tta_probs.append(probs.cpu().numpy())\n",
        "\n",
        "        # TTA 결과 저장\n",
        "        tta_probs = np.concatenate(tta_probs, axis=0)\n",
        "        fold_probs.append(tta_probs)\n",
        "\n",
        "    # ✅ Fold 내 TTA 평균\n",
        "    fold_probs = np.stack(fold_probs, axis=0)      # (tta_times, num_samples, num_classes)\n",
        "    fold_mean_probs = np.mean(fold_probs, axis=0)  # (num_samples, num_classes)\n",
        "\n",
        "    # ✅ Fold 결과 → ensemble list 추가\n",
        "    ensemble_outputs.append(fold_mean_probs)\n",
        "\n",
        "# ✅ Fold 앙상블 평균\n",
        "ensemble_outputs = np.stack(ensemble_outputs, axis=0)  # (num_folds, num_samples, num_classes)\n",
        "mean_outputs = np.mean(ensemble_outputs, axis=0)       # (num_samples, num_classes)\n",
        "\n",
        "# ✅ 최종 결과 저장\n",
        "results = []\n",
        "for idx, path in enumerate(test_dataset.file_list):\n",
        "    fname = os.path.basename(path).replace(\".npy\", \"\")\n",
        "    row = {\"ID\": fname}\n",
        "    row.update({class_name: mean_outputs[idx, i] for i, class_name in enumerate(column_names)})\n",
        "    results.append(row)\n",
        "\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "submission_df.to_csv(SAVE_SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"\\n✅ Fold 앙상블 + TTA 서브미션 저장 완료: {SAVE_SUBMISSION_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTFwTq3EDmDG",
        "outputId": "420b606b-6df7-427c-85f2-da0eed894443"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Inference with Fold 1 Model: /content/drive/MyDrive/team_models/EffNetB5_fold1.pth\n",
            "📢 TTA Round 1 / 3 for Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 1 | TTA 1: 100%|██████████| 130/130 [06:22<00:00,  2.94s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 2 / 3 for Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 1 | TTA 2: 100%|██████████| 130/130 [00:30<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 3 / 3 for Fold 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 1 | TTA 3: 100%|██████████| 130/130 [00:30<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Inference with Fold 2 Model: /content/drive/MyDrive/team_models/EffNetB5_fold2.pth\n",
            "📢 TTA Round 1 / 3 for Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 2 | TTA 1: 100%|██████████| 130/130 [00:30<00:00,  4.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 2 / 3 for Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 2 | TTA 2: 100%|██████████| 130/130 [00:30<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 3 / 3 for Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 2 | TTA 3: 100%|██████████| 130/130 [00:30<00:00,  4.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Inference with Fold 3 Model: /content/drive/MyDrive/team_models/EffNetB5_fold3.pth\n",
            "📢 TTA Round 1 / 3 for Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 3 | TTA 1: 100%|██████████| 130/130 [00:30<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 2 / 3 for Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 3 | TTA 2: 100%|██████████| 130/130 [00:30<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 3 / 3 for Fold 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 3 | TTA 3: 100%|██████████| 130/130 [00:30<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Inference with Fold 4 Model: /content/drive/MyDrive/team_models/EffNetB5_fold4.pth\n",
            "📢 TTA Round 1 / 3 for Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 4 | TTA 1: 100%|██████████| 130/130 [00:30<00:00,  4.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 2 / 3 for Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 4 | TTA 2: 100%|██████████| 130/130 [00:30<00:00,  4.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 3 / 3 for Fold 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 4 | TTA 3: 100%|██████████| 130/130 [00:30<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 Inference with Fold 5 Model: /content/drive/MyDrive/team_models/EffNetB5_fold5.pth\n",
            "📢 TTA Round 1 / 3 for Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 5 | TTA 1: 100%|██████████| 130/130 [00:30<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 2 / 3 for Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 5 | TTA 2: 100%|██████████| 130/130 [00:30<00:00,  4.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📢 TTA Round 3 / 3 for Fold 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Fold 5 | TTA 3: 100%|██████████| 130/130 [00:30<00:00,  4.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Fold 앙상블 + TTA 서브미션 저장 완료: /content/drive/MyDrive/team_models/submission_fold5_tta.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 다운로드할 경로 지정 (네가 저장한 경로 그대로 사용!)\n",
        "files.download('/content/drive/MyDrive/team_models/submission_fold5_tta.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "A4xDSAPU8O2h",
        "outputId": "46377599-0a5c-4a5e-9310-e32f4d17d5e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_927c34d9-ea9f-4770-b6bd-8d685dae03db\", \"submission_fold5_tta.csv\", 43583361)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}