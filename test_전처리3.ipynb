{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1B75A0nd3Ud9LN9u_qemX6Uy1b3ObwznA",
      "authorship_tag": "ABX9TyOlL5BsX47/ce4aj1gtht2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/test_%EC%A0%84%EC%B2%98%EB%A6%AC3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peaMNLWchXQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juS4rlAhexwK",
        "outputId": "dfafcc6d-aed5-4622-9470-dcddca01abe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF"
      ],
      "metadata": {
        "id": "eyLBp4j3i6F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ì„¤ì • =====\n",
        "test_csv_path = '/content/drive/MyDrive/open/test.csv'\n",
        "test_img_dir = '/content/drive/MyDrive/open/test'  # test ì´ë¯¸ì§€ í´ë”\n",
        "save_root = '/content/drive/MyDrive/fuck/preprocessed_test'  # test ì „ì²˜ë¦¬ ì €ì¥ ìœ„ì¹˜\n",
        "os.makedirs(save_root, exist_ok=True)"
      ],
      "metadata": {
        "id": "Ybtf0x5si9CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Grayscale + Resize transform ì •ì˜\n",
        "# class SquarePad:\n",
        "#     def __call__(self, image):\n",
        "#         w, h = image.size\n",
        "#         max_wh = max(w, h)\n",
        "#         pad_left = (max_wh - w) // 2\n",
        "#         pad_top = (max_wh - h) // 2\n",
        "#         padding = (pad_left, pad_top, max_wh - w - pad_left, max_wh - h - pad_top)\n",
        "#         return TF.pad(image, padding, fill=0)\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Grayscale(num_output_channels=1),\n",
        "#     SquarePad(),\n",
        "#     transforms.Resize((384, 384)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.5], [0.5])\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "Dxb4JBcejAnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ===== Test CSV ì½ê¸° =====\n",
        "# test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# # âœ… ìˆ˜ì •ëœ ë¶€ë¶„: img_pathì—ì„œ íŒŒì¼ëª…ë§Œ ì¶”ì¶œ\n",
        "# test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.basename(x))\n",
        "# test_df['full_img_path'] = test_df['img_path'].apply(lambda x: os.path.join(test_img_dir, x))\n",
        "# test_df['img_name_no_ext'] = test_df['img_path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])  # 'TEST_00000'\n",
        "\n",
        "# # ===== ì „ì²˜ë¦¬ ì‹œì‘ =====\n",
        "# counter = 0  # ì „ì²´ ì´ë¯¸ì§€ ì¹´ìš´í„°\n",
        "# batch_index = 0  # batch_000, batch_001...\n",
        "# batch_limit = 800  # í•œ í´ë”ì— ì €ì¥í•  ìµœëŒ€ ê°œìˆ˜\n",
        "\n",
        "# current_batch_dir = os.path.join(save_root, f\"batch_{batch_index:03}\")\n",
        "# os.makedirs(current_batch_dir, exist_ok=True)\n",
        "\n",
        "# print(\"ğŸ“¦ Test ì „ì²˜ë¦¬ ì‹œì‘...\")\n",
        "\n",
        "# for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "#     img_id = row['img_name_no_ext']  # TEST_00000\n",
        "#     img_path = row['full_img_path']\n",
        "\n",
        "#     try:\n",
        "#         img = Image.open(img_path).convert('RGB')\n",
        "#         img_tensor = transform(img)\n",
        "\n",
        "#         # í´ë” ë¶„í•  ì¡°ê±´\n",
        "#         if counter > 0 and counter % batch_limit == 0:\n",
        "#             batch_index += 1\n",
        "#             current_batch_dir = os.path.join(save_root, f\"batch_{batch_index:03}\")\n",
        "#             os.makedirs(current_batch_dir, exist_ok=True)\n",
        "\n",
        "#         # ì €ì¥ íŒŒì¼ëª…: TEST_00000.npy\n",
        "#         save_name = f\"{img_id}.npy\"\n",
        "#         save_path = os.path.join(current_batch_dir, save_name)\n",
        "#         np.save(save_path, img_tensor.numpy())\n",
        "\n",
        "#         counter += 1\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"âŒ ì˜¤ë¥˜: {img_path} â†’ {e}\")\n",
        "\n",
        "# print(f\"âœ… Test ì „ì²˜ë¦¬ ì™„ë£Œ: ì´ {counter}ê°œ ì´ë¯¸ì§€ ì €ì¥ë¨\")\n",
        "# print(f\"ğŸ“‚ ë°°ì¹˜ í´ë” ìˆ˜: {batch_index + 1}\")"
      ],
      "metadata": {
        "id": "SqM_vaNwjLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # ğŸš— Testìš© npy íŒŒì¼ ê²½ë¡œ (ì˜ˆì‹œ)\n",
        "# npy_path = '/content/drive/MyDrive/fuck/preprocessed_test/batch_000/TEST_00000.npy'\n",
        "\n",
        "# # npy ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "# img = np.load(npy_path)\n",
        "\n",
        "# # (1, H, W) â†’ (H, W)\n",
        "# if img.shape[0] == 1:\n",
        "#     img = img.squeeze(0)\n",
        "\n",
        "# # ì‹œê°í™”\n",
        "# plt.imshow(img, cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.title(\"Test Grayscale ì‹œê°í™”\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "spSREKsVZ9R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# # Test JPG íŒŒì¼ ìˆ˜ í™•ì¸\n",
        "# jpg_count = 0\n",
        "# jpg_paths = []\n",
        "\n",
        "# test_dir = '/content/drive/MyDrive/open/test'\n",
        "# for file in os.listdir(test_dir):\n",
        "#     if file.lower().endswith('.jpg'):\n",
        "#         jpg_count += 1\n",
        "#         jpg_paths.append(file)  # íŒŒì¼ëª…ë§Œ ì €ì¥ (TEST_00000.jpg ë“±)\n",
        "\n",
        "# print(f\"âœ… Test í´ë” ë‚´ JPG íŒŒì¼ ìˆ˜: {jpg_count}\")\n",
        "\n",
        "# # ì „ì²˜ë¦¬ëœ .npy íŒŒì¼ ìˆ˜ í™•ì¸\n",
        "# npy_dir = '/content/drive/MyDrive/fuck/preprocessed_test'\n",
        "# npy_count = 0\n",
        "# npy_files = []\n",
        "\n",
        "# # ëª¨ë“  í•˜ìœ„ í´ë”ê¹Œì§€ íƒìƒ‰\n",
        "# for root, dirs, files in os.walk(npy_dir):\n",
        "#     for file in files:\n",
        "#         if file.endswith('.npy'):\n",
        "#             npy_count += 1\n",
        "#             npy_files.append(os.path.join(root, file))\n",
        "\n",
        "# print(f\"âœ… ì €ì¥ëœ .npy íŒŒì¼ ìˆ˜: {npy_count}\")\n",
        "\n",
        "# # â›” ì¤‘ë³µ ë˜ëŠ” ì¶”ê°€ íŒŒì¼ ì˜ì‹¬ í™•ì¸\n",
        "# # jpg_paths = ['TEST_00000.jpg', ...] â†’ ëŒ€ì‘ë˜ëŠ” npyëŠ” 'TEST_00000.npy'\n",
        "# expected_npy_names = set([os.path.splitext(f)[0] + '.npy' for f in jpg_paths])\n",
        "# actual_npy_names = set([os.path.basename(f) for f in npy_files])\n",
        "\n",
        "# extra = actual_npy_names - expected_npy_names\n",
        "# missing = expected_npy_names - actual_npy_names\n",
        "\n",
        "# if len(extra) == 0 and len(missing) == 0:\n",
        "#     print(\"âœ… ëª¨ë“  íŒŒì¼ ì •ìƒ! JPG â†” npy ê°œìˆ˜ ë° ì´ë¦„ ì¼ì¹˜ ğŸ‰\")\n",
        "# else:\n",
        "#     print(f\"âš ï¸ ì˜ì‹¬ë˜ëŠ” ì¶”ê°€ ì €ì¥ íŒŒì¼ ìˆ˜: {len(extra)}\")\n",
        "#     print(\"ì˜ˆì‹œ íŒŒì¼ (extra):\", list(extra)[:5])\n",
        "#     print(f\"âš ï¸ ëˆ„ë½ëœ ì˜ˆìƒ íŒŒì¼ ìˆ˜: {len(missing)}\")\n",
        "#     print(\"ì˜ˆì‹œ íŒŒì¼ (missing):\", list(missing)[:5])\n"
      ],
      "metadata": {
        "id": "hcIid1rQ4fCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=396)\n",
        "print(model.default_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95uHM81tFoKn",
        "outputId": "07aeaad4-dc81-476c-c1de-576e0fcf8ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'url': '', 'hf_hub_id': 'timm/convnext_tiny.in12k_ft_in1k', 'architecture': 'convnext_tiny', 'tag': 'in12k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'test_input_size': (3, 288, 288), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_crop_pct': 1.0, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'stem.0', 'classifier': 'head.fc'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model.default_cfg)\n"
      ],
      "metadata": {
        "id": "IZ9btXdawzHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… 1ï¸âƒ£ ëª¨ë¸ ë§Œë“¤ê³  default_cfg í™•ì¸ (ì°¸ê³ ìš©)\n",
        "model = timm.create_model(\n",
        "    'convnext_tiny',\n",
        "    pretrained=True,\n",
        "    num_classes=396,\n",
        "    in_chans=1\n",
        ")\n",
        "\n",
        "# ì°¸ê³ ìš© ì¶œë ¥ (í•„ìˆ˜ëŠ” ì•„ë‹˜ â€” ê·¸ëƒ¥ í™•ì¸)\n",
        "print(model.default_cfg)\n",
        "\n",
        "# âœ… 2ï¸âƒ£ transformì€ ì´ë¯¸ ë‚´ê°€ ì“¸ ê±¸ ì •í–ˆìŒ (Grayscale + 384)\n",
        "# ê·¸ëŒ€ë¡œ ì‚¬ìš© (default_cfgì— mean/stdê°€ ìˆì–´ë„, ìš°ë¦¬ëŠ” [0.5], [0.5] ì”€ â†’ ì¼ì¹˜í•  í•„ìš” ì—†ìŒ)\n",
        "\n",
        "# âœ… 3ï¸âƒ£ DataLoader êµ¬ì„± â†’ í•™ìŠµ ì‹œì‘\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw2hgcRXz0ck",
        "outputId": "4878131a-5912-4995-f246-4b00e41d9292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'url': '', 'hf_hub_id': 'timm/convnext_tiny.in12k_ft_in1k', 'architecture': 'convnext_tiny', 'tag': 'in12k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'test_input_size': (3, 288, 288), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_crop_pct': 1.0, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'stem.0', 'classifier': 'head.fc'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB ë‹¨ìœ„\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB ë‹¨ìœ„\n",
        "    print(f\"ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# í˜„ì¬ CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "if torch.cuda.is_available():\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU ìºì‹œ ë° ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\nğŸ§¹ GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"âŒ CUDA ì‚¬ìš© ë¶ˆê°€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bH_WHzciHHx",
        "outputId": "8566d5d5-aa4a-4940-9419-80f8852439da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” ì´ˆê¸°í™” ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = 0.00 MB | Reserved = 0.00 MB\n",
            "\n",
            "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\n",
            "ğŸ” ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = 0.00 MB | Reserved = 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def extract_class_name(fname):\n",
        "    # '1ì‹œë¦¬ì¦ˆ_F20_2013_2015_000123.npy' â†’ '1ì‹œë¦¬ì¦ˆ_F20_2013_2015'\n",
        "    return '_'.join(os.path.basename(fname).replace('.npy', '').split('_')[:-1])\n",
        "\n",
        "all_npy_files = glob.glob('/content/drive/MyDrive/fuck/preprocessed/batch_*/**/*.npy', recursive=True)\n",
        "class_names = sorted(set(extract_class_name(f) for f in all_npy_files))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"í´ë˜ìŠ¤ ìˆ˜: {len(class_to_idx)}\")  # 396ê°œ ë‚˜ì™€ì•¼ ì •ìƒ\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OMK20ohGQU1",
        "outputId": "40c03b82-5dbd-4180-af86-16525ebb141e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í´ë˜ìŠ¤ ìˆ˜: 396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset í´ë˜ìŠ¤ ì •ì˜\n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import numpy as np\n",
        "\n",
        "# class CarNPYDataset(Dataset):\n",
        "#     def __init__(self, file_list, class_to_idx, transform=None):\n",
        "#         self.file_list = file_list\n",
        "#         self.class_to_idx = class_to_idx\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.file_list)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         path = self.file_list[idx]\n",
        "#         image = np.load(path)  # (1, 384, 384)\n",
        "#         image = torch.tensor(image, dtype=torch.float32)\n",
        "\n",
        "#         class_name = '_'.join(os.path.basename(path).replace('.npy', '').split('_')[:-1])\n",
        "#         label = self.class_to_idx[class_name]\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "\n",
        "#         return image, label\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CarNPYDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # ğŸš€ Step 1. Load npy â†’ tensor\n",
        "        image = np.load(path, mmap_mode='r')\n",
        "        image = torch.from_numpy(image).float()  # (1, H, W)\n",
        "\n",
        "        # ğŸš€ Step 2. Grayscale(1) â†’ RGB(3)\n",
        "        image = image.repeat(3, 1, 1)  # (3, H, W)\n",
        "\n",
        "        # ğŸš€ Step 3. Label ì¶”ì¶œ (!!! ì—¬ê¸°ê°€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨)\n",
        "        class_name = '_'.join(os.path.basename(path).replace('.npy', '').split('_')[:-1])\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # ğŸš€ Step 4. Transform ì ìš©\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # ğŸš€ Step 5. Return (ì´ ì‹œì ì— labelì´ ë°˜ë“œì‹œ ì •ì˜ë˜ì–´ì•¼ í•¨)\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "rtI0lYOuJZt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì „ì²´ .npy íŒŒì¼ ë¦¬ìŠ¤íŠ¸ + train/val split + DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ì „ì²´ .npy íŒŒì¼\n",
        "file_list = glob.glob('/content/drive/MyDrive/fuck/preprocessed/batch_*/**/*.npy', recursive=True)\n",
        "\n",
        "# ë¼ë²¨ ì¶”ì¶œ â†’ stratify ê¸°ë°˜ split\n",
        "labels = [class_to_idx[extract_class_name(f)] for f in file_list]\n",
        "train_files, val_files = train_test_split(file_list, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "# transform\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((384, 384)),  # âœ… 384ë¡œ ë³€ê²½\n",
        "    # transforms.ToTensor(),  # ì´ë¯¸ Tensorë¼ë©´ ë¹¼ê¸°\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "train_dataset = CarNPYDataset(train_files, class_to_idx, transform)\n",
        "val_dataset = CarNPYDataset(val_files, class_to_idx, transform)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "u2DB9tCSJcmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tNalQaGrKS5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AdamW + weight_decay ì¶”ê°€ ì¶”ì²œ (EffNet ê³„ì—´ì— ë§ì´ ì‚¬ìš©)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "JNIgNO9AKcl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "patience_counter = 0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    print(f\"\\nğŸ” Epoch {epoch}\")\n",
        "\n",
        "    # === í•™ìŠµ ===\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=\"Train\", leave=False)\n",
        "    for X, y in loop:\n",
        "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * X.size(0)\n",
        "        train_correct += (outputs.argmax(1) == y).sum().item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # === ê²€ì¦ ===\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "\n",
        "\n",
        "    val_loop = tqdm(val_loader, desc=\"Valid\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loop:\n",
        "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            val_loss += loss.item() * X.size(0)\n",
        "            val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "    # === ë¡œê·¸ ì¶œë ¥ ===\n",
        "    print(f\"âœ… Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "    print(f\"âœ… Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # === EarlyStopping ===\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/team_models/EffNetB5_progressing.pth\")\n",
        "        print(\"ğŸ“¦ Best model saved!\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"âš ï¸ EarlyStopping patience: {patience_counter}/{patience}\")\n",
        "        if patience_counter >= patience:\n",
        "            print(\"â›” Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# ìµœì¢… Best ëª¨ë¸ ë¡œë“œ\n",
        "model.load_state_dict(best_model_wts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZJkMSSKeiG",
        "outputId": "739b2cf5-f013-4fd8-92c7-b8d6855a1391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ” Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/1864 [00:00<?, ?it/s]<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "Valid:   0%|          | 0/208 [00:00<?, ?it/s]<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 1.7268 | Acc: 0.6301\n",
            "âœ… Val   Loss: 0.3908 | Acc: 0.8769\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.2905 | Acc: 0.9116\n",
            "âœ… Val   Loss: 0.3265 | Acc: 0.9074\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.2000 | Acc: 0.9397\n",
            "âœ… Val   Loss: 0.3075 | Acc: 0.9092\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.1518 | Acc: 0.9532\n",
            "âœ… Val   Loss: 0.2710 | Acc: 0.9228\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.1305 | Acc: 0.9591\n",
            "âœ… Val   Loss: 0.2205 | Acc: 0.9351\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.1066 | Acc: 0.9673\n",
            "âœ… Val   Loss: 0.2459 | Acc: 0.9366\n",
            "âš ï¸ EarlyStopping patience: 1/3\n",
            "\n",
            "ğŸ” Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.1040 | Acc: 0.9694\n",
            "âœ… Val   Loss: 0.2657 | Acc: 0.9336\n",
            "âš ï¸ EarlyStopping patience: 2/3\n",
            "\n",
            "ğŸ” Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.0819 | Acc: 0.9749\n",
            "âœ… Val   Loss: 0.2119 | Acc: 0.9517\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.0801 | Acc: 0.9755\n",
            "âœ… Val   Loss: 0.2041 | Acc: 0.9451\n",
            "ğŸ“¦ Best model saved!\n",
            "\n",
            "ğŸ” Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.0669 | Acc: 0.9809\n",
            "âœ… Val   Loss: 0.2483 | Acc: 0.9396\n",
            "âš ï¸ EarlyStopping patience: 1/3\n",
            "\n",
            "ğŸ” Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.0591 | Acc: 0.9830\n",
            "âœ… Val   Loss: 0.2275 | Acc: 0.9481\n",
            "âš ï¸ EarlyStopping patience: 2/3\n",
            "\n",
            "ğŸ” Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Train Loss: 0.0589 | Acc: 0.9835\n",
            "âœ… Val   Loss: 0.2161 | Acc: 0.9505\n",
            "âš ï¸ EarlyStopping patience: 3/3\n",
            "â›” Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "# ì„¤ì •\n",
        "MODEL_PATH = \"/content/drive/MyDrive/team_models/ConvNext-Tiny_progressing.pth\"  # âœ… ëª¨ë¸ íŒŒì¼ëª…\n",
        "TEST_DIR = \"/content/drive/MyDrive/fuck/preprocessed_test\"\n",
        "SAMPLE_SUB_PATH = \"/content/drive/MyDrive/open/sample_submission.csv\"\n",
        "SAVE_SUBMISSION_PATH = \"/content/drive/MyDrive/submission/submission.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' ì œì™¸\n",
        "\n",
        "# âœ… ëª¨ë¸ ë¡œë“œ\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = timm.create_model('efficientnet_b5', pretrained=False, num_classes=NUM_CLASSES)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# âœ… Transform (Normalizeë§Œ ì ìš©)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… í…ŒìŠ¤íŠ¸ìš© npy ê¸°ë°˜ Dataset\n",
        "class TestNPYDataset(Dataset):\n",
        "    def __init__(self, npy_root, transform=None):\n",
        "        self.file_list = []\n",
        "        for root, dirs, files in os.walk(npy_root):\n",
        "            for file in files:\n",
        "                if file.endswith('.npy'):\n",
        "                    self.file_list.append(os.path.join(root, file))\n",
        "        self.file_list.sort()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = np.load(path, mmap_mode='r').copy()\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image = image.repeat(3, 1, 1)  # âœ… Grayscale(1) â†’ RGB(3)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".npy\", \"\")  # TEST_xxx ê·¸ëŒ€ë¡œ ì¶”ì¶œ\n",
        "        return image, fname\n",
        "\n",
        "# âœ… DataLoader\n",
        "test_dataset = TestNPYDataset(TEST_DIR, transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,        # testëŠ” batch_size í¬ê²Œ OK\n",
        "    shuffle=False,\n",
        "    num_workers=2,        # ì•ˆì •ì„± ìœ„í•´ 2 ì¶”ì²œ\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "# âœ… Inference\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for imgs, names in tqdm(test_loader, desc=\"ğŸ” Inference\"):\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = model(imgs)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        for name, prob in zip(names, probs.cpu().numpy()):\n",
        "            row = {\"ID\": name}\n",
        "            row.update({class_name: prob[i] for i, class_name in enumerate(column_names)})\n",
        "            results.append(row)\n",
        "\n",
        "# âœ… ê²°ê³¼ ì €ì¥\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "submission_df.to_csv(SAVE_SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"âœ… ì„œë¸Œë¯¸ì…˜ ì €ì¥ ì™„ë£Œ: {SAVE_SUBMISSION_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k61x77gkNSDG",
        "outputId": "e972b290-80fa-4889-e5e7-716f9d899b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Inference:   8%|â–Š         | 20/259 [00:41<01:26,  2.75it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/submission.csv\")\n",
        "df.to_csv(\"submission_utf8sig.csv\", index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "ShGkYhOXRiw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°œìˆ˜: {len(test_files)}\")\n",
        "print(test_files[:3])  # ì• ëª‡ ê°œ íŒŒì¼ ì´ë¦„ í™•ì¸\n"
      ],
      "metadata": {
        "id": "2pLUJGGGOajU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "import numpy as np\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/fuck/preprocessed/batch_000/1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015_000000.npy\"\n",
        "with open(test_path, \"rb\") as f:\n",
        "    print(f.read(10))  # ì²˜ìŒ ëª‡ ë°”ì´íŠ¸ë¥¼ ì¶œë ¥ (ì •ìƒ npyë©´ b'\\x93NUMPY'ë¡œ ì‹œì‘)"
      ],
      "metadata": {
        "id": "XClXn_Pf5kHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "broken = []\n",
        "\n",
        "for npy_file in Path(\"/content/drive/MyDrive/fuck/preprocessed\").rglob(\"*.npy\"):\n",
        "    try:\n",
        "        np.load(str(npy_file), allow_pickle=False)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ {npy_file} - {e}\")\n",
        "        broken.append(npy_file)\n",
        "\n",
        "print(f\"\\nì†ìƒëœ íŒŒì¼ ìˆ˜: {len(broken)}\")\n"
      ],
      "metadata": {
        "id": "EfDHwnaH9WXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def is_npy_file_valid(path):\n",
        "    try:\n",
        "        # allow_pickle=Falseë¡œ ë¨¼ì € ì‹œë„\n",
        "        _ = np.load(path, allow_pickle=False)\n",
        "        return True\n",
        "    except ValueError as e:\n",
        "        # pickle ê´€ë ¨ ì˜¤ë¥˜ë§Œ ìˆì„ ê²½ìš° allow_pickle=Trueë¡œ ì¬ì‹œë„\n",
        "        if \"pickled data\" in str(e):\n",
        "            try:\n",
        "                _ = np.load(path, allow_pickle=True)\n",
        "                return True\n",
        "            except Exception:\n",
        "                return False\n",
        "        else:\n",
        "            return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# ê²€ì‚¬í•  ê²½ë¡œ\n",
        "base_dir = \"/content/drive/MyDrive/fuck/preprocessed\"\n",
        "\n",
        "# ëª¨ë“  npy íŒŒì¼ ê²½ë¡œ ìˆ˜ì§‘\n",
        "corrupted_files = []\n",
        "total_files = 0\n",
        "\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".npy\"):\n",
        "            path = os.path.join(root, file)\n",
        "            total_files += 1\n",
        "            if not is_npy_file_valid(path):\n",
        "                corrupted_files.append(path)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"ì´ ê²€ì‚¬í•œ íŒŒì¼ ìˆ˜: {total_files}\")\n",
        "print(f\"âŒ ì†ìƒëœ íŒŒì¼ ìˆ˜: {len(corrupted_files)}\")\n",
        "if corrupted_files:\n",
        "    print(\"ì˜ˆì‹œ ì†ìƒ íŒŒì¼:\")\n",
        "    for path in corrupted_files[:5]:\n",
        "        print(\" -\", path)\n"
      ],
      "metadata": {
        "id": "XEvdFYyoAzys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "broken_path = \"/content/drive/MyDrive/fuck/preprocessed/batch_000/1á„‰á…µá„…á…µá„Œá…³_F20_2013_2015_000000.npy\"\n"
      ],
      "metadata": {
        "id": "81E3SxAEAzrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "filename = os.path.basename(broken_path)\n",
        "parts = filename.replace(\".npy\", \"\").split(\"_\")\n",
        "class_name = \"_\".join(parts[:-1])\n",
        "index = parts[-1]\n",
        "print(f\"class_name: {class_name}, index: {index}\")\n"
      ],
      "metadata": {
        "id": "YghDGItjB6Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_image_path = f\"/content/drive/MyDrive/open/train/{class_name}\"\n",
        "print(\"í•´ë‹¹ í´ë˜ìŠ¤ í´ë” ê²½ë¡œ:\", original_image_path)\n",
        "\n",
        "# í•´ë‹¹ í´ë˜ìŠ¤ ì•ˆì—ì„œ ëª‡ ë²ˆì§¸ ì´ë¯¸ì§€ì¸ì§€ ì°¾ì•„ì•¼ í•¨\n",
        "import os\n",
        "\n",
        "# ìˆ«ì ì¸ë±ìŠ¤ëŠ” ì•ì—ì„œ ëª‡ ë²ˆì§¸ì¸ì§€ ì•Œ ìˆ˜ ìˆê²Œ ìˆœì„œëŒ€ë¡œ ì ‘ê·¼\n",
        "images = sorted(os.listdir(original_image_path))\n",
        "target_image_name = images[int(index)]\n",
        "print(\"ëŒ€ìƒ ì›ë³¸ ì´ë¯¸ì§€ ì´ë¦„:\", target_image_name)\n"
      ],
      "metadata": {
        "id": "_tJfniUhB8_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "# ì „ì²˜ë¦¬ transform ì •ì˜\n",
        "class SquarePad:\n",
        "    def __call__(self, image):\n",
        "        w, h = image.size\n",
        "        max_wh = max(w, h)\n",
        "        pad_left = (max_wh - w) // 2\n",
        "        pad_top = (max_wh - h) // 2\n",
        "        padding = (pad_left, pad_top, max_wh - w - pad_left, max_wh - h - pad_top)\n",
        "        return TF.pad(image, padding, fill=0)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    SquarePad(),\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# ì´ë¯¸ì§€ ì—´ê¸°\n",
        "img_path = os.path.join(original_image_path, target_image_name)\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "img_tensor = transform(img)\n",
        "\n",
        "# ì•ˆì „í•˜ê²Œ ì €ì¥ (astypeìœ¼ë¡œ pickle ë°©ì§€)\n",
        "np.save(broken_path, img_tensor.numpy().astype(np.float32))\n",
        "print(\"âœ… ë‹¤ì‹œ ì €ì¥ ì™„ë£Œ:\", broken_path)\n"
      ],
      "metadata": {
        "id": "Gx32rJk8CHKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}