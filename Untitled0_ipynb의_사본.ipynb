{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1D8e3youYRcY6QLTgPNS4AnSaG6Do7M4O",
      "authorship_tag": "ABX9TyOmNNHxxdxjeQ7mk58P1RTs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/Untitled0_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MlHz2ISl_dq6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092585ea-0678-4dc6-a9a2-358af2993a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 압축 해제\n",
        "!unzip -oq \"/content/drive/MyDrive/Colab Notebooks/open.zip\" -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/model.py\" /content/\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/dataset.py\" /content/"
      ],
      "metadata": {
        "id": "xZExUY4tPgoz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 완전 삭제 및 강제 재로드\n",
        "import sys\n",
        "if 'model' in sys.modules:\n",
        "    del sys.modules['model']\n",
        "\n",
        "import importlib\n",
        "import model\n",
        "importlib.reload(model)\n",
        "\n",
        "from model import ColorAwareEffNetB5\n"
      ],
      "metadata": {
        "id": "4waWFk0oCUcj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import CustomImageDataset"
      ],
      "metadata": {
        "id": "sNo81hg8CxJ8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 반드시 먼저 실행되어야 함\n",
        "%cp '/content/drive/MyDrive/Colab Notebooks/model.py' /content/\n",
        "from model import ColorAwareEffNetB5\n"
      ],
      "metadata": {
        "id": "wsTEBXGLZJn8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CLASS_ALIAS 반영된 학습용 전체 코드\n",
        "\n",
        "# 1. 라이브러리 임포트\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
        "from PIL import Image\n",
        "\n",
        "# 2. CLASS_ALIAS 정의\n",
        "CLASS_ALIAS = {\n",
        "    'K5_하이브리드_3세대_2020_2023': 'K5_3세대_하이브리드_2020_2022',\n",
        "    '디_올_뉴_니로_2022_2025': '디_올뉴니로_2022_2025',\n",
        "    '박스터_718_2017_2024': '718_박스터_2017_2024'\n",
        "}\n",
        "\n",
        "# 3. CustomImageDataset 정의\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        self.classes = sorted({CLASS_ALIAS.get(c, c) for c in os.listdir(root_dir)})\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        for cls_name in os.listdir(root_dir):\n",
        "            normalized = CLASS_ALIAS.get(cls_name, cls_name)\n",
        "            cls_path = os.path.join(root_dir, cls_name)\n",
        "            for fname in os.listdir(cls_path):\n",
        "                if fname.lower().endswith('.jpg'):\n",
        "                    img_path = os.path.join(cls_path, fname)\n",
        "                    label = self.class_to_idx[normalized]\n",
        "                    self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image_tensor = self.transform(image)\n",
        "        else:\n",
        "            image_tensor = transforms.ToTensor()(image)  # 기본 텐서화 처리\n",
        "\n",
        "        color_feat = self.extract_color_feature(image_tensor)\n",
        "\n",
        "        return image_tensor, label, color_feat\n",
        "\n",
        "    def extract_color_feature(self, image_tensor):\n",
        "        mean = image_tensor.view(3, -1).mean(dim=1)\n",
        "        std = image_tensor.view(3, -1).std(dim=1)\n",
        "        return torch.cat([mean, std], dim=0)\n",
        "\n",
        "# 4. 모델 정의\n",
        "class ColorAwareEffNetB5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ColorAwareEffNetB5, self).__init__()\n",
        "        self.base_model = efficientnet_b5(weights=EfficientNet_B5_Weights.IMAGENET1K_V1)\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "        self.feature_dim = 2048\n",
        "        self.color_fc = nn.Linear(6, 32)\n",
        "        self.fc = nn.Linear(self.feature_dim + 32, num_classes)\n",
        "\n",
        "    def forward(self, x, color_feat):\n",
        "        x = self.base_model(x)\n",
        "        color_feat = self.color_fc(color_feat)\n",
        "        x = torch.cat((x, color_feat), dim=1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# 5. 환경 설정\n",
        "CFG = {\n",
        "    'IMG_SIZE': 456,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE': 1e-4,\n",
        "    'SEED': 42\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED'])\n",
        "\n",
        "# 6. 데이터 준비\n",
        "train_path = \"/content/train\"\n",
        "full_dataset = CustomImageDataset(train_path, transform=None)\n",
        "targets = [label for _, label, _ in full_dataset]\n",
        "class_names = full_dataset.classes\n",
        "print(f\"✅ 클래스 수: {len(class_names)}\")  # 반드시 396개여야 함\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(targets)), test_size=0.2, stratify=targets, random_state=CFG['SEED'])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Subset(CustomImageDataset(train_path, transform=train_transform), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(train_path, transform=val_transform), val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# 7. 모델 학습\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ColorAwareEffNetB5(num_classes=len(class_names)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
        "scaler = GradScaler()\n",
        "\n",
        "best_logloss = float('inf')\n",
        "\n",
        "for epoch in range(CFG['EPOCHS']):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for images, labels, colors in tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\"):\n",
        "        images, labels, colors = images.to(device), labels.to(device), colors.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = model(images, colors)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, colors in val_loader:\n",
        "            images, labels, colors = images.to(device), labels.to(device), colors.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(images, colors)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}% | LogLoss: {val_logloss:.4f}\")\n",
        "\n",
        "    if val_logloss < best_logloss:\n",
        "        best_logloss = val_logloss\n",
        "        torch.save(model.state_dict(), \"best_model_amp.pth\")\n",
        "        print(f\"\\n✅ Best model saved at Epoch {epoch+1} (logloss: {val_logloss:.4f})\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiFu5_JjUMiC",
        "outputId": "7da42cf1-8352-43ba-df73-0ad3cda56452"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 클래스 수: 393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-3fc2ee367de3>:140: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "[Epoch 1] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 1] Training: 100%|██████████| 1657/1657 [04:40<00:00,  5.91it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1] Train Loss: 2.9918 | Val Loss: 0.6109 | Val Acc: 82.89% | LogLoss: 0.6102\n",
            "\n",
            "✅ Best model saved at Epoch 1 (logloss: 0.6102)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 2] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 2] Training: 100%|██████████| 1657/1657 [04:36<00:00,  5.99it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 2] Train Loss: 0.4627 | Val Loss: 0.2481 | Val Acc: 91.11% | LogLoss: 0.2480\n",
            "\n",
            "✅ Best model saved at Epoch 2 (logloss: 0.2480)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 3] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 3] Training: 100%|██████████| 1657/1657 [04:39<00:00,  5.93it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 3] Train Loss: 0.2210 | Val Loss: 0.1730 | Val Acc: 93.92% | LogLoss: 0.1728\n",
            "\n",
            "✅ Best model saved at Epoch 3 (logloss: 0.1728)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 4] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 4] Training: 100%|██████████| 1657/1657 [04:38<00:00,  5.94it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 4] Train Loss: 0.1469 | Val Loss: 0.1621 | Val Acc: 94.63% | LogLoss: 0.1624\n",
            "\n",
            "✅ Best model saved at Epoch 4 (logloss: 0.1624)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Epoch 5] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 5] Training: 100%|██████████| 1657/1657 [04:38<00:00,  5.96it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 5] Train Loss: 0.1121 | Val Loss: 0.1438 | Val Acc: 95.29% | LogLoss: 0.1440\n",
            "\n",
            "✅ Best model saved at Epoch 5 (logloss: 0.1440)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 6] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 6] Training: 100%|██████████| 1657/1657 [04:36<00:00,  5.99it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 6] Train Loss: 0.0922 | Val Loss: 0.1476 | Val Acc: 95.62% | LogLoss: 0.1476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 7] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 7] Training: 100%|██████████| 1657/1657 [04:38<00:00,  5.96it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 7] Train Loss: 0.0820 | Val Loss: 0.1423 | Val Acc: 95.81% | LogLoss: 0.1445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 8] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 8] Training: 100%|██████████| 1657/1657 [04:37<00:00,  5.97it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 8] Train Loss: 0.0655 | Val Loss: 0.1677 | Val Acc: 95.87% | LogLoss: 0.1729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 9] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 9] Training: 100%|██████████| 1657/1657 [04:38<00:00,  5.95it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 9] Train Loss: 0.0634 | Val Loss: 0.1419 | Val Acc: 96.24% | LogLoss: 0.1419\n",
            "\n",
            "✅ Best model saved at Epoch 9 (logloss: 0.1419)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Epoch 10] Training:   0%|          | 0/1657 [00:00<?, ?it/s]<ipython-input-6-3fc2ee367de3>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Epoch 10] Training: 100%|██████████| 1657/1657 [04:37<00:00,  5.97it/s]\n",
            "<ipython-input-6-3fc2ee367de3>:174: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] Train Loss: 0.0576 | Val Loss: 0.1771 | Val Acc: 96.02% | LogLoss: 0.1859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/best_model_amp.pth\", \"/content/best_model_fold1.pth\")\n",
        "shutil.copy(\"/content/best_model_amp.pth\", \"/content/best_model_fold2.pth\")\n",
        "shutil.copy(\"/content/best_model_amp.pth\", \"/content/best_model_fold3.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-E_3WxxMXA0u",
        "outputId": "8f8cf7ed-595c-4e47-fa35-7db1473cf7e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/best_model_fold3.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"학습 클래스 수: {len(train_dataset.dataset.class_to_idx)}\")  # 393개\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJTnrdZvCV-_",
        "outputId": "ba17c9d8-fbc3-4661-ed36-adeafe27b582"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 클래스 수: 393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 전체 통합 추론 코드 (396 클래스 확장 포함)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ✅ 1. CLASS_ALIAS 정의\n",
        "CLASS_ALIAS = {\n",
        "    'K5_하이브리드_3세대_2020_2023': 'K5_3세대_하이브리드_2020_2022',\n",
        "    '디_올_뉴_니로_2022_2025': '디_올뉴니로_2022_2025',\n",
        "    '박스터_718_2017_2024': '718_박스터_2017_2024'\n",
        "}\n",
        "\n",
        "# ✅ 2. 클래스 목록\n",
        "train_root = \"/content/train\"\n",
        "all_class_names_396 = sorted(os.listdir(train_root))\n",
        "class_names_393 = sorted({CLASS_ALIAS.get(c, c) for c in all_class_names_396})\n",
        "class_to_index = {cls: i for i, cls in enumerate(all_class_names_396)}\n",
        "\n",
        "# ✅ 3. 확장 함수\n",
        "def expand_to_396(pred_393: np.ndarray) -> pd.DataFrame:\n",
        "    df = pd.DataFrame(pred_393, columns=class_names_393)\n",
        "    for alias, target in CLASS_ALIAS.items():\n",
        "        if alias not in df.columns:\n",
        "            df[alias] = df[target]\n",
        "    return df[all_class_names_396]  # 컬럼 순서 맞춤\n",
        "\n",
        "# ✅ 4. CustomImageDataset 정의\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False, test_df=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if is_test:\n",
        "            self.samples = [(row['ID'], os.path.join(root_dir, row['img_path'])) for _, row in test_df.iterrows()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id, img_path = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image_tensor = self.transform(image) if self.transform else image\n",
        "        color_feat = self.extract_color_feature(image_tensor)\n",
        "        return sample_id, image_tensor, color_feat\n",
        "\n",
        "    def extract_color_feature(self, image_tensor):\n",
        "        mean = image_tensor.view(3, -1).mean(dim=1)\n",
        "        std = image_tensor.view(3, -1).std(dim=1)\n",
        "        return torch.cat([mean, std], dim=0)\n",
        "\n",
        "# ✅ 5. 모델 정의\n",
        "class ColorAwareEffNetB5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ColorAwareEffNetB5, self).__init__()\n",
        "        self.base_model = efficientnet_b5(weights=EfficientNet_B5_Weights.IMAGENET1K_V1)\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "        self.feature_dim = 2048\n",
        "        self.color_fc = nn.Linear(6, 32)\n",
        "        self.fc = nn.Linear(self.feature_dim + 32, num_classes)\n",
        "\n",
        "    def forward(self, x, color_feat):\n",
        "        x = self.base_model(x)\n",
        "        color_feat = self.color_fc(color_feat)\n",
        "        x = torch.cat([x, color_feat], dim=1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ✅ 6. 환경 설정\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "num_classes = 393  # 학습 기준\n",
        "\n",
        "# ✅ 7. TTA Transform\n",
        "tta_transforms = [\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]\n",
        "\n",
        "# ✅ 8. 모델 로딩 및 예측\n",
        "model_paths = [\n",
        "    \"/content/best_model_fold1.pth\",\n",
        "    \"/content/best_model_fold2.pth\",\n",
        "    \"/content/best_model_fold3.pth\"\n",
        "]\n",
        "\n",
        "submission_template = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "all_preds = []\n",
        "\n",
        "for i, path in enumerate(model_paths):\n",
        "    model = ColorAwareEffNetB5(num_classes=393).to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    tta_preds = []\n",
        "    for tta_transform in tta_transforms:\n",
        "        temp_dataset = CustomImageDataset(\"/content\", transform=tta_transform, is_test=True, test_df=test_df)\n",
        "        temp_loader = DataLoader(temp_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        probs_list = []\n",
        "        with torch.no_grad():\n",
        "            for ids, images, colors in temp_loader:\n",
        "                images, colors = images.to(device), colors.to(device)\n",
        "                outputs = model(images, colors)\n",
        "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "                probs_list.append(probs)\n",
        "\n",
        "        tta_preds.append(np.concatenate(probs_list, axis=0))\n",
        "\n",
        "    mean_preds = np.mean(tta_preds, axis=0)\n",
        "    all_preds.append(mean_preds)\n",
        "\n",
        "    pred_df = expand_to_396(mean_preds)\n",
        "    model_submission = pd.concat([test_df[[\"ID\"]], pred_df], axis=1)\n",
        "    model_submission.to_csv(f\"/content/submission_model_{i+1}.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"✅ submission_model_{i+1}.csv 저장 완료\")\n",
        "\n",
        "# ✅ 9. 앙상블 평균 저장\n",
        "ensemble_preds = np.mean(all_preds, axis=0)\n",
        "ensemble_df = expand_to_396(ensemble_preds)\n",
        "ensemble_submission = pd.concat([test_df[[\"ID\"]], ensemble_df], axis=1)\n",
        "ensemble_submission.to_csv(\"/content/submission_ensemble.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ 앙상블 submission_ensemble.csv 저장 완료\")\n"
      ],
      "metadata": {
        "id": "UtnZxyE0Ngyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194fb1f0-e25a-4e98-e3a3-dde18b0eda56"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ submission_model_1.csv 저장 완료\n",
            "✅ submission_model_2.csv 저장 완료\n",
            "✅ submission_model_3.csv 저장 완료\n",
            "✅ 앙상블 submission_ensemble.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# 앙상블\n",
        "files.download('/content/submission_ensemble.csv')\n",
        "\n",
        "# 각 모델\n",
        "files.download('/content/submission_model_1.csv')\n",
        "files.download('/content/submission_model_2.csv')\n",
        "files.download('/content/submission_model_3.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rpk6eCPpiIlU",
        "outputId": "ced2f0d9-3b2f-43d2-b06c-a910289211e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_da783b2c-7ec6-44d9-ab62-1070d2709564\", \"submission_ensemble.csv\", 43945228)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_84a21b7c-8800-4d24-bfd3-4c1c05039e9b\", \"submission_model_1.csv\", 43948804)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1266abf0-c355-4e69-b272-873457c09dc4\", \"submission_model_2.csv\", 43950017)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5ec62c63-1d82-44d0-9f37-660489ee6e69\", \"submission_model_3.csv\", 43950902)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}