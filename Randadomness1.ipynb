{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 87793,
          "databundleVersionId": 12276181,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 10855324,
          "sourceType": "datasetVersion",
          "datasetId": 6742586
        },
        {
          "sourceId": 11118830,
          "sourceType": "datasetVersion",
          "datasetId": 6933267
        },
        {
          "sourceId": 11830543,
          "sourceType": "datasetVersion",
          "datasetId": 7432215
        },
        {
          "sourceId": 11830789,
          "sourceType": "datasetVersion",
          "datasetId": 7432367
        },
        {
          "sourceId": 11831460,
          "sourceType": "datasetVersion",
          "datasetId": 7432831
        },
        {
          "sourceId": 11831882,
          "sourceType": "datasetVersion",
          "datasetId": 7433107
        },
        {
          "sourceId": 11833356,
          "sourceType": "datasetVersion",
          "datasetId": 7434181
        },
        {
          "sourceId": 224830487,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Randadomness",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/Randadomness1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "uUFbjJLjkfpP"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "stanford_rna_3d_folding_path = kagglehub.competition_download('stanford-rna-3d-folding')\n",
        "metric_usalign_path = kagglehub.dataset_download('metric/usalign')\n",
        "geraseva_protenix_checkpoints_path = kagglehub.dataset_download('geraseva/protenix-checkpoints')\n",
        "biniroun_protenix_packages_path = kagglehub.dataset_download('biniroun/protenix-packages')\n",
        "biniroun_linux_biowheels_310_path = kagglehub.dataset_download('biniroun/linux-biowheels-310')\n",
        "biniroun_linux_mlwhl_311_path = kagglehub.dataset_download('biniroun/linux-mlwhl-311')\n",
        "biniroun_protenix_main_path = kagglehub.dataset_download('biniroun/protenix-main')\n",
        "biniroun_rdkit_cp310_path = kagglehub.dataset_download('biniroun/rdkit-cp310')\n",
        "metric_ribonanza_tm_score_path = kagglehub.notebook_output_download('metric/ribonanza-tm-score')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "HYZ5nnKWkfpQ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-index --find-links=/kaggle/input/linux-biowheels-310 biopython numpy\n",
        "!pip install --no-index --find-links=/kaggle/input/linux-mlwhl-311 ml-collections contextlib2\n",
        "!pip install --no-index --find-links=/kaggle/input/linux-biowheels-310 biopython\n",
        "!pip install --no-index --find-links=/kaggle/input/rdkit-cp310 rdkit\n",
        "!pip install --no-index --find-links=/kaggle/input/linux-mlwhl-311 biopython ml-collections contextlib2 rdkit\n",
        "!pip install --no-index --find-links=/kaggle/input/linux-mlwhl-311 biotite"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-16T03:41:56.088386Z",
          "iopub.execute_input": "2025-05-16T03:41:56.088656Z",
          "iopub.status.idle": "2025-05-16T03:42:00.555722Z",
          "shell.execute_reply.started": "2025-05-16T03:41:56.088635Z",
          "shell.execute_reply": "2025-05-16T03:42:00.554849Z"
        },
        "id": "7PLE1uTBkfpQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/kaggle/input/protenix-main\")  # 또는 업로드한 zip의 정확한 이름\n",
        "\n",
        "# 이후 import 실행\n",
        "from protenix.data.infer_data_pipeline import InferenceDataset\n",
        "\n",
        "# 📌 기본 세팅\n",
        "import os, sys, numpy as np, pandas as pd, torch, warnings\n",
        "from tqdm import tqdm\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# 📌 GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"📌 Using device: {device}\")\n",
        "\n",
        "# 📌 USAlign 설정\n",
        "os.system(\"cp /kaggle/input/usalign/USalign /kaggle/working/\")\n",
        "os.system(\"chmod u+x /kaggle/working/USalign\")\n",
        "\n",
        "# 📌 Protenix 코드 및 패키지 경로 등록\n",
        "sys.path.append(\"/kaggle/input/protenix-main\")\n",
        "sys.path.append(\"/kaggle/input/protenix-packages\")\n",
        "\n",
        "# 📌 학습 데이터 병합 (v2 우선)\n",
        "seq_v1 = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n",
        "seq_v2 = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.v2.csv')\n",
        "label_v1 = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
        "label_v2 = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.v2.csv')\n",
        "\n",
        "seq_v1 = seq_v1[~seq_v1['target_id'].isin(seq_v2['target_id'])]\n",
        "label_v1 = label_v1[~label_v1['ID'].str.extract(r\"^(.+)_\\d+$\")[0].isin(label_v2['ID'].str.extract(r\"^(.+)_\\d+$\")[0])]\n",
        "\n",
        "merged_seq = pd.concat([seq_v2, seq_v1], ignore_index=True)\n",
        "merged_label = pd.concat([label_v2, label_v1], ignore_index=True)\n",
        "\n",
        "# 📌 입력 생성\n",
        "inputs = []\n",
        "for _, row in merged_seq.iterrows():\n",
        "    tid = row[\"target_id\"]\n",
        "    seq = row[\"sequence\"]\n",
        "    lbl = merged_label[merged_label[\"ID\"].str.startswith(tid + \"_\")].copy()\n",
        "    lbl.sort_values(\"resid\", inplace=True)\n",
        "    if len(lbl) != len(seq):\n",
        "        continue\n",
        "    coords = lbl[[\"x_1\", \"y_1\", \"z_1\"]].values.astype(np.float32)\n",
        "    inputs.append({\n",
        "        \"name\": tid,\n",
        "        \"sequences\": [{\n",
        "            \"rnaSequence\": {\"sequence\": seq, \"count\": 1},\n",
        "            \"coordinates\": coords.tolist()\n",
        "        }]\n",
        "    })\n",
        "\n",
        "print(f\"✅ 학습 가능한 시퀀스 수: {len(inputs)}\")\n",
        "\n",
        "# 📌 InferenceDataset 정의\n",
        "from protenix.data.infer_data_pipeline import InferenceDataset\n",
        "\n",
        "class TrainDataset(InferenceDataset):\n",
        "    def __init__(self, data_list, use_msa=False):\n",
        "        self.inputs = data_list\n",
        "        self.use_msa = use_msa\n",
        "        self.dump_dir = \"output\"\n",
        "\n",
        "dataset = TrainDataset(inputs)\n",
        "\n",
        "# 📌 모델 설정\n",
        "from runner.inference import update_inference_configs, InferenceRunner\n",
        "from configs.configs_base import configs as configs_base\n",
        "from configs.configs_data import data_configs\n",
        "from configs.configs_inference import inference_configs\n",
        "from protenix.config.config import parse_configs\n",
        "\n",
        "configs_base[\"model\"][\"N_cycle\"] = 10\n",
        "configs_base[\"sample_diffusion\"][\"N_sample\"] = 5\n",
        "configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
        "inference_configs['load_checkpoint_path'] = '/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
        "\n",
        "configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
        "configs = parse_configs(configs=configs, fill_required_with_null=True)\n",
        "runner = InferenceRunner(configs)\n",
        "runner.model.to(device)  # 📌 명시적 GPU 지정\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 📌 테스트셋 로딩\n",
        "test_df = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
        "\n",
        "class TestDataset(InferenceDataset):\n",
        "    def __init__(self, seq_list, id_list):\n",
        "        self.use_msa = False\n",
        "        self.dump_dir = \"output\"\n",
        "        self.inputs = [{\n",
        "            \"sequences\": [{\"rnaSequence\": {\"sequence\": seq, \"count\": 1}}],\n",
        "            \"name\": i\n",
        "        } for i, seq in zip(id_list, seq_list)]\n",
        "\n",
        "test_dataset = TestDataset(test_df['sequence'], test_df['target_id'])\n",
        "\n",
        "# 📌 예측 및 제출파일 생성\n",
        "with open(\"submission.csv\", \"w\") as f:\n",
        "    for i in tqdm(range(len(test_dataset))):\n",
        "        try:\n",
        "            data, atom_array, err_msg = test_dataset[i]\n",
        "            if err_msg:\n",
        "                raise Exception(err_msg)\n",
        "            runner.update_model_configs(update_inference_configs(configs, data[\"N_token\"].item()))\n",
        "            out = runner.predict(data)\n",
        "            coords = out[\"coordinate\"][:, data[\"input_feature_dict\"][\"atom_to_tokatom_idx\"] == 12]\n",
        "\n",
        "            result = []\n",
        "            for j, res in enumerate(data['sequences'][0]['rnaSequence']['sequence']):\n",
        "                row = {\n",
        "                    'ID': f\"{data['sample_name']}_{j+1}\",\n",
        "                    'resname': res,\n",
        "                    'resid': j + 1,\n",
        "                }\n",
        "                for k in range(5):\n",
        "                    if k < coords.shape[0]:\n",
        "                        row.update({\n",
        "                            f\"x_{k+1}\": coords[k, j, 0],\n",
        "                            f\"y_{k+1}\": coords[k, j, 1],\n",
        "                            f\"z_{k+1}\": coords[k, j, 2],\n",
        "                        })\n",
        "                    else:\n",
        "                        row.update({f\"x_{k+1}\": 0.0, f\"y_{k+1}\": 0.0, f\"z_{k+1}\": 0.0})\n",
        "                result.append(row)\n",
        "            pd.DataFrame(result).to_csv(f, index=False, header=(i == 0))\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "print(\"✅ submission.csv 생성 완료 🎉\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "V6GJWK1LkfpR"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}