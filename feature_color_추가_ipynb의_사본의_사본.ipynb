{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1b6riaVBEOzHpfm8HFHoZLBImRDTktDdh",
      "authorship_tag": "ABX9TyMpGF3l/xiX/LXvVqD27Z3e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/feature_color_%EC%B6%94%EA%B0%80_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# 1. Driveì—ì„œ ë¡œì»¬ë¡œ ë³µì‚¬ (ë¹ ë¦„)\n",
        "shutil.copy(\"/content/drive/MyDrive/open.zip\", \"/content/open.zip\")\n",
        "\n",
        "# 2. ì••ì¶• í’€ê¸°\n",
        "with zipfile.ZipFile(\"/content/open.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# 3. í™•ì¸\n",
        "!ls /content/train"
      ],
      "metadata": {
        "id": "VGLGwzmFf9U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad25ae8-59e5-4ad7-90ff-cc418719cd1f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì»¨í‹°ë„¨íƒˆ_10ì„¸ëŒ€_2017_2019\t     A_í´ë˜ìŠ¤_W177_2020_2025\n",
            "ì–´ì½”ë“œ_10ì„¸ëŒ€_2018_2022\t\t     B_í´ë˜ìŠ¤_W246_2013_2018\n",
            "1ì‹œë¦¬ì¦ˆ_F20_2013_2015\t\t     ë‰´_ìŠ¤íƒ€ì¼_ì½”ë€ë„_C_2017_2019\n",
            "1ì‹œë¦¬ì¦ˆ_F20_2016_2019\t\t     í”„ë¦¬ìš°ìŠ¤_C_2018_2020\n",
            "1ì‹œë¦¬ì¦ˆ_F40_2020_2024\t\t     ë‰´_CC_2012_2016\n",
            "ê·¸ëœë“œì¹´ë‹ˆë°œ_2006_2010\t\t     CLA_í´ë˜ìŠ¤_C117_2014_2019\n",
            "2008_2015_2017\t\t\t     CLA_í´ë˜ìŠ¤_C118_2020_2025\n",
            "ì—ì¿ ìŠ¤_ì‹ í˜•_2010_2015\t\t     CLE_í´ë˜ìŠ¤_C236_2024_2025\n",
            "íŒŒë‚˜ë©”ë¼_2010_2016\t\t     CLS_í´ë˜ìŠ¤_C257_2019_2023\n",
            "ë‰´_ì œíƒ€_2011_2016\t\t     CLS_í´ë˜ìŠ¤_W218_2012_2017\n",
            "ë‰´_ì¹´ì´ì—”_2011_2018\t\t     ì•„ë°˜ë–¼_í•˜ì´ë¸Œë¦¬ë“œ_CN7_2021_2023\n",
            "ì—‘ì„¼íŠ¸_ì‹ í˜•_2011_2019\t\t     ì•„ë°˜ë–¼_CN7_2021_2023\n",
            "ìŠ¤íŒŒí¬_2012_2015\t\t     ë”_ë‰´_ì•„ë°˜ë–¼_CN7_2023_2025\n",
            "ì¿ í¼_ì»¨íŠ¸ë¦¬ë§¨_2012_2015\t\t     CT6_2016_2018\n",
            "ì˜¬_ë‰´_ëª¨ë‹_2012_2015\t\t     C_í´ë˜ìŠ¤_W204_2008_2015\n",
            "ë§ë¦¬ë¶€_2012_2016\t\t     C_í´ë˜ìŠ¤_W205_2015_2021\n",
            "ì•„ë² ì˜¤_2012_2016\t\t     C_í´ë˜ìŠ¤_W206_2022_2024\n",
            "ë‰´_í‹°êµ¬ì•ˆ_2012_2016\t\t     ì œë„¤ì‹œìŠ¤_DH_2014_2016\n",
            "ë ˆì´_2012_2017\t\t\t     ì˜ë‚˜íƒ€_DN8_2020_2023\n",
            "ì˜¬ë€ë„_2012_2018\t\t     ì˜ë‚˜íƒ€_ë””_ì—£ì§€_DN8_2024_2025\n",
            "ë”_ë‰´_íŒŒì‚¬íŠ¸_2012_2019\t\t     e_íŠ¸ë¡ _2020_2023\n",
            "íŠ¸ë™ìŠ¤_2013_2016\t\t     E_PACE_2018_2020\n",
            "ì½°íŠ¸ë¡œí¬ë¥´í…Œ_2014_2016\t\t     EQ900_2016_2018\n",
            "ë”_ë‰´_ì•„ë°˜ë–¼_2014_2016\t\t     EQA_H243_2021_2024\n",
            "ë§ˆì¹¸_2014_2018\t\t\t     EQE_V295_2022_2024\n",
            "ê·¸ëœë“œ_ì²´ë¡œí‚¤_2014_2020\t\t     EQS_V297_2022_2023\n",
            "ê¸°ë¸”ë¦¬_2014_2023\t\t     ë‰´_ES300h_2013_2015\n",
            "ë”_ë‰´_ëª¨ë‹_2015_2016\t\t     ë‰´_ES300h_2016_2018\n",
            "ë ˆë‹ˆê²Œì´ë“œ_2015_2017\t\t     ES300h_7ì„¸ëŒ€_2019_2026\n",
            "ì˜¬_ë‰´_ì˜ë Œí† _2015_2017\t\t     ë””_ì˜¬ë‰´ë‹ˆë¡œEV_2023_2024\n",
            "í‹°ë³¼ë¦¬_2015_2018\t\t     ë”_ê¸°ì•„_ë ˆì´_EV_2024_2025\n",
            "ì•„ìŠ¬ë€_2015_2018\t\t     EV6_2022_2024\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_ìŠ¤í¬ì¸ _2015_2019\t     EV9_2024_2025\n",
            "ì˜¬_ë‰´_ì¹´ë‹ˆë°œ_2015_2019\t\t     E_í´ë˜ìŠ¤_W212_2010_2016\n",
            "ì—ìŠ¤ì»¬ë ˆì´ë“œ_2015_2020\t\t     E_í´ë˜ìŠ¤_W213_2017_2020\n",
            "ë¨¸ìŠ¤íƒ±_2015_2023\t\t     E_í´ë˜ìŠ¤_W213_2021_2023\n",
            "ìµìŠ¤í”Œë¡œëŸ¬_2016_2017\t\t     E_í´ë˜ìŠ¤_W214_2024_2025\n",
            "ê·¸ëœë“œ_ìŠ¤íƒ€ë ‰ìŠ¤_2016_2018\t     F150_2004_2021\n",
            "ì‹¼íƒ€í˜_ë”_í”„ë¼ì„_2016_2018\t     F_PACE_2017_2019\n",
            "ë”_ë„¥ìŠ¤íŠ¸_ìŠ¤íŒŒí¬_2016_2018\t     G4_ë ‰ìŠ¤í„´_2018_2020\n",
            "ë”_ë‰´_ë§¥ìŠ¤í¬ë£¨ì¦ˆ_2016_2018\t     G70_2018_2020\n",
            "ë”_ë‰´_ì½”ë€ë„_ìŠ¤í¬ì¸ _2016_2018\t     ë”_ë‰´_G70_2021_2025\n",
            "ë ˆì¸ì§€ë¡œë²„_ì´ë³´í¬_2016_2019\t     G80_2017_2020\n",
            "ì•„ì´ì˜¤ë‹‰_í•˜ì´ë¸Œë¦¬ë“œ_2016_2019\t     ë”_ì˜¬ë‰´G80_2021_2024\n",
            "í‹°ë³¼ë¦¬_ì—ì–´_2016_2019\t\t     ë‰´_G80_2025_2026\n",
            "ì„íŒ”ë¼_2016_2019\t\t     G80_RG3_2021_2023\n",
            "ì¿ í¼_ì»¨íŠ¸ë¦¬ë§¨_2016_2024\t\t     G80_RG3_2025\n",
            "ì¿ í¼_ì»¨ë²„í„°ë¸”_2016_2024\t\t     G90_2019_2022\n",
            "ì¿ í¼_í´ëŸ½ë§¨_2016_2024\t\t     G90_RS4_2022_2025\n",
            "ì•Œí‹°ë§ˆ_2017_2018\t\t     GLA_í´ë˜ìŠ¤_H247_2020_2025\n",
            "ì˜¬_ë‰´_ë§ë¦¬ë¶€_2017_2018\t\t     GLA_í´ë˜ìŠ¤_X156_2015_2019\n",
            "ì˜¬_ë‰´_ì¹´ë§ˆë¡œ_2017_2018\t\t     GLB_í´ë˜ìŠ¤_X247_2020_2023\n",
            "ë‹ˆë¡œ_2017_2019\t\t\t     GLC_í´ë˜ìŠ¤_X253_2017_2019\n",
            "ë”_ë‰´_ëª¨í•˜ë¹„_2017_2019\t\t     GLC_í´ë˜ìŠ¤_X253_2020_2022\n",
            "ì½°íŠ¸ë¡œí¬ë¥´í…Œ_2017_2022\t\t     GLC_í´ë˜ìŠ¤_X253_2023\n",
            "ë¥´ë°˜ë–¼_2017_2022\t\t     GLC_í´ë˜ìŠ¤_X254_2023_2025\n",
            "ë”_ë‰´_íŠ¸ë™ìŠ¤_2017_2022\t\t     GLE_í´ë˜ìŠ¤_W166_2016_2018\n",
            "ë ˆì¸ì§€ë¡œë²„_ë²¨ë¼_2018_2019\t     GLE_í´ë˜ìŠ¤_W167_2019_2024\n",
            "ìµìŠ¤í”Œë¡œëŸ¬_2018_2019\t\t     GLS_í´ë˜ìŠ¤_X166_2017_2019\n",
            "í‹°ë³¼ë¦¬_ì•„ë¨¸_2018_2019\t\t     GLS_í´ë˜ìŠ¤_X167_2020_2024\n",
            "ì˜ë‚˜íƒ€_ë‰´_ë¼ì´ì¦ˆ_2018_2019\t     ê·¸ëœì €_GN7_2023_2025\n",
            "ìŠ¤í† ë‹‰_2018_2020\t\t     ì»¨í‹°ë„¨íƒˆ_GT_2ì„¸ëŒ€_2012_2017\n",
            "ìŠ¤íŒ…ì–´_2018_2020\t\t     ì»¨í‹°ë„¨íƒˆ_GT_3ì„¸ëŒ€_2018_2023\n",
            "ì½”ë‚˜_2018_2020\t\t\t     íŒŒì‚¬íŠ¸_GT_B8_2018_2022\n",
            "ë”_ë‰´_ì˜ë Œí† _2018_2020\t\t     GV70_2021_2023\n",
            "ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _2018_2021\t\t     ì¼ë ‰íŠ¸ë¦¬íŒŒì´ë“œ_GV70_2022_2024\n",
            "ë”_ë‰´_ê·¸ëœë“œ_ìŠ¤íƒ€ë ‰ìŠ¤_2018_2021      GV80_2020_2022\n",
            "ë”_ë‰´_ë ˆì´_2018_2022\t\t     ë‰´_GV80_2024_2025\n",
            "í‹°êµ¬ì•ˆ_ì˜¬ìŠ¤í˜ì´ìŠ¤_2018_2023\t     GV80_2024_2025\n",
            "ì•„í…Œì˜¨_2018_2023\t\t     G_í´ë˜ìŠ¤_W463_2009_2017\n",
            "ë„¥ì˜_2018_2024\t\t\t     G_í´ë˜ìŠ¤_W463b_2019_2025\n",
            "ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _ì¹¸_2019_2020\t     ê·¸ëœì €_HG_2011_2014\n",
            "ë”_ë‰´_ì¹´ë‹ˆë°œ_2019_2020\t\t     ê·¸ëœì €_HG_2015_2017\n",
            "ë§ˆì¹¸_2019_2021\t\t\t     i30_PD_2017_2018\n",
            "íŒ°ë¦¬ì„¸ì´ë“œ_2019_2022\t\t     i4_2022_2024\n",
            "ìŠ¤í¬í‹°ì§€_ë”_ë³¼ë“œ_2019_2022\t     ê·¸ëœì €_IG_2017_2019\n",
            "ë”_ë‰´_ë§ë¦¬ë¶€_2019_2022\t\t     ë”_ë‰´_ê·¸ëœì €_IG_2020_2023\n",
            "ë”_ë‰´_ìŠ¤íŒŒí¬_2019_2022\t\t     iX_2022_2024\n",
            "ë ˆë‹ˆê²Œì´ë“œ_2019_2023\t\t     ì˜¬_ë‰´_ëª¨ë‹_JA_2017_2020\n",
            "ë·°í‹°í’€_ì½”ë€ë„_2019_2024\t\t     ëª¨ë‹_ì–´ë°˜_JA_2021_2023\n",
            "ë”_ë‰´_ì•„ì´ì˜¤ë‹‰_í•˜ì´ë¸Œë¦¬ë“œ_2020\t     ë”_ë‰´_ëª¨ë‹_JA_2024_2025\n",
            "ì½œë¡œë¼ë„_2020_2020\t\t     ë­ê¸€ëŸ¬_JK_2009_2017\n",
            "ì½”ì„¸ì–´_2020_2022\t\t     ë­ê¸€ëŸ¬_JL_2018_2024\n",
            "ë”_ë‰´_ë‹ˆë¡œ_2020_2022\t\t     ë²¨ë¡œìŠ¤í„°_JS_2018_2020\n",
            "íŠ¸ë˜ë²„ìŠ¤_2020_2023\t\t     ê¸€ë˜ë””ì—ì´í„°_JT_2020_2023\n",
            "ì…€í† ìŠ¤_2020_2023\t\t     K3_2013_2015\n",
            "ë² ë¦¬_ë‰´_í‹°ë³¼ë¦¬_2020_2023\t     ë”_ë‰´_K3_2016_2018\n",
            "ëª¨í•˜ë¹„_ë”_ë§ˆìŠ¤í„°_2020_2024\t     ì˜¬_ë‰´_K3_2019_2021\n",
            "ë² ë‰´_2020_2024\t\t\t     ë”_ë‰´_K3_2ì„¸ëŒ€_2022_2024\n",
            "íŠ¸ë ˆì¼ë¸”ë ˆì´ì €_2021_2022\t     K5_2ì„¸ëŒ€_2016_2018\n",
            "í‹°ë³¼ë¦¬_ì—ì–´_2021_2022\t\t     ë”_ë‰´_K5_2ì„¸ëŒ€_2019_2020\n",
            "ë¦¬ì–¼_ë‰´_ì½œë¡œë¼ë„_2021_2022\t     K5_3ì„¸ëŒ€_í•˜ì´ë¸Œë¦¬ë“œ_2020_2022\n",
            "ìŠ¤íŒ…ì–´_ë§ˆì´ìŠ¤í„°_2021_2023\t     K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2020_2023\n",
            "ë”_ì˜¬ë‰´íˆ¬ì‹¼_í•˜ì´ë¸Œë¦¬ë“œ_2021_2023     K5_3ì„¸ëŒ€_2020_2023\n",
            "ë”_ë‰´_ì‹¼íƒ€í˜_2021_2023\t\t     ë”_ë‰´_K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2023_2025\n",
            "ë”_ë‰´_ì½”ë‚˜_2021_2023\t\t     ë”_ë‰´_K5_3ì„¸ëŒ€_2024_2025\n",
            "íƒ€ì´ì¹¸_2021_2025\t\t     ë”_ë‰´_K7_2013_2016\n",
            "ë”_ë‰´_ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _ì¹¸_2021_2025     ì˜¬_ë‰´_K7_2016_2019\n",
            "ë”_ë‰´_ë ‰ìŠ¤í„´_ìŠ¤í¬ì¸ _2021_2025\t     ì˜¬_ë‰´_K7_í•˜ì´ë¸Œë¦¬ë“œ_2017_2019\n",
            "ì˜¬_ë‰´_ë ‰ìŠ¤í„´_2021_2025\t\t     K7_í”„ë¦¬ë¯¸ì–´_í•˜ì´ë¸Œë¦¬ë“œ_2020_2021\n",
            "ìºìŠ¤í¼_2022_2024\t\t     K7_í”„ë¦¬ë¯¸ì–´_2020_2021\n",
            "ë§ˆì¹¸_2022_2024\t\t\t     K8_í•˜ì´ë¸Œë¦¬ë“œ_2022_2024\n",
            "ë””_ì˜¬_ë‰´_ìŠ¤í¬í‹°ì§€_2022_2024\t     K8_2022_2024\n",
            "ìŠ¤íƒ€ë¦¬ì•„_2022_2025\t\t     ë”_K9_2019_2021\n",
            "ë””_ì˜¬ë‰´ë‹ˆë¡œ_2022_2025\t\t     ë”_ë‰´_K9_2ì„¸ëŒ€_2022_2025\n",
            "ë”_ë‰´_ê¸°ì•„_ë ˆì´_2022_2025\t     ì²´ë¡œí‚¤_KL_2019_2023\n",
            "ë””_ì˜¬_ë‰´_ë‹ˆë¡œ_2022_2025\t\t     ë””íœë”_L663_2020_2025\n",
            "íŠ¸ë ˆì¼ë¸”ë ˆì´ì €_2023\t\t     LF_ì˜ë‚˜íƒ€_2015_2017\n",
            "ë”_ë‰´_íŒ°ë¦¬ì„¸ì´ë“œ_2023_2024\t     íŒ°ë¦¬ì„¸ì´ë“œ_LX3_2025\n",
            "í† ë ˆìŠ¤_2023_2025\t\t     M2_F87_2016_2021\n",
            "ë””_ì˜¬ë‰´ê·¸ëœì €_2023_2025\t\t     M4_F82_2015_2020\n",
            "ë””_ì˜¬ë‰´ì½”ë‚˜_2023_2025\t\t     M5_F90_2018_2023\n",
            "ë”_ë‰´_ì…€í† ìŠ¤_2023_2025\t\t     ì•„ë°˜ë–¼_MD_2011_2014\n",
            "íŠ¸ë™ìŠ¤_í¬ë¡œìŠ¤ì˜¤ë²„_2024_2025\t     MKC_2015_2018\n",
            "ë””_ì˜¬ë‰´ì‹¼íƒ€í˜_2024_2025\t\t     ë‰´_MKZ_2017_2020\n",
            "ê·¸ë‘_ì½œë ˆì˜¤ìŠ¤_2025\t\t     ì‹¼íƒ€í˜_MX5_2024_2025\n",
            "ë ˆì¸ì§€ë¡œë²„_ìŠ¤í¬ì¸ _2ì„¸ëŒ€_2013_2017    ì•„ë°˜ë–¼_N_2022_2023\n",
            "ë ˆì¸ì§€ë¡œë²„_ìŠ¤í¬ì¸ _2ì„¸ëŒ€_2018_2022    New_XF_2012_2015\n",
            "ì»´íŒ¨ìŠ¤_2ì„¸ëŒ€_2018_2022\t\t     íˆ¬ì‹¼_NX4_2021_2023\n",
            "ë ˆì¸ì§€ë¡œë²„_ì´ë³´í¬_2ì„¸ëŒ€_2020_2022    ë”_ë‰´_íˆ¬ì‹¼_NX4_2023_2025\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_ìŠ¤í¬ì¸ _2ì„¸ëŒ€_2020_2025    ì¹´ì´ì—”_PO536_2019_2023\n",
            "ì—ë¹„ì—ì´í„°_2ì„¸ëŒ€_2020_2025\t     Q30_2017_2019\n",
            "ë ˆì¸ì§€ë¡œë²„_ì´ë³´í¬_2ì„¸ëŒ€_2023_2024    Q3_F3_2020_2024\n",
            "ì•¡í‹°ì–¸_2ì„¸ëŒ€_2025\t\t     Q50_2014_2017\n",
            "2ì‹œë¦¬ì¦ˆ_ê·¸ë€ì¿ í˜_F44_2020_2024\t     Q5_FY_2020\n",
            "2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_F45_2019_2021  Q5_FY_2021_2024\n",
            "2ì‹œë¦¬ì¦ˆ_ì•¡í‹°ë¸Œ_íˆ¬ì–´ëŸ¬_U06_2022_2024  Q7_4M_2016_2019\n",
            "3008_2ì„¸ëŒ€_2018_2023\t\t     Q7_4M_2020_2023\n",
            "íŒŒì¼ëŸ¿_3ì„¸ëŒ€_2016_2018\t\t     Q8_4M_2020_2025\n",
            "ëª¨ë¸_3_2019_2022\t\t     QM3_2014_2017\n",
            "íˆ¬ì•„ë ‰_3ì„¸ëŒ€_2020_2023\t\t     ë‰´QM3_2018_2019\n",
            "ëª¨ë¸_3_2024_2025\t\t     ë‰´_QM5_2012_2014\n",
            "3ì‹œë¦¬ì¦ˆ_E90_2005_2012\t\t     QM6_2017_2019\n",
            "3ì‹œë¦¬ì¦ˆ_F30_2013_2018\t\t     ë”_ë‰´_QM6_2020_2023\n",
            "3ì‹œë¦¬ì¦ˆ_G20_2019_2022\t\t     ë‰´_QM6_2021_2023\n",
            "3ì‹œë¦¬ì¦ˆ_G20_2023_2025\t\t     ë”_ë‰´_QM6_2024_2025\n",
            "3ì‹œë¦¬ì¦ˆ_GT_F34_2014_2021\t     QX60_2016_2018\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_4_2010_2016\t\t     ë‰´ì˜ë Œí† _R_2013_2014\n",
            "ë ˆì¸ì§€ë¡œë²„_4ì„¸ëŒ€_2014_2017\t     ë”_ë‰´ìŠ¤í¬í‹°ì§€R_2014_2016\n",
            "ëª¬ë°ì˜¤_4ì„¸ëŒ€_2015_2020\t\t     RAV4_2016_2018\n",
            "ìŠ¤í¬í‹°ì§€_4ì„¸ëŒ€_2016_2018\t     RAV4_5ì„¸ëŒ€_2019_2024\n",
            "í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2016_2018\t     S60_3ì„¸ëŒ€_2020_2024\n",
            "ë ˆì¸ì§€ë¡œë²„_4ì„¸ëŒ€_2018_2022\t     S90_2017_2020\n",
            "í”„ë¦¬ìš°ìŠ¤_4ì„¸ëŒ€_2019_2022\t     S90_2021_2025\n",
            "ì¹´ë‹ˆë°œ_4ì„¸ëŒ€_2021\t\t     SM3_ë„¤ì˜¤_2015_2019\n",
            "ì˜ë Œí† _4ì„¸ëŒ€_2021_2023\t\t     ë‰´_SM5_ì„í”„ë ˆì…˜_2008_2010\n",
            "ì‹œì—ë‚˜_4ì„¸ëŒ€_2021_2024\t\t     ë‰´_SM5_í”Œë˜í‹°ë„˜_2013_2014\n",
            "ì¹´ë‹ˆë°œ_4ì„¸ëŒ€_2022_2023\t\t     SM5_ë…¸ë°”_2015_2019\n",
            "ë”_ë‰´_ì¹´ë‹ˆë°œ_4ì„¸ëŒ€_2024_2025\t     SM6_2016_2020\n",
            "ë”_ë‰´_ì˜ë Œí† _4ì„¸ëŒ€_2024_2025\t     ë”_ë‰´_SM6_2021_2024\n",
            "ë¼ë¸Œ4_4ì„¸ëŒ€_2013_2018\t\t     SM7_ë‰´ì•„íŠ¸_2008_2011\n",
            "ë¼ë¸Œ4_5ì„¸ëŒ€_2019_2024\t\t     SM7_ë…¸ë°”_2015_2019\n",
            "4ì‹œë¦¬ì¦ˆ_F32_2014_2020\t\t     S_í´ë˜ìŠ¤_W221_2006_2013\n",
            "4ì‹œë¦¬ì¦ˆ_G22_2021_2023\t\t     S_í´ë˜ìŠ¤_W222_2014_2020\n",
            "4ì‹œë¦¬ì¦ˆ_G22_2024_2025\t\t     S_í´ë˜ìŠ¤_W223_2021_2025\n",
            "5008_2ì„¸ëŒ€_2018_2019\t\t     ì½”ë‚˜_SX2_2023_2025\n",
            "5008_2ì„¸ëŒ€_2021_2024\t\t     ê·¸ëœì €TG_2007_2008\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_5_2017_2020\t\t     ì˜¬_ë‰´_íˆ¬ì‹¼_TL_2016_2018\n",
            "ì—ìŠ¤ì»¬ë ˆì´ë“œ_5ì„¸ëŒ€_2021_2024\t     ì˜¬_ë‰´_íˆ¬ì‹¼_TL_2019_2020\n",
            "ì•„ì´ì˜¤ë‹‰5_2022_2023\t\t     ì‹¼íƒ€í˜_TM_2019_2020\n",
            "ë””ìŠ¤ì»¤ë²„ë¦¬_5_2022_2024\t\t     UX250h_2019_2024\n",
            "ìŠ¤í¬í‹°ì§€_5ì„¸ëŒ€_2022_2024\t     V40_2015_2018\n",
            "ë ˆì¸ì§€ë¡œë²„_5ì„¸ëŒ€_2023_2024\t     V60_í¬ë¡œìŠ¤ì»¨íŠ¸ë¦¬_2ì„¸ëŒ€_2020_2025\n",
            "5ì‹œë¦¬ì¦ˆ_F10_2010_2016\t\t     V90_í¬ë¡œìŠ¤ì»¨íŠ¸ë¦¬_2018_2024\n",
            "5ì‹œë¦¬ì¦ˆ_G30_2017_2023\t\t     ë‰´_ì²´ì–´ë§¨_W_2012_2016\n",
            "5ì‹œë¦¬ì¦ˆ_G60_2024_2025\t\t     ê·¸ëœë“œ_ì²´ë¡œí‚¤_WL_2021_2023\n",
            "5ì‹œë¦¬ì¦ˆ_GT_F07_2010_2017\t     X1_F48_2016_2019\n",
            "ìµìŠ¤í”Œë¡œëŸ¬_6ì„¸ëŒ€_2020_2025\t     X1_F48_2020_2022\n",
            "ì•„ì´ì˜¤ë‹‰6_2023_2025\t\t     X1_U11_2023_2024\n",
            "6ì‹œë¦¬ì¦ˆ_F12_2011_2018\t\t     X2_F39_2018_2023\n",
            "6ì‹œë¦¬ì¦ˆ_GT_G32_2018_2020\t     X3_G01_2018_2021\n",
            "6ì‹œë¦¬ì¦ˆ_GT_G32_2021_2024\t     X3_G01_2022_2024\n",
            "ë°•ìŠ¤í„°_718_2017_2024\t\t     X4_F26_2015_2018\n",
            "718_ë°•ìŠ¤í„°_2017_2024\t\t     X4_G02_2019_2021\n",
            "718_ì¹´ì´ë§¨_2017_2024\t\t     X4_G02_2022_2025\n",
            "ê³¨í”„_7ì„¸ëŒ€_2013_2016\t\t     X5_F15_2014_2018\n",
            "7ì‹œë¦¬ì¦ˆ_F01_2009_2015\t\t     X5_G05_2019_2023\n",
            "7ì‹œë¦¬ì¦ˆ_G11_2016_2018\t\t     X5_G05_2024_2025\n",
            "7ì‹œë¦¬ì¦ˆ_G11_2019_2022\t\t     X6_F16_2015_2019\n",
            "7ì‹œë¦¬ì¦ˆ_G70_2023_2025\t\t     X6_G06_2020_2023\n",
            "8ì‹œë¦¬ì¦ˆ_G15_2020_2024\t\t     X6_G06_2024_2025\n",
            "911_2003_2019\t\t\t     X7_G07_2019_2022\n",
            "911_992_2020_2024\t\t     X7_G07_2023_2025\n",
            "íŒŒë‚˜ë©”ë¼_971_2017_2023\t\t     XC40_2019_2022\n",
            "A4_B9_2016_2019\t\t\t     XC60_2ì„¸ëŒ€_2018_2021\n",
            "A4_B9_2020_2024\t\t\t     XC60_2ì„¸ëŒ€_2022_2025\n",
            "A5_F5_2019_2024\t\t\t     XC90_2ì„¸ëŒ€_2017_2019\n",
            "ë‰´_A6_2012_2014\t\t\t     XC90_2ì„¸ëŒ€_2020_2025\n",
            "ë‰´_A6_2015_2018\t\t\t     XE_2016_2019\n",
            "A6_C8_2019_2025\t\t\t     XF_X260_2016_2020\n",
            "A7_2012_2016\t\t\t     XJ_8ì„¸ëŒ€_2010_2019\n",
            "A7_4K_2020_2024\t\t\t     XM3_2020_2023\n",
            "A8_D5_2018_2023\t\t\t     XM3_2024\n",
            "ì•„ë°˜ë–¼_AD_2016_2018\t\t     ìº ë¦¬_XV70_2018_2024\n",
            "ë”_ë‰´_ì•„ë°˜ë–¼_AD_2019_2020\t     ëª¨ë¸_Y_2021_2025\n",
            "All_New_XJ_2016_2019\t\t     YFì˜ë‚˜íƒ€_2009_2012\n",
            "AMG_GT_2016_2024\t\t     YFì˜ë‚˜íƒ€_í•˜ì´ë¸Œë¦¬ë“œ_2011_2015\n",
            "A_í´ë˜ìŠ¤_W176_2015_2018\t\t     Z4_G29_2019_2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "metadata": {
        "id": "eyLBp4j3i6F1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train ê²½ë¡œ\n",
        "train_dir = '/content/train'\n",
        "\n",
        "# test ê²½ë¡œ\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# sample_submission (ì¶”ë¡  ë•Œ ì‚¬ìš©)\n",
        "sample_submission_path = '/content/sample_submission.csv'\n"
      ],
      "metadata": {
        "id": "Ybtf0x5si9CE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB ë‹¨ìœ„\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB ë‹¨ìœ„\n",
        "    print(f\"ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# í˜„ì¬ CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "if torch.cuda.is_available():\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU ìºì‹œ ë° ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\nğŸ§¹ GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
        "    print(\"ğŸ” ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"âŒ CUDA ì‚¬ìš© ë¶ˆê°€\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxuQLgBAmkIm",
        "outputId": "136ea32c-fa63-4a1d-a33b-cac7b24eb0f9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” ì´ˆê¸°í™” ì „ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = 0.00 MB | Reserved = 0.00 MB\n",
            "\n",
            "ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™” ì™„ë£Œ\n",
            "ğŸ” ì´ˆê¸°í™” í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ:\n",
            "ğŸ“Š í˜„ì¬ GPU ë©”ëª¨ë¦¬ ìƒíƒœ: Allocated = 0.00 MB | Reserved = 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CarImageDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None, use_aspect=False, use_color=False):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # ğŸš— Step 1: Load Image (RGB ê³ ì •)\n",
        "        image_pil = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        # ğŸš— Step 2: Calculate Features if needed\n",
        "        width, height = image_pil.size\n",
        "        aspect_ratio = np.array([width / height], dtype=np.float32)\n",
        "\n",
        "        image_cv2 = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "        color_mean = image_cv2.mean(axis=(0, 1))\n",
        "        color_mean = color_mean[::-1]\n",
        "        color_mean = np.array(color_mean / 255.0, dtype=np.float32)\n",
        "\n",
        "        # ğŸš— Step 3: Apply Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image_pil)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image_pil)  # fallback\n",
        "\n",
        "        # ğŸš— Step 4: Extract label\n",
        "        class_name = os.path.basename(os.path.dirname(path))\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # ğŸš— Step 5: Return according to mode\n",
        "        if self.use_aspect and self.use_color:\n",
        "            return image, torch.tensor(aspect_ratio), torch.tensor(color_mean), label\n",
        "        elif self.use_aspect:\n",
        "            return image, torch.tensor(aspect_ratio), label\n",
        "        elif self.use_color:\n",
        "            return image, torch.tensor(color_mean), label\n",
        "        else:\n",
        "            return image, label\n"
      ],
      "metadata": {
        "id": "rtI0lYOuJZt5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# âœ… ì „ì²´ JPG íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸° (Train)\n",
        "file_list = glob.glob('/content/train/*/*.jpg')\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ëª… ì¶”ì¶œ (í´ë”ëª…)\n",
        "def extract_class_name_jpg(path):\n",
        "    return os.path.basename(os.path.dirname(path))\n",
        "\n",
        "class_names = sorted(set(extract_class_name_jpg(f) for f in file_list))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"âœ… í´ë˜ìŠ¤ ìˆ˜: {len(class_to_idx)}\")  # 396ê°œ ë‚˜ì™€ì•¼ ì •ìƒ\n",
        "\n",
        "# âœ… ë¼ë²¨ ìƒì„±\n",
        "labels = [class_to_idx[extract_class_name_jpg(f)] for f in file_list]\n",
        "\n",
        "# âœ… Train/Val Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_files, val_files = train_test_split(file_list, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "# âœ… Transform ì •ì˜\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… í™•ì¥í˜• Dataset í´ë˜ìŠ¤ (ì•ì„œ ë§Œë“  ë²„ì „ ì‚¬ìš©!)\n",
        "class CarImageDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None, use_aspect=False, use_color=False):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # ğŸš— Load Image (RGB ê³ ì •)\n",
        "        image_pil = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        # ğŸš— Feature: Aspect Ratio\n",
        "        width, height = image_pil.size\n",
        "        aspect_ratio = torch.tensor([width / height], dtype=torch.float32)\n",
        "\n",
        "        # ğŸš— Feature: Dominant Color (mean RGB)\n",
        "        image_np = np.array(image_pil)\n",
        "        color_mean = image_np.mean(axis=(0, 1)) / 255.0  # Normalize to 0~1\n",
        "        color_mean = torch.tensor(color_mean, dtype=torch.float32)\n",
        "\n",
        "        # ğŸš— Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image_pil)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image_pil)\n",
        "\n",
        "        # ğŸš— Label\n",
        "        class_name = extract_class_name_jpg(path)\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # ğŸš— Return mode\n",
        "        if self.use_aspect and self.use_color:\n",
        "            return image, aspect_ratio, color_mean, label\n",
        "        elif self.use_aspect:\n",
        "            return image, aspect_ratio, label\n",
        "        elif self.use_color:\n",
        "            return image, color_mean, label\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "# âœ… ì‹¤í—˜ ì„¤ì • (Base / Aspect / Color / Aspect+Color)\n",
        "USE_ASPECT = False    # ì‹¤í—˜ A â†’ Base / True â†’ ì‹¤í—˜ B/D\n",
        "USE_COLOR = False     # ì‹¤í—˜ A â†’ Base / True â†’ ì‹¤í—˜ C/D\n",
        "\n",
        "# âœ… Dataset ì •ì˜\n",
        "train_dataset = CarImageDataset(train_files, class_to_idx, train_transform, use_aspect=USE_ASPECT, use_color=USE_COLOR)\n",
        "val_dataset = CarImageDataset(val_files, class_to_idx, val_transform, use_aspect=USE_ASPECT, use_color=USE_COLOR)\n",
        "\n",
        "# âœ… DataLoader ì •ì˜\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "u2DB9tCSJcmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "035b9958-6e33-48c8-d5b2-454cc449afdb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… í´ë˜ìŠ¤ ìˆ˜: 396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import timm\n",
        "import torch\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, use_aspect, use_color, num_classes):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "\n",
        "        # âœ… EfficientNet-B5 backbone\n",
        "        self.backbone = timm.create_model('efficientnet_b5', pretrained=True, num_classes=0)  # feature extractor\n",
        "        backbone_out_features = self.backbone.num_features\n",
        "\n",
        "        # âœ… Meta feature dimension ê³„ì‚°\n",
        "        meta_features_dim = 0\n",
        "        if self.use_aspect:\n",
        "            meta_features_dim += 1  # aspect ratio 1ê°œ\n",
        "        if self.use_color:\n",
        "            meta_features_dim += 3  # color_mean (R, G, B) 3ê°œ\n",
        "\n",
        "        # âœ… Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(backbone_out_features + meta_features_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, aspect_ratio=None, color_mean=None):\n",
        "        # âœ… EfficientNet feature\n",
        "        x = self.backbone(image)\n",
        "\n",
        "        # âœ… Meta features concat\n",
        "        aux_list = []\n",
        "\n",
        "        if self.use_aspect:\n",
        "            aux_list.append(aspect_ratio)\n",
        "\n",
        "        if self.use_color:\n",
        "            aux_list.append(color_mean)\n",
        "\n",
        "        if aux_list:\n",
        "            aux_features = torch.cat(aux_list, dim=1)\n",
        "            x = torch.cat([x, aux_features], dim=1)\n",
        "\n",
        "        # âœ… Final classifier\n",
        "        out = self.classifier(x)\n",
        "        return out\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tNalQaGrKS5u"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AdamW + weight_decay ì¶”ê°€ ì¶”ì²œ (EffNet ê³„ì—´ì— ë§ì´ ì‚¬ìš©)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "JNIgNO9AKcl1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import copy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# âœ… device ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… ì „ì²´ jpg íŒŒì¼\n",
        "file_list = glob.glob('/content/train/*/*.jpg')\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ëª… ì¶”ì¶œ\n",
        "def extract_class_name_jpg(path):\n",
        "    return os.path.basename(os.path.dirname(path))\n",
        "\n",
        "class_names = sorted(set(extract_class_name_jpg(f) for f in file_list))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"âœ… í´ë˜ìŠ¤ ìˆ˜: {len(class_to_idx)}\")\n",
        "\n",
        "# âœ… ë¼ë²¨ ìƒì„±\n",
        "labels = [class_to_idx[extract_class_name_jpg(f)] for f in file_list]\n",
        "\n",
        "# âœ… Aspect Ratio Feature í•¨ìˆ˜\n",
        "def compute_aspect_ratio(path):\n",
        "    with Image.open(path) as img:\n",
        "        w, h = img.size\n",
        "        return w / h\n",
        "\n",
        "# âœ… Dominant Color Feature í•¨ìˆ˜ (ê°„ë‹¨í•œ RGB í‰ê·  ì‚¬ìš©)\n",
        "def compute_dominant_color(path):\n",
        "    with Image.open(path).convert(\"RGB\") as img:\n",
        "        img = img.resize((16, 16))  # ì‘ì€ í¬ê¸°ë¡œ ì¤„ì—¬ì„œ í‰ê·  ê³„ì‚°\n",
        "        np_img = np.array(img) / 255.0\n",
        "        mean_color = np_img.mean(axis=(0, 1))  # R, G, B í‰ê· \n",
        "        return mean_color  # (3,)\n",
        "\n",
        "# âœ… Dataset í´ë˜ìŠ¤ ì •ì˜ (JPGìš©)\n",
        "class CarJPGDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None, use_aspect=False, use_color=False):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        class_name = extract_class_name_jpg(path)\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        meta_features = []\n",
        "\n",
        "        # âœ… Aspect Ratio ì¶”ê°€\n",
        "        if self.use_aspect:\n",
        "            ar = compute_aspect_ratio(path)\n",
        "            meta_features.append(ar)\n",
        "\n",
        "        # âœ… Dominant Color ì¶”ê°€\n",
        "        if self.use_color:\n",
        "            color = compute_dominant_color(path)  # (3,)\n",
        "            meta_features.extend(color.tolist())\n",
        "\n",
        "        # if meta_features:\n",
        "        #     meta_features = torch.tensor(meta_features, dtype=torch.float32)\n",
        "        #     return image, meta_features, label\n",
        "        # else:\n",
        "        #     return image, label\n",
        "        if meta_features:\n",
        "            meta_features = torch.tensor(meta_features, dtype=torch.float32)\n",
        "        else:\n",
        "            meta_features = torch.zeros(3, dtype=torch.float32)  # <= Dummy tensor (0,0,0)\n",
        "\n",
        "        return image, meta_features, label\n",
        "# âœ… transform ì •ì˜\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "# âœ… StratifiedKFold ì •ì˜\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# âœ… ì „ëµ ì„¤ì • (ì „ëµ C)\n",
        "EXPERIMENT = \"C\"  # A / B / C / D\n",
        "\n",
        "use_aspect = False\n",
        "use_color = True\n",
        "\n",
        "print(f\"\\nğŸš€ ì‹¤í—˜ ì„¤ì •: {EXPERIMENT} (Aspect={use_aspect}, Color={use_color})\\n\")\n",
        "\n",
        "# âœ… 5-Fold ë£¨í”„ ì‹œì‘\n",
        "# for fold, (train_idx, val_idx) in enumerate(skf.split(file_list, labels)):\n",
        "#     print(f\"\\n==============================\")\n",
        "#     print(f\"ğŸ” Fold {fold + 1} / 5\")\n",
        "#     print(f\"==============================\\n\")\n",
        "\n",
        "#     # âœ… Foldë³„ split\n",
        "#     train_files = [file_list[i] for i in train_idx]\n",
        "#     val_files = [file_list[i] for i in val_idx]\n",
        "\n",
        "#     # âœ… Foldë³„ Dataset & DataLoader\n",
        "#     train_dataset = CarJPGDataset(train_files, class_to_idx, train_transform, use_aspect, use_color)\n",
        "#     val_dataset = CarJPGDataset(val_files, class_to_idx, val_transform, use_aspect, use_color)\n",
        "\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "#     val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "#     # âœ… Foldë³„ model / criterion / optimizer ì´ˆê¸°í™”\n",
        "#     model = CustomModel(use_aspect=use_aspect, use_color=use_color, num_classes=396)\n",
        "#     model = model.to(device)\n",
        "\n",
        "#     criterion = torch.nn.CrossEntropyLoss()\n",
        "#     optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "#     # âœ… EarlyStopping ë³€ìˆ˜ ì´ˆê¸°í™”\n",
        "#     best_val_loss = float('inf')\n",
        "#     patience = 3\n",
        "#     patience_counter = 0\n",
        "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # âœ… Epoch ë£¨í”„\n",
        "    # for epoch in range(1, 31):\n",
        "    #     print(f\"\\nğŸ“Œ Fold {fold+1} | Epoch {epoch}\")\n",
        "\n",
        "    #     # === í•™ìŠµ ===\n",
        "    #     model.train()\n",
        "    #     train_loss = 0.0\n",
        "    #     train_correct = 0\n",
        "\n",
        "    #     loop = tqdm(train_loader, desc=f\"Train Fold {fold+1}\", leave=False)\n",
        "    #     for batch in loop:\n",
        "    #         # âœ… ì „ëµ C (USE_COLOR=True)\n",
        "    #         if use_aspect and use_color:\n",
        "    #             X, meta_aspect, meta_color, y = batch\n",
        "    #             X, meta_aspect, meta_color, y = X.to(device), meta_aspect.to(device), meta_color.to(device), y.to(device)\n",
        "    #             outputs = model(X, aspect_ratio=meta_aspect, color_mean=meta_color)\n",
        "    #         elif use_aspect:\n",
        "    #             X, meta_aspect, y = batch\n",
        "    #             X, meta_aspect, y = X.to(device), meta_aspect.to(device), y.to(device)\n",
        "    #             outputs = model(X, aspect_ratio=meta_aspect)\n",
        "    #         elif use_color:\n",
        "    #             X, meta_color, y = batch\n",
        "    #             X, meta_color, y = X.to(device), meta_color.to(device), y.to(device)\n",
        "    #             outputs = model(X, color_mean=meta_color)\n",
        "    #         else:\n",
        "    #             X, y = batch\n",
        "    #             X, y = X.to(device), y.to(device)\n",
        "    #             outputs = model(X)\n",
        "\n",
        "    #         loss = criterion(outputs, y)\n",
        "    #         optimizer.zero_grad()\n",
        "    #         loss.backward()\n",
        "    #         optimizer.step()\n",
        "\n",
        "    #         train_loss += loss.item() * X.size(0)\n",
        "    #         train_correct += (outputs.argmax(1) == y).sum().item()\n",
        "    #         loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    #     train_loss /= len(train_loader.dataset)\n",
        "    #     train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "    #     # === ê²€ì¦ ===\n",
        "    #     model.eval()\n",
        "    #     val_loss = 0.0\n",
        "    #     val_correct = 0\n",
        "\n",
        "    #     val_loop = tqdm(val_loader, desc=f\"Valid Fold {fold+1}\", leave=False)\n",
        "    #     with torch.no_grad():\n",
        "    #         for batch in val_loop:\n",
        "    #             if use_aspect and use_color:\n",
        "    #                 X, meta_aspect, meta_color, y = batch\n",
        "    #                 X, meta_aspect, meta_color, y = X.to(device), meta_aspect.to(device), meta_color.to(device), y.to(device)\n",
        "    #                 outputs = model(X, aspect_ratio=meta_aspect, color_mean=meta_color)\n",
        "    #             elif use_aspect:\n",
        "    #                 X, meta_aspect, y = batch\n",
        "    #                 X, meta_aspect, y = X.to(device), meta_aspect.to(device), y.to(device)\n",
        "    #                 outputs = model(X, aspect_ratio=meta_aspect)\n",
        "    #             elif use_color:\n",
        "    #                 X, meta_color, y = batch\n",
        "    #                 X, meta_color, y = X.to(device), meta_color.to(device), y.to(device)\n",
        "    #                 outputs = model(X, color_mean=meta_color)\n",
        "    #             else:\n",
        "    #                 X, y = batch\n",
        "    #                 X, y = X.to(device), y.to(device)\n",
        "    #                 outputs = model(X)\n",
        "\n",
        "    #             loss = criterion(outputs, y)\n",
        "    #             val_loss += loss.item() * X.size(0)\n",
        "    #             val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "    #             val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    #     val_loss /= len(val_loader.dataset)\n",
        "    #     val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "    #     # === ë¡œê·¸ ì¶œë ¥ ===\n",
        "    #     print(f\"âœ… Fold {fold+1} | Epoch {epoch} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "    #     print(f\"âœ… Fold {fold+1} | Epoch {epoch} | Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "    #     # === EarlyStopping ===\n",
        "    #     if val_loss < best_val_loss:\n",
        "    #         best_val_loss = val_loss\n",
        "    #         best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    #         save_path = f\"/content/drive/MyDrive/team_models/EffNetB5_{EXPERIMENT}_fold{fold+1}.pth\"\n",
        "    #         torch.save(model.state_dict(), save_path)\n",
        "    #         print(f\"ğŸ“¦ Best model saved for Fold {fold+1}!\")\n",
        "    #         patience_counter = 0\n",
        "    #     else:\n",
        "    #         patience_counter += 1\n",
        "    #         print(f\"âš ï¸ EarlyStopping patience: {patience_counter}/{patience}\")\n",
        "    #         if patience_counter >= patience:\n",
        "    #             print(\"â›” Early stopping triggered.\")\n",
        "    #             break\n",
        "\n",
        "    # # âœ… Fold ëë‚˜ê³  Best ëª¨ë¸ ë¡œë“œ\n",
        "    # model.load_state_dict(best_model_wts)\n",
        "    # print(f\"âœ… Fold {fold+1} Best model loaded.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZJkMSSKeiG",
        "outputId": "83dd85b3-625d-4986-f106-9be62e7d9992"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… í´ë˜ìŠ¤ ìˆ˜: 396\n",
            "\n",
            "ğŸš€ ì‹¤í—˜ ì„¤ì •: C (Aspect=False, Color=True)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì˜ˆì‹œ: fold1 ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "# ì˜¬ë°”ë¥¸ êµ¬ì¡°ë¡œ ëª¨ë¸ì„ ë¨¼ì € ì„ ì–¸í•œ ë‹¤ìŒ, ê·¸ ì „ì²´ êµ¬ì¡°ì— ë§ê²Œ weightë¥¼ ë¡œë“œí•´ì•¼ í•¨\n",
        "model = CustomModel(use_aspect=False, use_color=True, num_classes=396).to(device)\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold1.pth\"))\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold2.pth\"))\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold3.pth\"))\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold4.pth\"))\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold5.pth\"))\n",
        "\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBEK7kgk4Q8m",
        "outputId": "bdec14ed-74f6-4588-8899-d7daf40abdc7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (backbone): EfficientNet(\n",
              "    (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1056, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (8): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Identity()\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=2051, out_features=512, bias=True)\n",
              "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.3, inplace=False)\n",
              "    (4): Linear(in_features=512, out_features=396, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "# âœ… ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, use_aspect, use_color, num_classes):\n",
        "        super().__init__()\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "        self.backbone = timm.create_model(\n",
        "            'tf_efficientnet_b5',\n",
        "            pretrained=False,\n",
        "            num_classes=0\n",
        "        )\n",
        "        meta_dim = (1 if use_aspect else 0) + (3 if use_color else 0)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.backbone.num_features + meta_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, aspect_ratio=None, color_mean=None):\n",
        "        x = self.backbone(image)\n",
        "        aux = []\n",
        "        if self.use_aspect:\n",
        "            aux.append(aspect_ratio)\n",
        "        if self.use_color:\n",
        "            aux.append(color_mean)\n",
        "        if aux:\n",
        "            x = torch.cat([x] + aux, dim=1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# âœ… ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "TEST_DIR = \"/content/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/sample_submission.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# âœ… í´ë˜ìŠ¤ëª… ì¶”ì¶œ\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]\n",
        "\n",
        "# âœ… TTA transform 3ì¢…\n",
        "tta_transforms = [\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((456, 456)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((456, 456)),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((456, 456)),\n",
        "        transforms.RandomRotation(degrees=15),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]\n",
        "\n",
        "# âœ… Color í‰ê· ê°’ ì¶”ì¶œ\n",
        "def compute_dominant_color(path):\n",
        "    with Image.open(path).convert(\"RGB\") as img:\n",
        "        img = img.resize((16, 16))\n",
        "        np_img = np.array(img) / 255.0\n",
        "        return np_img.mean(axis=(0, 1))\n",
        "\n",
        "# âœ… Dataset\n",
        "class TestTTADataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        self.image_paths = sorted([\n",
        "            os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if fname.endswith('.jpg')\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.image_paths[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")  # âœ… PIL.Image ìœ ì§€\n",
        "        color_mean = compute_dominant_color(path)\n",
        "        color_tensor = torch.tensor(color_mean, dtype=torch.float32)\n",
        "        fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "        return img, color_tensor, fname\n",
        "\n",
        "# âœ… collate_fn ì •ì˜ (PIL ì´ë¯¸ì§€ + Tensor + stringì„ ì²˜ë¦¬)\n",
        "def custom_collate(batch):\n",
        "    imgs, colors, fnames = zip(*batch)\n",
        "    return list(imgs), torch.stack(colors), list(fnames)\n",
        "\n",
        "# âœ… DataLoader ì„¤ì •\n",
        "test_dataset = TestTTADataset(TEST_DIR)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    collate_fn=custom_collate\n",
        ")\n",
        "\n",
        "# âœ… ëª¨ë¸ weight ê²½ë¡œ\n",
        "model_paths = [f\"/content/drive/MyDrive/team_models/EffNetB5_C_fold{i}.pth\" for i in range(1, 6)]\n",
        "\n",
        "# âœ… ì¶”ë¡  ìˆ˜í–‰\n",
        "all_probs = []\n",
        "\n",
        "for fold, path in enumerate(model_paths):\n",
        "    print(f\"\\nğŸ“¦ Fold {fold+1} weight ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: {path}\")\n",
        "    model = CustomModel(use_aspect=False, use_color=True, num_classes=NUM_CLASSES).to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    fold_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, color_mean, fnames in tqdm(test_loader, desc=f\"TTA Fold {fold+1}\"):\n",
        "            color_mean = color_mean.to(device)\n",
        "            tta_outputs = []\n",
        "\n",
        "            for tta_transform in tta_transforms:\n",
        "                # ê° ì´ë¯¸ì§€ì— transform ì ìš©\n",
        "                imgs_tta = torch.stack([tta_transform(i) for i in imgs]).to(device)\n",
        "                outputs = model(imgs_tta, color_mean=color_mean)\n",
        "                probs = F.softmax(outputs, dim=1)\n",
        "                tta_outputs.append(probs)\n",
        "\n",
        "            tta_avg = torch.mean(torch.stack(tta_outputs), dim=0)\n",
        "            fold_probs.append(tta_avg.cpu().numpy())\n",
        "\n",
        "    fold_probs = np.concatenate(fold_probs, axis=0)\n",
        "    all_probs.append(fold_probs)\n",
        "\n",
        "# âœ… ì•™ìƒë¸” í‰ê· \n",
        "final_probs = np.mean(np.stack(all_probs, axis=0), axis=0)\n",
        "\n",
        "# âœ… ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "results = []\n",
        "for i, (img_path, prob) in enumerate(zip(test_dataset.image_paths, final_probs)):\n",
        "    fname = os.path.basename(img_path).replace(\".jpg\", \"\")\n",
        "    row = {\"ID\": fname}\n",
        "    row.update({col: prob[idx] for idx, col in enumerate(column_names)})\n",
        "    results.append(row)\n",
        "\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "save_path = \"/content/drive/MyDrive/team_models/submission_TTA_fold5_C.csv\"\n",
        "submission_df.to_csv(save_path, index=False)\n",
        "\n",
        "print(f\"\\nâœ… TTA ê¸°ë°˜ ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR2yIn0h3Rhx",
        "outputId": "4d2beb2b-3699-4737-db0f-6052b911323b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ Fold 1 weight ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: /content/drive/MyDrive/team_models/EffNetB5_C_fold1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA Fold 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [09:46<00:00,  4.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ Fold 2 weight ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: /content/drive/MyDrive/team_models/EffNetB5_C_fold2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA Fold 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [09:46<00:00,  4.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ Fold 3 weight ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: /content/drive/MyDrive/team_models/EffNetB5_C_fold3.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA Fold 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [09:45<00:00,  4.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ Fold 4 weight ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: /content/drive/MyDrive/team_models/EffNetB5_C_fold4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA Fold 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [09:43<00:00,  4.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“¦ Fold 5 weight ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘: /content/drive/MyDrive/team_models/EffNetB5_C_fold5.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TTA Fold 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [09:47<00:00,  4.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… TTA ê¸°ë°˜ ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/team_models/submission_TTA_fold5_C.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/team_models/submission_TTA_fold5_C.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "HxzI2CBJOY_z",
        "outputId": "613e5601-b3d3-48d1-b012-c6220012581a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f403b6af-d4d3-4695-8855-e9697d498813\", \"submission_TTA_fold5_C.csv\", 42425188)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# âœ… ê³ ì • ê²½ë¡œ\n",
        "TEST_DIR = \"/content/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/sample_submission.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# âœ… ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' ì œì™¸\n",
        "\n",
        "# âœ… Transform (JPGìš©)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… Dominant Color ê³„ì‚° í•¨ìˆ˜\n",
        "def compute_dominant_color(path):\n",
        "    with Image.open(path).convert(\"RGB\") as img:\n",
        "        img = img.resize((16, 16))\n",
        "        np_img = np.array(img) / 255.0\n",
        "        mean_color = np_img.mean(axis=(0, 1))\n",
        "        return mean_color  # (3,)\n",
        "\n",
        "# âœ… í…ŒìŠ¤íŠ¸ìš© Dataset (JPGìš© + color_mean í¬í•¨)\n",
        "class TestJPGDatasetWithColor(Dataset):\n",
        "    def __init__(self, img_root, transform=None):\n",
        "        self.file_list = []\n",
        "        for file in os.listdir(img_root):\n",
        "            if file.endswith('.jpg'):\n",
        "                self.file_list.append(os.path.join(img_root, file))\n",
        "        self.file_list.sort()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        # color_mean ê³„ì‚°\n",
        "        color_mean = compute_dominant_color(path)\n",
        "        color_mean = torch.tensor(color_mean, dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "        return image, color_mean, fname\n",
        "\n",
        "# âœ… DataLoader ê³ ì •\n",
        "test_dataset = TestJPGDatasetWithColor(TEST_DIR, transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=4\n",
        ")\n",
        "\n",
        "# âœ… ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… ì‹¤í—˜ ë¦¬ìŠ¤íŠ¸ (ì „ëµ Cë§Œ!)\n",
        "exp_list = [\"C\"]\n",
        "\n",
        "# âœ… ë¹„êµ ê²°ê³¼ ì €ì¥ìš© (submission í•©ì¹˜ê¸°)\n",
        "all_submissions = []\n",
        "\n",
        "# # âœ… ì‹¤í—˜ ë£¨í”„ ì‹œì‘\n",
        "# for exp_name in exp_list:\n",
        "#     print(f\"\\n==============================\")\n",
        "#     print(f\"ğŸš€ START INFERENCE: EXPERIMENT {exp_name}\")\n",
        "#     print(f\"==============================\\n\")\n",
        "\n",
        "#     # âœ… ëª¨ë¸ ê²½ë¡œ ìë™ ìƒì„±\n",
        "#     FOLD_MODEL_PATHS = [\n",
        "#         f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold1.pth\",\n",
        "#         f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold2.pth\",\n",
        "#         f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold3.pth\",\n",
        "#         f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold4.pth\",\n",
        "#         f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold5.pth\",\n",
        "#     ]\n",
        "\n",
        "#     # âœ… ì•™ìƒë¸” ê²°ê³¼ ì´ˆê¸°í™”\n",
        "#     ensemble_outputs = []\n",
        "\n",
        "#     # âœ… Fold ëª¨ë¸ ìˆœì„œëŒ€ë¡œ ì¶”ë¡ \n",
        "#     for fold_idx, model_path in enumerate(FOLD_MODEL_PATHS):\n",
        "#         print(f\"\\nğŸš€ Inference with Fold {fold_idx + 1} Model: {model_path}\")\n",
        "\n",
        "#         # âœ… ë°˜ë“œì‹œ CustomModel ë¡œë“œ (ì „ëµ C)\n",
        "#         model = CustomModel(use_aspect=False, use_color=True, num_classes=NUM_CLASSES)\n",
        "#         model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "#         model.to(device)\n",
        "#         model.eval()\n",
        "\n",
        "#         # foldë³„ output ì €ì¥\n",
        "#         fold_probs = []\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for imgs, color_mean, names in tqdm(test_loader, desc=f\"ğŸ” Fold {fold_idx + 1} Inference\"):\n",
        "#                 imgs = imgs.to(device)\n",
        "#                 color_mean = color_mean.to(device)\n",
        "\n",
        "#                 outputs = model(imgs, color_mean=color_mean)\n",
        "#                 probs = F.softmax(outputs, dim=1)\n",
        "#                 fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "#         fold_probs = np.concatenate(fold_probs, axis=0)\n",
        "#         ensemble_outputs.append(fold_probs)\n",
        "\n",
        "#     # âœ… ì•™ìƒë¸” í‰ê· \n",
        "#     ensemble_outputs = np.stack(ensemble_outputs, axis=0)  # (num_folds, num_samples, num_classes)\n",
        "#     mean_outputs = np.mean(ensemble_outputs, axis=0)       # (num_samples, num_classes)\n",
        "\n",
        "#     # âœ… ê²°ê³¼ ì €ì¥\n",
        "#     results = []\n",
        "#     for idx, path in enumerate(test_dataset.file_list):\n",
        "#         fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "#         row = {\"ID\": fname}\n",
        "#         row.update({class_name: mean_outputs[idx, i] for i, class_name in enumerate(column_names)})\n",
        "#         results.append(row)\n",
        "\n",
        "#     submission_df = pd.DataFrame(results)\n",
        "#     submission_df = submission_df[[\"ID\"] + column_names]\n",
        "\n",
        "#     # âœ… íŒŒì¼ ì €ì¥\n",
        "#     SAVE_SUBMISSION_PATH = f\"/content/drive/MyDrive/team_models/submission_fold5_ensemble_{exp_name}.csv\"\n",
        "#     submission_df.to_csv(SAVE_SUBMISSION_PATH, index=False)\n",
        "\n",
        "#     print(f\"\\nâœ… ì•™ìƒë¸” ì„œë¸Œë¯¸ì…˜ ì €ì¥ ì™„ë£Œ: {SAVE_SUBMISSION_PATH}\")\n",
        "\n",
        "#     # âœ… ë¹„êµìš©ìœ¼ë¡œ all_submissionsì— ì €ì¥\n",
        "#     submission_df[\"experiment\"] = exp_name\n",
        "#     all_submissions.append(submission_df)\n",
        "\n",
        "# # âœ… ìµœì¢… ë¹„êµìš© DataFrame ë§Œë“¤ê¸°\n",
        "# final_compare_df = pd.concat(all_submissions, axis=0)\n",
        "# compare_save_path = \"/content/drive/MyDrive/team_models/all_experiments_submission_compare.csv\"\n",
        "# final_compare_df.to_csv(compare_save_path, index=False)\n",
        "\n",
        "# print(f\"\\nğŸ‰ ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ! ë¹„êµìš© CSV ì €ì¥ë¨: {compare_save_path}\")\n"
      ],
      "metadata": {
        "id": "k61x77gkNSDG",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # âœ… ì „ëµ C ì•™ìƒë¸” ê²°ê³¼ë¬¼ ê²½ë¡œ\n",
        "# submission_path = \"/content/drive/MyDrive/team_models/submission_fold5_ensemble_C.csv\"\n",
        "\n",
        "# # âœ… ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
        "# files.download(submission_path)\n",
        "\n",
        "# # âœ… ì „ì²´ ë¹„êµ CSV ë‹¤ìš´ë¡œë“œ\n",
        "# compare_path = \"/content/drive/MyDrive/team_models/all_experiments_submission_compare.csv\"\n",
        "\n",
        "# files.download(compare_path)\n"
      ],
      "metadata": {
        "id": "G8IEkAgaXKJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast          # âœ… ê²½ë¡œ ìˆ˜ì •\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. í™˜ê²½ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Teacher ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "teacher = CustomModel(use_aspect=False, use_color=True, num_classes=396)\n",
        "teacher.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold1.pth\"))\n",
        "teacher = teacher.to(device).half()                     # âœ… FP16 ë³€í™˜\n",
        "teacher.eval()\n",
        "for p in teacher.parameters():                         # âœ… Freeze\n",
        "    p.requires_grad = False\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Student ëª¨ë¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "student = CustomModel(use_aspect=False, use_color=True, num_classes=396).to(device)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. ì˜µí‹°ë§ˆì´ì € & ë¡œìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "alpha      = 0.7        # ğŸ”¥ KD ë¹„ì¤‘\n",
        "T_init     = 2.0\n",
        "T_min      = 1.0\n",
        "T_decay    = 0.95\n",
        "\n",
        "kd_crit    = nn.KLDivLoss(reduction='batchmean')\n",
        "ce_crit    = nn.CrossEntropyLoss()\n",
        "optimizer  = torch.optim.AdamW(student.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "scaler     = GradScaler()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. ë°ì´í„°ë¡œë” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "train_ds = CarJPGDataset(train_files, class_to_idx, train_transform, use_aspect, use_color)\n",
        "val_ds   = CarJPGDataset(val_files,   class_to_idx, val_transform,   use_aspect, use_color)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True,  num_workers=4,\n",
        "                          pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=4,\n",
        "                          pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. í•™ìŠµ ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "num_epochs     = 50\n",
        "patience       = 5\n",
        "best_val_loss  = float('inf')\n",
        "early_counter  = 0\n",
        "T              = T_init\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "\n",
        "    # ======== Train ========\n",
        "    student.train()\n",
        "    train_loss, n_samples = 0.0, 0\n",
        "    loop = tqdm(train_loader, desc=f\"[Epoch {epoch}] Train\")\n",
        "\n",
        "    for imgs, metas, labels in loop:\n",
        "        imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "\n",
        "        # ---- Teacher forward (FP16) ----\n",
        "        with torch.no_grad():\n",
        "            t_logits = teacher(imgs.half(), color_mean=metas.half())\n",
        "            soft_lbl = F.softmax(t_logits / T, dim=1).detach()     # âœ… detach\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        # ---- Student forward ----\n",
        "        with autocast():\n",
        "            s_logits   = student(imgs, color_mean=metas)\n",
        "            logp_s     = F.log_softmax(s_logits / T, dim=1)\n",
        "\n",
        "            kd_loss    = kd_crit(logp_s, soft_lbl) * (T * T)\n",
        "            ce_loss    = ce_crit(s_logits, labels)\n",
        "            loss       = alpha * kd_loss + (1 - alpha) * ce_loss\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student.parameters(), 5.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "        n_samples  += imgs.size(0)\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = train_loss / n_samples\n",
        "    print(f\"ğŸŸ¢ Epoch {epoch}: Avg Train Loss = {avg_train_loss:.4f}\")\n",
        "\n",
        "    # ======== Validation ========\n",
        "    student.eval()\n",
        "    val_loss, val_correct, val_total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, metas, labels in val_loader:\n",
        "            imgs, metas, labels = imgs.to(device), metas.to(device), labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                s_logits  = student(imgs, color_mean=metas)\n",
        "                logp_s    = F.log_softmax(s_logits / T, dim=1)\n",
        "\n",
        "                t_logits  = teacher(imgs.half(), color_mean=metas.half())\n",
        "                soft_lbl  = F.softmax(t_logits / T, dim=1)\n",
        "\n",
        "                kd_loss   = kd_crit(logp_s, soft_lbl) * (T * T)\n",
        "                ce_loss   = ce_crit(s_logits, labels)\n",
        "                loss      = alpha * kd_loss + (1 - alpha) * ce_loss\n",
        "\n",
        "            val_loss   += loss.item() * imgs.size(0)\n",
        "            preds       = s_logits.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total   += labels.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / val_total\n",
        "    val_acc      = val_correct / val_total\n",
        "    print(f\"ğŸ”µ Validation: Loss={avg_val_loss:.4f} | Acc={val_acc:.4f}\")\n",
        "\n",
        "    # ======== Early-Stopping ========\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        early_counter = 0\n",
        "        torch.save(student.state_dict(),\n",
        "                   \"/content/drive/MyDrive/team_models/Student_stage2_fold1_best.pth\")\n",
        "        print(\"ğŸ’¾ Best model saved!\")\n",
        "    else:\n",
        "        early_counter += 1\n",
        "        print(f\"â³ EarlyStopping {early_counter}/{patience}\")\n",
        "        if early_counter >= patience:\n",
        "            print(\"ğŸ›‘ Early stopping.\")\n",
        "            break\n",
        "\n",
        "    # ======== Scheduler & T update ========\n",
        "    scheduler.step()                         # âœ… optimizer.step ë’¤\n",
        "    T = max(T_min, T * T_decay)              # âœ… val ì´í›„ì— ì—…ë°ì´íŠ¸\n",
        "\n",
        "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n"
      ],
      "metadata": {
        "id": "QHn6wXuwqc4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# âœ… ê²½ë¡œ ì„¤ì •\n",
        "TEST_DIR = \"/content/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/sample_submission.csv\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/team_models/EffNetB5_C_fold1.pth\"\n",
        "SUBMISSION_SAVE_PATH = \"/content/drive/MyDrive/team_models/submission_stage2_student.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# âœ… ìƒ˜í”Œ ì œì¶œ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ëª… ì¶”ì¶œ\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' ì œì™¸\n",
        "\n",
        "# âœ… Transform ì •ì˜\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# âœ… Dominant Color ê³„ì‚° í•¨ìˆ˜\n",
        "def compute_dominant_color(path):\n",
        "    with Image.open(path).convert(\"RGB\") as img:\n",
        "        img = img.resize((16, 16))\n",
        "        np_img = np.array(img) / 255.0\n",
        "        mean_color = np_img.mean(axis=(0, 1))\n",
        "        return mean_color  # (3,)\n",
        "\n",
        "# âœ… Test Dataset ì •ì˜\n",
        "class TestJPGDatasetWithColor(Dataset):\n",
        "    def __init__(self, img_root, transform=None):\n",
        "        self.file_list = []\n",
        "        for file in os.listdir(img_root):\n",
        "            if file.endswith('.jpg'):\n",
        "                self.file_list.append(os.path.join(img_root, file))\n",
        "        self.file_list.sort()\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "\n",
        "        # color_mean ê³„ì‚°\n",
        "        color_mean = compute_dominant_color(path)\n",
        "        color_mean = torch.tensor(color_mean, dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "        return image, color_mean, fname\n",
        "\n",
        "# âœ… DataLoader\n",
        "test_dataset = TestJPGDatasetWithColor(TEST_DIR, transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=6,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=4\n",
        ")\n",
        "\n",
        "# âœ… ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… ëª¨ë¸ ë¡œë“œ (Student ëª¨ë¸)\n",
        "student = CustomModel(use_aspect=False, use_color=True, num_classes=NUM_CLASSES)\n",
        "student.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "student = student.to(device)\n",
        "student.eval()\n",
        "\n",
        "# âœ… ì¶”ë¡ \n",
        "predictions = []\n",
        "file_names = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, color_mean, names in tqdm(test_loader, desc=\"ğŸ” Student Model Inference\"):\n",
        "        imgs = imgs.to(device)\n",
        "        color_mean = color_mean.to(device)\n",
        "\n",
        "        outputs = student(imgs, color_mean=color_mean)\n",
        "        probs = F.softmax(outputs, dim=1)  # ì†Œí”„íŠ¸ë§¥ìŠ¤ í™•ë¥ \n",
        "\n",
        "        predictions.append(probs.cpu().numpy())\n",
        "        file_names.extend(names)\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# âœ… ê²°ê³¼ ì €ì¥\n",
        "results = []\n",
        "for idx, fname in enumerate(file_names):\n",
        "    row = {\"ID\": fname}\n",
        "    row.update({class_name: predictions[idx, i] for i, class_name in enumerate(column_names)})\n",
        "    results.append(row)\n",
        "\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "\n",
        "# âœ… CSVë¡œ ì €ì¥\n",
        "submission_df.to_csv(SUBMISSION_SAVE_PATH, index=False, encoding = 'utf-8-sig')\n",
        "print(f\"\\nâœ… Submission ì €ì¥ ì™„ë£Œ: {SUBMISSION_SAVE_PATH}\")\n"
      ],
      "metadata": {
        "id": "1BlGU3jTGlFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb98c1fd-64f1-4647-c44b-db952201aaab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ğŸ” Student Model Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [00:26<00:00,  4.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Submission ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/team_models/submission_stage2_student.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "# âœ… GPU ë©”ëª¨ë¦¬ ì´ˆê¸°í™”\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# âœ… 1. Teacher ëª¨ë¸ ì¤€ë¹„ (Freeze)\n",
        "teacher = CustomModel(use_aspect=False, use_color=True, num_classes=396)\n",
        "teacher.load_state_dict(torch.load(\"/content/drive/MyDrive/team_models/EffNetB5_C_fold1.pth\"))\n",
        "teacher = teacher.to(device)\n",
        "teacher.eval()\n",
        "for param in teacher.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# âœ… 2. Student ëª¨ë¸ ì¤€ë¹„\n",
        "student = CustomModel(use_aspect=False, use_color=True, num_classes=396)\n",
        "student = student.to(device)\n",
        "\n",
        "# âœ… 3. Optimizer, Criterion, Scaler\n",
        "T_init = 2.0\n",
        "T_min = 1.0\n",
        "T_decay = 0.95\n",
        "\n",
        "train_criterion = nn.KLDivLoss(reduction='batchmean')\n",
        "val_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(student.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# âœ… 4. Dataset & DataLoader\n",
        "train_dataset = CarImageDataset(train_files, class_to_idx, train_transform)\n",
        "val_dataset = CarImageDataset(val_files, class_to_idx, val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4,\n",
        "                          pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4,\n",
        "                        pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "# âœ… 5. Resume Checkpoint\n",
        "checkpoint_path = \"/content/drive/MyDrive/team_models/Student_stage2_fold1_best.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location='cuda')\n",
        "\n",
        "student.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "start_epoch = checkpoint['epoch'] + 1   # ë”± ë‹¤ìŒ ì—í¬í¬ë¶€í„°\n",
        "best_val_loss = checkpoint['best_val_loss']\n",
        "\n",
        "print(f\"âœ… Resumed training from Epoch {start_epoch}\")\n",
        "\n",
        "# âœ… 6. Stage 2 í•™ìŠµ ì´ì–´ê°€ê¸°\n",
        "num_epochs = 50\n",
        "patience = 5\n",
        "counter = 0\n",
        "T = T_init * (T_decay ** (start_epoch - 1))  # ì´ì „ T ê°’ ë³µêµ¬\n",
        "\n",
        "for epoch in range(start_epoch, num_epochs + 1):\n",
        "    student.train()\n",
        "    total_loss = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=f\"Stage2 Epoch {epoch}\")\n",
        "    for images, meta_features, _ in loop:\n",
        "        images = images.to(device)\n",
        "        meta_features = meta_features.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pseudo_logits = teacher(images, color_mean=meta_features)\n",
        "            pseudo_soft_labels = F.softmax(pseudo_logits / T, dim=1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = student(images, color_mean=meta_features)\n",
        "            student_log_probs = F.log_softmax(outputs / T, dim=1)\n",
        "            loss = train_criterion(student_log_probs, pseudo_soft_labels) * (T * T)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(student.parameters(), max_norm=5.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        total_samples += images.size(0)\n",
        "\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_loss / total_samples\n",
        "    print(f\"ğŸ“š Stage2 Epoch {epoch}: Train Loss={avg_train_loss:.4f}\")\n",
        "\n",
        "    # ğŸ”¥ Temperature ìŠ¤ì¼€ì¤„ë§\n",
        "    T = max(T_min, T * T_decay)\n",
        "\n",
        "    # âœ… Validation\n",
        "    student.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, meta_features, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            meta_features = meta_features.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = student(images, color_mean=meta_features)\n",
        "                loss = val_criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    avg_val_loss = val_loss / val_total\n",
        "    val_acc = val_correct / val_total\n",
        "    print(f\"ğŸ“š Validation Loss={avg_val_loss:.4f} | Validation Accuracy={val_acc:.4f}\")\n",
        "\n",
        "    # âœ… Early Stopping Check\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        counter = 0\n",
        "        torch.save(student.state_dict(), \"/content/drive/MyDrive/team_models/Student_stage2_fold1_best.pth\")\n",
        "        print(f\"âœ… Best model saved at Epoch {epoch}!\")\n",
        "\n",
        "        # âœ… Checkpoint ì €ì¥\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': student.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'scaler_state_dict': scaler.state_dict(),\n",
        "            'best_val_loss': best_val_loss,\n",
        "        }\n",
        "        torch.save(checkpoint, checkpoint_path)\n",
        "        print(f\"âœ… Checkpoint saved at Epoch {epoch}!\")\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"âš ï¸ EarlyStopping patience: {counter}/{patience}\")\n",
        "        if counter >= patience:\n",
        "            print(\"â›” Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(\"âœ… í•™ìŠµ ì™„ë£Œ!\")\n"
      ],
      "metadata": {
        "id": "6pII8rBMltnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}