{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuFjEO54yG2ikA3/NTeNKH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/Untitled7_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmYsCxRuHATb"
      },
      "outputs": [],
      "source": [
        "# 구글 드라이브 마운트\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 압축 해제\n",
        "!unzip -oq \"/content/drive/MyDrive/Colab Notebooks/open.zip\" -d /content/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/model.py\" /content/\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/dataset.py\" /content/"
      ],
      "metadata": {
        "id": "RVQBCxiCHC6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 완전 삭제 및 강제 재로드\n",
        "import sys\n",
        "if 'model' in sys.modules:\n",
        "    del sys.modules['model']\n",
        "\n",
        "import importlib\n",
        "import model\n",
        "importlib.reload(model)\n",
        "\n",
        "from model import ColorAwareEffNetB5\n"
      ],
      "metadata": {
        "id": "msgwgiNiHDtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import CustomImageDataset"
      ],
      "metadata": {
        "id": "fXuGwsRqHEaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 반드시 먼저 실행되어야 함\n",
        "%cp '/content/drive/MyDrive/Colab Notebooks/model.py' /content/\n",
        "from model import ColorAwareEffNetB5\n"
      ],
      "metadata": {
        "id": "_KESHDMFHFC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ CLASS_ALIAS 반영된 학습용 전체 코드\n",
        "\n",
        "# 1. 라이브러리 임포트\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
        "from PIL import Image\n",
        "\n",
        "# 2. CLASS_ALIAS 정의\n",
        "CLASS_ALIAS = {\n",
        "    'K5_하이브리드_3세대_2020_2023': 'K5_3세대_하이브리드_2020_2022',\n",
        "    '디_올_뉴_니로_2022_2025': '디_올뉴니로_2022_2025',\n",
        "    '박스터_718_2017_2024': '718_박스터_2017_2024'\n",
        "}\n",
        "\n",
        "# 3. CustomImageDataset 정의\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        self.classes = sorted({CLASS_ALIAS.get(c, c) for c in os.listdir(root_dir)})\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        for cls_name in os.listdir(root_dir):\n",
        "            normalized = CLASS_ALIAS.get(cls_name, cls_name)\n",
        "            cls_path = os.path.join(root_dir, cls_name)\n",
        "            for fname in os.listdir(cls_path):\n",
        "                if fname.lower().endswith('.jpg'):\n",
        "                    img_path = os.path.join(cls_path, fname)\n",
        "                    label = self.class_to_idx[normalized]\n",
        "                    self.samples.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image_tensor = self.transform(image)\n",
        "        else:\n",
        "            image_tensor = transforms.ToTensor()(image)  # 기본 텐서화 처리\n",
        "\n",
        "        color_feat = self.extract_color_feature(image_tensor)\n",
        "\n",
        "        return image_tensor, label, color_feat\n",
        "\n",
        "    def extract_color_feature(self, image_tensor):\n",
        "        mean = image_tensor.view(3, -1).mean(dim=1)\n",
        "        std = image_tensor.view(3, -1).std(dim=1)\n",
        "        return torch.cat([mean, std], dim=0)\n",
        "\n",
        "# 4. 모델 정의\n",
        "class ColorAwareEffNetB5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ColorAwareEffNetB5, self).__init__()\n",
        "        self.base_model = efficientnet_b5(weights=EfficientNet_B5_Weights.IMAGENET1K_V1)\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "        self.feature_dim = 2048\n",
        "        self.color_fc = nn.Linear(6, 32)\n",
        "        self.fc = nn.Linear(self.feature_dim + 32, num_classes)\n",
        "\n",
        "    def forward(self, x, color_feat):\n",
        "        x = self.base_model(x)\n",
        "        color_feat = self.color_fc(color_feat)\n",
        "        x = torch.cat((x, color_feat), dim=1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# 5. 환경 설정\n",
        "CFG = {\n",
        "    'IMG_SIZE': 456,\n",
        "    'BATCH_SIZE': 16,\n",
        "    'EPOCHS': 10,\n",
        "    'LEARNING_RATE': 1e-4,\n",
        "    'SEED': 42\n",
        "}\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED'])\n",
        "\n",
        "# 6. 데이터 준비\n",
        "train_path = \"/content/train\"\n",
        "full_dataset = CustomImageDataset(train_path, transform=None)\n",
        "targets = [label for _, label, _ in full_dataset]\n",
        "class_names = full_dataset.classes\n",
        "print(f\"✅ 클래스 수: {len(class_names)}\")  # 반드시 396개여야 함\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    range(len(targets)), test_size=0.2, stratify=targets, random_state=CFG['SEED'])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((CFG['IMG_SIZE'], CFG['IMG_SIZE'])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Subset(CustomImageDataset(train_path, transform=train_transform), train_idx)\n",
        "val_dataset = Subset(CustomImageDataset(train_path, transform=val_transform), val_idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# 7. 모델 학습\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ColorAwareEffNetB5(num_classes=len(class_names)).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
        "scaler = GradScaler()\n",
        "\n",
        "best_logloss = float('inf')\n",
        "\n",
        "for epoch in range(CFG['EPOCHS']):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for images, labels, colors in tqdm(train_loader, desc=f\"[Epoch {epoch+1}] Training\"):\n",
        "        images, labels, colors = images.to(device), labels.to(device), colors.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = model(images, colors)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, colors in val_loader:\n",
        "            images, labels, colors = images.to(device), labels.to(device), colors.to(device)\n",
        "            with autocast():\n",
        "                outputs = model(images, colors)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    val_accuracy = 100 * correct / total\n",
        "    val_logloss = log_loss(all_labels, all_probs, labels=list(range(len(class_names))))\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.2f}% | LogLoss: {val_logloss:.4f}\")\n",
        "\n",
        "    if val_logloss < best_logloss:\n",
        "        best_logloss = val_logloss\n",
        "        torch.save(model.state_dict(), \"best_model_amp.pth\")\n",
        "        print(f\"\\n✅ Best model saved at Epoch {epoch+1} (logloss: {val_logloss:.4f})\\n\")\n"
      ],
      "metadata": {
        "id": "m1ASyCZBHF8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/best_model_amp.pth\", \"/content/best_model_fold1.pth\")\n",
        "shutil.copy(\"/content/best_model_amp.pth\", \"/content/best_model_fold2.pth\")\n",
        "shutil.copy(\"/content/best_model_amp.pth\", \"/content/best_model_fold3.pth\")\n"
      ],
      "metadata": {
        "id": "hM76t_TDHG1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"학습 클래스 수: {len(train_dataset.dataset.class_to_idx)}\")  # 393개\n"
      ],
      "metadata": {
        "id": "Hvh_jvTzHKUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 전체 통합 추론 코드 (396 클래스 확장 포함)\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_b5, EfficientNet_B5_Weights\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ✅ 1. CLASS_ALIAS 정의\n",
        "CLASS_ALIAS = {\n",
        "    'K5_하이브리드_3세대_2020_2023': 'K5_3세대_하이브리드_2020_2022',\n",
        "    '디_올_뉴_니로_2022_2025': '디_올뉴니로_2022_2025',\n",
        "    '박스터_718_2017_2024': '718_박스터_2017_2024'\n",
        "}\n",
        "\n",
        "# ✅ 2. 클래스 목록\n",
        "train_root = \"/content/train\"\n",
        "all_class_names_396 = sorted(os.listdir(train_root))\n",
        "class_names_393 = sorted({CLASS_ALIAS.get(c, c) for c in all_class_names_396})\n",
        "class_to_index = {cls: i for i, cls in enumerate(all_class_names_396)}\n",
        "\n",
        "# ✅ 3. 확장 함수\n",
        "def expand_to_396(pred_393: np.ndarray) -> pd.DataFrame:\n",
        "    df = pd.DataFrame(pred_393, columns=class_names_393)\n",
        "    for alias, target in CLASS_ALIAS.items():\n",
        "        if alias not in df.columns:\n",
        "            df[alias] = df[target]\n",
        "    return df[all_class_names_396]  # 컬럼 순서 맞춤\n",
        "\n",
        "# ✅ 4. CustomImageDataset 정의\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False, test_df=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_test = is_test\n",
        "        self.samples = []\n",
        "\n",
        "        if is_test:\n",
        "            self.samples = [(row['ID'], os.path.join(root_dir, row['img_path'])) for _, row in test_df.iterrows()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id, img_path = self.samples[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image_tensor = self.transform(image) if self.transform else image\n",
        "        color_feat = self.extract_color_feature(image_tensor)\n",
        "        return sample_id, image_tensor, color_feat\n",
        "\n",
        "    def extract_color_feature(self, image_tensor):\n",
        "        mean = image_tensor.view(3, -1).mean(dim=1)\n",
        "        std = image_tensor.view(3, -1).std(dim=1)\n",
        "        return torch.cat([mean, std], dim=0)\n",
        "\n",
        "# ✅ 5. 모델 정의\n",
        "class ColorAwareEffNetB5(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ColorAwareEffNetB5, self).__init__()\n",
        "        self.base_model = efficientnet_b5(weights=EfficientNet_B5_Weights.IMAGENET1K_V1)\n",
        "        self.base_model.classifier = nn.Identity()\n",
        "        self.feature_dim = 2048\n",
        "        self.color_fc = nn.Linear(6, 32)\n",
        "        self.fc = nn.Linear(self.feature_dim + 32, num_classes)\n",
        "\n",
        "    def forward(self, x, color_feat):\n",
        "        x = self.base_model(x)\n",
        "        color_feat = self.color_fc(color_feat)\n",
        "        x = torch.cat([x, color_feat], dim=1)\n",
        "        return self.fc(x)\n",
        "\n",
        "# ✅ 6. 환경 설정\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\")\n",
        "num_classes = 393  # 학습 기준\n",
        "\n",
        "# ✅ 7. TTA Transform\n",
        "tta_transforms = [\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(p=1.0),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "]\n",
        "\n",
        "# ✅ 8. 모델 로딩 및 예측\n",
        "model_paths = [\n",
        "    \"/content/best_model_fold1.pth\",\n",
        "    \"/content/best_model_fold2.pth\",\n",
        "    \"/content/best_model_fold3.pth\"\n",
        "]\n",
        "\n",
        "submission_template = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "all_preds = []\n",
        "\n",
        "for i, path in enumerate(model_paths):\n",
        "    model = ColorAwareEffNetB5(num_classes=393).to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    tta_preds = []\n",
        "    for tta_transform in tta_transforms:\n",
        "        temp_dataset = CustomImageDataset(\"/content\", transform=tta_transform, is_test=True, test_df=test_df)\n",
        "        temp_loader = DataLoader(temp_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "        probs_list = []\n",
        "        with torch.no_grad():\n",
        "            for ids, images, colors in temp_loader:\n",
        "                images, colors = images.to(device), colors.to(device)\n",
        "                outputs = model(images, colors)\n",
        "                probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
        "                probs_list.append(probs)\n",
        "\n",
        "        tta_preds.append(np.concatenate(probs_list, axis=0))\n",
        "\n",
        "    mean_preds = np.mean(tta_preds, axis=0)\n",
        "    all_preds.append(mean_preds)\n",
        "\n",
        "    pred_df = expand_to_396(mean_preds)\n",
        "    model_submission = pd.concat([test_df[[\"ID\"]], pred_df], axis=1)\n",
        "    model_submission.to_csv(f\"/content/submission_model_{i+1}.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "    print(f\"✅ submission_model_{i+1}.csv 저장 완료\")\n",
        "\n",
        "# ✅ 9. 앙상블 평균 저장\n",
        "ensemble_preds = np.mean(all_preds, axis=0)\n",
        "ensemble_df = expand_to_396(ensemble_preds)\n",
        "ensemble_submission = pd.concat([test_df[[\"ID\"]], ensemble_df], axis=1)\n",
        "ensemble_submission.to_csv(\"/content/submission_ensemble.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ 앙상블 submission_ensemble.csv 저장 완료\")\n"
      ],
      "metadata": {
        "id": "fG0ubZqJHLEz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}