{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1B75A0nd3Ud9LN9u_qemX6Uy1b3ObwznA",
      "authorship_tag": "ABX9TyOlL5BsX47/ce4aj1gtht2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/test_%EC%A0%84%EC%B2%98%EB%A6%AC3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "peaMNLWchXQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juS4rlAhexwK",
        "outputId": "dfafcc6d-aed5-4622-9470-dcddca01abe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF"
      ],
      "metadata": {
        "id": "eyLBp4j3i6F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== 설정 =====\n",
        "test_csv_path = '/content/drive/MyDrive/open/test.csv'\n",
        "test_img_dir = '/content/drive/MyDrive/open/test'  # test 이미지 폴더\n",
        "save_root = '/content/drive/MyDrive/fuck/preprocessed_test'  # test 전처리 저장 위치\n",
        "os.makedirs(save_root, exist_ok=True)"
      ],
      "metadata": {
        "id": "Ybtf0x5si9CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Grayscale + Resize transform 정의\n",
        "# class SquarePad:\n",
        "#     def __call__(self, image):\n",
        "#         w, h = image.size\n",
        "#         max_wh = max(w, h)\n",
        "#         pad_left = (max_wh - w) // 2\n",
        "#         pad_top = (max_wh - h) // 2\n",
        "#         padding = (pad_left, pad_top, max_wh - w - pad_left, max_wh - h - pad_top)\n",
        "#         return TF.pad(image, padding, fill=0)\n",
        "\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Grayscale(num_output_channels=1),\n",
        "#     SquarePad(),\n",
        "#     transforms.Resize((384, 384)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.5], [0.5])\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "Dxb4JBcejAnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ===== Test CSV 읽기 =====\n",
        "# test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# # ✅ 수정된 부분: img_path에서 파일명만 추출\n",
        "# test_df['img_path'] = test_df['img_path'].apply(lambda x: os.path.basename(x))\n",
        "# test_df['full_img_path'] = test_df['img_path'].apply(lambda x: os.path.join(test_img_dir, x))\n",
        "# test_df['img_name_no_ext'] = test_df['img_path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])  # 'TEST_00000'\n",
        "\n",
        "# # ===== 전처리 시작 =====\n",
        "# counter = 0  # 전체 이미지 카운터\n",
        "# batch_index = 0  # batch_000, batch_001...\n",
        "# batch_limit = 800  # 한 폴더에 저장할 최대 개수\n",
        "\n",
        "# current_batch_dir = os.path.join(save_root, f\"batch_{batch_index:03}\")\n",
        "# os.makedirs(current_batch_dir, exist_ok=True)\n",
        "\n",
        "# print(\"📦 Test 전처리 시작...\")\n",
        "\n",
        "# for i, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "#     img_id = row['img_name_no_ext']  # TEST_00000\n",
        "#     img_path = row['full_img_path']\n",
        "\n",
        "#     try:\n",
        "#         img = Image.open(img_path).convert('RGB')\n",
        "#         img_tensor = transform(img)\n",
        "\n",
        "#         # 폴더 분할 조건\n",
        "#         if counter > 0 and counter % batch_limit == 0:\n",
        "#             batch_index += 1\n",
        "#             current_batch_dir = os.path.join(save_root, f\"batch_{batch_index:03}\")\n",
        "#             os.makedirs(current_batch_dir, exist_ok=True)\n",
        "\n",
        "#         # 저장 파일명: TEST_00000.npy\n",
        "#         save_name = f\"{img_id}.npy\"\n",
        "#         save_path = os.path.join(current_batch_dir, save_name)\n",
        "#         np.save(save_path, img_tensor.numpy())\n",
        "\n",
        "#         counter += 1\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"❌ 오류: {img_path} → {e}\")\n",
        "\n",
        "# print(f\"✅ Test 전처리 완료: 총 {counter}개 이미지 저장됨\")\n",
        "# print(f\"📂 배치 폴더 수: {batch_index + 1}\")"
      ],
      "metadata": {
        "id": "SqM_vaNwjLHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # 🚗 Test용 npy 파일 경로 (예시)\n",
        "# npy_path = '/content/drive/MyDrive/fuck/preprocessed_test/batch_000/TEST_00000.npy'\n",
        "\n",
        "# # npy 불러오기\n",
        "# img = np.load(npy_path)\n",
        "\n",
        "# # (1, H, W) → (H, W)\n",
        "# if img.shape[0] == 1:\n",
        "#     img = img.squeeze(0)\n",
        "\n",
        "# # 시각화\n",
        "# plt.imshow(img, cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.title(\"Test Grayscale 시각화\")\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "spSREKsVZ9R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# # Test JPG 파일 수 확인\n",
        "# jpg_count = 0\n",
        "# jpg_paths = []\n",
        "\n",
        "# test_dir = '/content/drive/MyDrive/open/test'\n",
        "# for file in os.listdir(test_dir):\n",
        "#     if file.lower().endswith('.jpg'):\n",
        "#         jpg_count += 1\n",
        "#         jpg_paths.append(file)  # 파일명만 저장 (TEST_00000.jpg 등)\n",
        "\n",
        "# print(f\"✅ Test 폴더 내 JPG 파일 수: {jpg_count}\")\n",
        "\n",
        "# # 전처리된 .npy 파일 수 확인\n",
        "# npy_dir = '/content/drive/MyDrive/fuck/preprocessed_test'\n",
        "# npy_count = 0\n",
        "# npy_files = []\n",
        "\n",
        "# # 모든 하위 폴더까지 탐색\n",
        "# for root, dirs, files in os.walk(npy_dir):\n",
        "#     for file in files:\n",
        "#         if file.endswith('.npy'):\n",
        "#             npy_count += 1\n",
        "#             npy_files.append(os.path.join(root, file))\n",
        "\n",
        "# print(f\"✅ 저장된 .npy 파일 수: {npy_count}\")\n",
        "\n",
        "# # ⛔ 중복 또는 추가 파일 의심 확인\n",
        "# # jpg_paths = ['TEST_00000.jpg', ...] → 대응되는 npy는 'TEST_00000.npy'\n",
        "# expected_npy_names = set([os.path.splitext(f)[0] + '.npy' for f in jpg_paths])\n",
        "# actual_npy_names = set([os.path.basename(f) for f in npy_files])\n",
        "\n",
        "# extra = actual_npy_names - expected_npy_names\n",
        "# missing = expected_npy_names - actual_npy_names\n",
        "\n",
        "# if len(extra) == 0 and len(missing) == 0:\n",
        "#     print(\"✅ 모든 파일 정상! JPG ↔ npy 개수 및 이름 일치 🎉\")\n",
        "# else:\n",
        "#     print(f\"⚠️ 의심되는 추가 저장 파일 수: {len(extra)}\")\n",
        "#     print(\"예시 파일 (extra):\", list(extra)[:5])\n",
        "#     print(f\"⚠️ 누락된 예상 파일 수: {len(missing)}\")\n",
        "#     print(\"예시 파일 (missing):\", list(missing)[:5])\n"
      ],
      "metadata": {
        "id": "hcIid1rQ4fCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "\n",
        "model = timm.create_model('convnext_tiny', pretrained=True, num_classes=396)\n",
        "print(model.default_cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95uHM81tFoKn",
        "outputId": "07aeaad4-dc81-476c-c1de-576e0fcf8ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'url': '', 'hf_hub_id': 'timm/convnext_tiny.in12k_ft_in1k', 'architecture': 'convnext_tiny', 'tag': 'in12k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'test_input_size': (3, 288, 288), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_crop_pct': 1.0, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'stem.0', 'classifier': 'head.fc'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(model.default_cfg)\n"
      ],
      "metadata": {
        "id": "IZ9btXdawzHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 1️⃣ 모델 만들고 default_cfg 확인 (참고용)\n",
        "model = timm.create_model(\n",
        "    'convnext_tiny',\n",
        "    pretrained=True,\n",
        "    num_classes=396,\n",
        "    in_chans=1\n",
        ")\n",
        "\n",
        "# 참고용 출력 (필수는 아님 — 그냥 확인)\n",
        "print(model.default_cfg)\n",
        "\n",
        "# ✅ 2️⃣ transform은 이미 내가 쓸 걸 정했음 (Grayscale + 384)\n",
        "# 그대로 사용 (default_cfg에 mean/std가 있어도, 우리는 [0.5], [0.5] 씀 → 일치할 필요 없음)\n",
        "\n",
        "# ✅ 3️⃣ DataLoader 구성 → 학습 시작\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw2hgcRXz0ck",
        "outputId": "4878131a-5912-4995-f246-4b00e41d9292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'url': '', 'hf_hub_id': 'timm/convnext_tiny.in12k_ft_in1k', 'architecture': 'convnext_tiny', 'tag': 'in12k_ft_in1k', 'custom_load': False, 'input_size': (3, 224, 224), 'test_input_size': (3, 288, 288), 'fixed_input_size': False, 'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_crop_pct': 1.0, 'crop_mode': 'center', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'num_classes': 1000, 'pool_size': (7, 7), 'first_conv': 'stem.0', 'classifier': 'head.fc'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB 단위\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB 단위\n",
        "    print(f\"📊 현재 GPU 메모리 상태: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# 현재 CUDA 사용 가능 여부 확인\n",
        "if torch.cuda.is_available():\n",
        "    print(\"🔍 초기화 전 GPU 메모리 상태:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU 캐시 및 메모리 초기화\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\n🧹 GPU 메모리 초기화 완료\")\n",
        "    print(\"🔍 초기화 후 GPU 메모리 상태:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"❌ CUDA 사용 불가\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bH_WHzciHHx",
        "outputId": "8566d5d5-aa4a-4940-9419-80f8852439da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 초기화 전 GPU 메모리 상태:\n",
            "📊 현재 GPU 메모리 상태: Allocated = 0.00 MB | Reserved = 0.00 MB\n",
            "\n",
            "🧹 GPU 메모리 초기화 완료\n",
            "🔍 초기화 후 GPU 메모리 상태:\n",
            "📊 현재 GPU 메모리 상태: Allocated = 0.00 MB | Reserved = 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "def extract_class_name(fname):\n",
        "    # '1시리즈_F20_2013_2015_000123.npy' → '1시리즈_F20_2013_2015'\n",
        "    return '_'.join(os.path.basename(fname).replace('.npy', '').split('_')[:-1])\n",
        "\n",
        "all_npy_files = glob.glob('/content/drive/MyDrive/fuck/preprocessed/batch_*/**/*.npy', recursive=True)\n",
        "class_names = sorted(set(extract_class_name(f) for f in all_npy_files))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"클래스 수: {len(class_to_idx)}\")  # 396개 나와야 정상\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OMK20ohGQU1",
        "outputId": "40c03b82-5dbd-4180-af86-16525ebb141e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 수: 396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Dataset 클래스 정의\n",
        "\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import numpy as np\n",
        "\n",
        "# class CarNPYDataset(Dataset):\n",
        "#     def __init__(self, file_list, class_to_idx, transform=None):\n",
        "#         self.file_list = file_list\n",
        "#         self.class_to_idx = class_to_idx\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.file_list)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         path = self.file_list[idx]\n",
        "#         image = np.load(path)  # (1, 384, 384)\n",
        "#         image = torch.tensor(image, dtype=torch.float32)\n",
        "\n",
        "#         class_name = '_'.join(os.path.basename(path).replace('.npy', '').split('_')[:-1])\n",
        "#         label = self.class_to_idx[class_name]\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "\n",
        "#         return image, label\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CarNPYDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # 🚀 Step 1. Load npy → tensor\n",
        "        image = np.load(path, mmap_mode='r')\n",
        "        image = torch.from_numpy(image).float()  # (1, H, W)\n",
        "\n",
        "        # 🚀 Step 2. Grayscale(1) → RGB(3)\n",
        "        image = image.repeat(3, 1, 1)  # (3, H, W)\n",
        "\n",
        "        # 🚀 Step 3. Label 추출 (!!! 여기가 반드시 있어야 함)\n",
        "        class_name = '_'.join(os.path.basename(path).replace('.npy', '').split('_')[:-1])\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # 🚀 Step 4. Transform 적용\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # 🚀 Step 5. Return (이 시점에 label이 반드시 정의되어야 함)\n",
        "        return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "rtI0lYOuJZt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 .npy 파일 리스트 + train/val split + DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 전체 .npy 파일\n",
        "file_list = glob.glob('/content/drive/MyDrive/fuck/preprocessed/batch_*/**/*.npy', recursive=True)\n",
        "\n",
        "# 라벨 추출 → stratify 기반 split\n",
        "labels = [class_to_idx[extract_class_name(f)] for f in file_list]\n",
        "train_files, val_files = train_test_split(file_list, test_size=0.1, stratify=labels, random_state=42)\n",
        "\n",
        "# transform\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((384, 384)),  # ✅ 384로 변경\n",
        "    # transforms.ToTensor(),  # 이미 Tensor라면 빼기\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "train_dataset = CarNPYDataset(train_files, class_to_idx, transform)\n",
        "val_dataset = CarNPYDataset(val_files, class_to_idx, transform)\n",
        "\n",
        "# DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n"
      ],
      "metadata": {
        "id": "u2DB9tCSJcmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = timm.create_model('efficientnet_b5', pretrained=True, num_classes=396)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "tNalQaGrKS5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# AdamW + weight_decay 추가 추천 (EffNet 계열에 많이 사용)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "JNIgNO9AKcl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 3\n",
        "patience_counter = 0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(1, 31):\n",
        "    print(f\"\\n🔁 Epoch {epoch}\")\n",
        "\n",
        "    # === 학습 ===\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "\n",
        "    loop = tqdm(train_loader, desc=\"Train\", leave=False)\n",
        "    for X, y in loop:\n",
        "        X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X)\n",
        "        loss = criterion(outputs, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * X.size(0)\n",
        "        train_correct += (outputs.argmax(1) == y).sum().item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "    # === 검증 ===\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "\n",
        "\n",
        "    val_loop = tqdm(val_loader, desc=\"Valid\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loop:\n",
        "            X, y = X.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, y)\n",
        "            val_loss += loss.item() * X.size(0)\n",
        "            val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "    # === 로그 출력 ===\n",
        "    print(f\"✅ Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "    print(f\"✅ Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # === EarlyStopping ===\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        torch.save(model.state_dict(), \"/content/drive/MyDrive/team_models/EffNetB5_progressing.pth\")\n",
        "        print(\"📦 Best model saved!\")\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"⚠️ EarlyStopping patience: {patience_counter}/{patience}\")\n",
        "        if patience_counter >= patience:\n",
        "            print(\"⛔ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "# 최종 Best 모델 로드\n",
        "model.load_state_dict(best_model_wts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZJkMSSKeiG",
        "outputId": "739b2cf5-f013-4fd8-92c7-b8d6855a1391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTrain:   0%|          | 0/1864 [00:00<?, ?it/s]<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "Valid:   0%|          | 0/208 [00:00<?, ?it/s]<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n",
            "<ipython-input-13-30fb53cd65a4>:48: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  image = torch.from_numpy(image).float()  # (1, H, W)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 1.7268 | Acc: 0.6301\n",
            "✅ Val   Loss: 0.3908 | Acc: 0.8769\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.2905 | Acc: 0.9116\n",
            "✅ Val   Loss: 0.3265 | Acc: 0.9074\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.2000 | Acc: 0.9397\n",
            "✅ Val   Loss: 0.3075 | Acc: 0.9092\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.1518 | Acc: 0.9532\n",
            "✅ Val   Loss: 0.2710 | Acc: 0.9228\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.1305 | Acc: 0.9591\n",
            "✅ Val   Loss: 0.2205 | Acc: 0.9351\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.1066 | Acc: 0.9673\n",
            "✅ Val   Loss: 0.2459 | Acc: 0.9366\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "🔁 Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.1040 | Acc: 0.9694\n",
            "✅ Val   Loss: 0.2657 | Acc: 0.9336\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "🔁 Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.0819 | Acc: 0.9749\n",
            "✅ Val   Loss: 0.2119 | Acc: 0.9517\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.0801 | Acc: 0.9755\n",
            "✅ Val   Loss: 0.2041 | Acc: 0.9451\n",
            "📦 Best model saved!\n",
            "\n",
            "🔁 Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.0669 | Acc: 0.9809\n",
            "✅ Val   Loss: 0.2483 | Acc: 0.9396\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "🔁 Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.0591 | Acc: 0.9830\n",
            "✅ Val   Loss: 0.2275 | Acc: 0.9481\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "🔁 Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Train Loss: 0.0589 | Acc: 0.9835\n",
            "✅ Val   Loss: 0.2161 | Acc: 0.9505\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "\n",
        "# 설정\n",
        "MODEL_PATH = \"/content/drive/MyDrive/team_models/ConvNext-Tiny_progressing.pth\"  # ✅ 모델 파일명\n",
        "TEST_DIR = \"/content/drive/MyDrive/fuck/preprocessed_test\"\n",
        "SAMPLE_SUB_PATH = \"/content/drive/MyDrive/open/sample_submission.csv\"\n",
        "SAVE_SUBMISSION_PATH = \"/content/drive/MyDrive/submission/submission.csv\"\n",
        "NUM_CLASSES = 396\n",
        "\n",
        "# 샘플 제출 파일에서 클래스명 추출\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' 제외\n",
        "\n",
        "# ✅ 모델 로드\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = timm.create_model('efficientnet_b5', pretrained=False, num_classes=NUM_CLASSES)\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ✅ Transform (Normalize만 적용)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ✅ 테스트용 npy 기반 Dataset\n",
        "class TestNPYDataset(Dataset):\n",
        "    def __init__(self, npy_root, transform=None):\n",
        "        self.file_list = []\n",
        "        for root, dirs, files in os.walk(npy_root):\n",
        "            for file in files:\n",
        "                if file.endswith('.npy'):\n",
        "                    self.file_list.append(os.path.join(root, file))\n",
        "        self.file_list.sort()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image = np.load(path, mmap_mode='r').copy()\n",
        "        image = torch.from_numpy(image).float()\n",
        "        image = image.repeat(3, 1, 1)  # ✅ Grayscale(1) → RGB(3)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".npy\", \"\")  # TEST_xxx 그대로 추출\n",
        "        return image, fname\n",
        "\n",
        "# ✅ DataLoader\n",
        "test_dataset = TestNPYDataset(TEST_DIR, transform)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,        # test는 batch_size 크게 OK\n",
        "    shuffle=False,\n",
        "    num_workers=2,        # 안정성 위해 2 추천\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=2\n",
        ")\n",
        "\n",
        "# ✅ Inference\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for imgs, names in tqdm(test_loader, desc=\"🔍 Inference\"):\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = model(imgs)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "        for name, prob in zip(names, probs.cpu().numpy()):\n",
        "            row = {\"ID\": name}\n",
        "            row.update({class_name: prob[i] for i, class_name in enumerate(column_names)})\n",
        "            results.append(row)\n",
        "\n",
        "# ✅ 결과 저장\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "submission_df.to_csv(SAVE_SUBMISSION_PATH, index=False)\n",
        "\n",
        "print(f\"✅ 서브미션 저장 완료: {SAVE_SUBMISSION_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k61x77gkNSDG",
        "outputId": "e972b290-80fa-4889-e5e7-716f9d899b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "🔍 Inference:   8%|▊         | 20/259 [00:41<01:26,  2.75it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/submission.csv\")\n",
        "df.to_csv(\"submission_utf8sig.csv\", index=False, encoding='utf-8-sig')\n"
      ],
      "metadata": {
        "id": "ShGkYhOXRiw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"테스트 파일 개수: {len(test_files)}\")\n",
        "print(test_files[:3])  # 앞 몇 개 파일 이름 확인\n"
      ],
      "metadata": {
        "id": "2pLUJGGGOajU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트용 파일 불러오기\n",
        "import numpy as np\n",
        "\n",
        "test_path = \"/content/drive/MyDrive/fuck/preprocessed/batch_000/1시리즈_F20_2013_2015_000000.npy\"\n",
        "with open(test_path, \"rb\") as f:\n",
        "    print(f.read(10))  # 처음 몇 바이트를 출력 (정상 npy면 b'\\x93NUMPY'로 시작)"
      ],
      "metadata": {
        "id": "XClXn_Pf5kHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "broken = []\n",
        "\n",
        "for npy_file in Path(\"/content/drive/MyDrive/fuck/preprocessed\").rglob(\"*.npy\"):\n",
        "    try:\n",
        "        np.load(str(npy_file), allow_pickle=False)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ {npy_file} - {e}\")\n",
        "        broken.append(npy_file)\n",
        "\n",
        "print(f\"\\n손상된 파일 수: {len(broken)}\")\n"
      ],
      "metadata": {
        "id": "EfDHwnaH9WXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def is_npy_file_valid(path):\n",
        "    try:\n",
        "        # allow_pickle=False로 먼저 시도\n",
        "        _ = np.load(path, allow_pickle=False)\n",
        "        return True\n",
        "    except ValueError as e:\n",
        "        # pickle 관련 오류만 있을 경우 allow_pickle=True로 재시도\n",
        "        if \"pickled data\" in str(e):\n",
        "            try:\n",
        "                _ = np.load(path, allow_pickle=True)\n",
        "                return True\n",
        "            except Exception:\n",
        "                return False\n",
        "        else:\n",
        "            return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# 검사할 경로\n",
        "base_dir = \"/content/drive/MyDrive/fuck/preprocessed\"\n",
        "\n",
        "# 모든 npy 파일 경로 수집\n",
        "corrupted_files = []\n",
        "total_files = 0\n",
        "\n",
        "for root, dirs, files in os.walk(base_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".npy\"):\n",
        "            path = os.path.join(root, file)\n",
        "            total_files += 1\n",
        "            if not is_npy_file_valid(path):\n",
        "                corrupted_files.append(path)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"총 검사한 파일 수: {total_files}\")\n",
        "print(f\"❌ 손상된 파일 수: {len(corrupted_files)}\")\n",
        "if corrupted_files:\n",
        "    print(\"예시 손상 파일:\")\n",
        "    for path in corrupted_files[:5]:\n",
        "        print(\" -\", path)\n"
      ],
      "metadata": {
        "id": "XEvdFYyoAzys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "broken_path = \"/content/drive/MyDrive/fuck/preprocessed/batch_000/1시리즈_F20_2013_2015_000000.npy\"\n"
      ],
      "metadata": {
        "id": "81E3SxAEAzrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "filename = os.path.basename(broken_path)\n",
        "parts = filename.replace(\".npy\", \"\").split(\"_\")\n",
        "class_name = \"_\".join(parts[:-1])\n",
        "index = parts[-1]\n",
        "print(f\"class_name: {class_name}, index: {index}\")\n"
      ],
      "metadata": {
        "id": "YghDGItjB6Dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_image_path = f\"/content/drive/MyDrive/open/train/{class_name}\"\n",
        "print(\"해당 클래스 폴더 경로:\", original_image_path)\n",
        "\n",
        "# 해당 클래스 안에서 몇 번째 이미지인지 찾아야 함\n",
        "import os\n",
        "\n",
        "# 숫자 인덱스는 앞에서 몇 번째인지 알 수 있게 순서대로 접근\n",
        "images = sorted(os.listdir(original_image_path))\n",
        "target_image_name = images[int(index)]\n",
        "print(\"대상 원본 이미지 이름:\", target_image_name)\n"
      ],
      "metadata": {
        "id": "_tJfniUhB8_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "# 전처리 transform 정의\n",
        "class SquarePad:\n",
        "    def __call__(self, image):\n",
        "        w, h = image.size\n",
        "        max_wh = max(w, h)\n",
        "        pad_left = (max_wh - w) // 2\n",
        "        pad_top = (max_wh - h) // 2\n",
        "        padding = (pad_left, pad_top, max_wh - w - pad_left, max_wh - h - pad_top)\n",
        "        return TF.pad(image, padding, fill=0)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    SquarePad(),\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# 이미지 열기\n",
        "img_path = os.path.join(original_image_path, target_image_name)\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "img_tensor = transform(img)\n",
        "\n",
        "# 안전하게 저장 (astype으로 pickle 방지)\n",
        "np.save(broken_path, img_tensor.numpy().astype(np.float32))\n",
        "print(\"✅ 다시 저장 완료:\", broken_path)\n"
      ],
      "metadata": {
        "id": "Gx32rJk8CHKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}