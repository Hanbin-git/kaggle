{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1HuAO5Kys89GsFnFfOFan853-bSVE68l-",
      "authorship_tag": "ABX9TyPZZ6aAGeCHaxXouY8aYo7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/feature_color%EB%A1%9C_%EC%A0%84%EB%9E%B5_%EC%88%98%EC%A0%952025_06_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import zipfile\n",
        "\n",
        "# 1. Drive에서 로컬로 복사 (빠름)\n",
        "shutil.copy(\"/content/drive/MyDrive/open.zip\", \"/content/open.zip\")\n",
        "\n",
        "# 2. 압축 풀기\n",
        "with zipfile.ZipFile(\"/content/open.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "\n",
        "# 3. 확인\n",
        "!ls /content/train\n"
      ],
      "metadata": {
        "id": "VGLGwzmFf9U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53668e8f-8c12-4b5c-c2bb-8bf94c3fd970"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "컨티넨탈_10세대_2017_2019\t     A_클래스_W177_2020_2025\n",
            "어코드_10세대_2018_2022\t\t     B_클래스_W246_2013_2018\n",
            "1시리즈_F20_2013_2015\t\t     뉴_스타일_코란도_C_2017_2019\n",
            "1시리즈_F20_2016_2019\t\t     프리우스_C_2018_2020\n",
            "1시리즈_F40_2020_2024\t\t     뉴_CC_2012_2016\n",
            "그랜드카니발_2006_2010\t\t     CLA_클래스_C117_2014_2019\n",
            "2008_2015_2017\t\t\t     CLA_클래스_C118_2020_2025\n",
            "에쿠스_신형_2010_2015\t\t     CLE_클래스_C236_2024_2025\n",
            "파나메라_2010_2016\t\t     CLS_클래스_C257_2019_2023\n",
            "뉴_제타_2011_2016\t\t     CLS_클래스_W218_2012_2017\n",
            "뉴_카이엔_2011_2018\t\t     아반떼_하이브리드_CN7_2021_2023\n",
            "엑센트_신형_2011_2019\t\t     아반떼_CN7_2021_2023\n",
            "스파크_2012_2015\t\t     더_뉴_아반떼_CN7_2023_2025\n",
            "쿠퍼_컨트리맨_2012_2015\t\t     CT6_2016_2018\n",
            "올_뉴_모닝_2012_2015\t\t     C_클래스_W204_2008_2015\n",
            "아베오_2012_2016\t\t     C_클래스_W205_2015_2021\n",
            "말리부_2012_2016\t\t     C_클래스_W206_2022_2024\n",
            "뉴_티구안_2012_2016\t\t     제네시스_DH_2014_2016\n",
            "레이_2012_2017\t\t\t     쏘나타_DN8_2020_2023\n",
            "올란도_2012_2018\t\t     쏘나타_디_엣지_DN8_2024_2025\n",
            "더_뉴_파사트_2012_2019\t\t     e_트론_2020_2023\n",
            "트랙스_2013_2016\t\t     E_PACE_2018_2020\n",
            "콰트로포르테_2014_2016\t\t     EQ900_2016_2018\n",
            "더_뉴_아반떼_2014_2016\t\t     EQA_H243_2021_2024\n",
            "마칸_2014_2018\t\t\t     EQE_V295_2022_2024\n",
            "그랜드_체로키_2014_2020\t\t     EQS_V297_2022_2023\n",
            "기블리_2014_2023\t\t     뉴_ES300h_2013_2015\n",
            "더_뉴_모닝_2015_2016\t\t     뉴_ES300h_2016_2018\n",
            "레니게이드_2015_2017\t\t     ES300h_7세대_2019_2026\n",
            "올_뉴_쏘렌토_2015_2017\t\t     디_올뉴니로EV_2023_2024\n",
            "아슬란_2015_2018\t\t     더_기아_레이_EV_2024_2025\n",
            "티볼리_2015_2018\t\t     EV6_2022_2024\n",
            "디스커버리_스포츠_2015_2019\t     EV9_2024_2025\n",
            "올_뉴_카니발_2015_2019\t\t     E_클래스_W212_2010_2016\n",
            "에스컬레이드_2015_2020\t\t     E_클래스_W213_2017_2020\n",
            "머스탱_2015_2023\t\t     E_클래스_W213_2021_2023\n",
            "익스플로러_2016_2017\t\t     E_클래스_W214_2024_2025\n",
            "그랜드_스타렉스_2016_2018\t     F150_2004_2021\n",
            "싼타페_더_프라임_2016_2018\t     F_PACE_2017_2019\n",
            "더_넥스트_스파크_2016_2018\t     G4_렉스턴_2018_2020\n",
            "더_뉴_맥스크루즈_2016_2018\t     G70_2018_2020\n",
            "더_뉴_코란도_스포츠_2016_2018\t     더_뉴_G70_2021_2025\n",
            "레인지로버_이보크_2016_2019\t     G80_2017_2020\n",
            "아이오닉_하이브리드_2016_2019\t     더_올뉴G80_2021_2024\n",
            "티볼리_에어_2016_2019\t\t     뉴_G80_2025_2026\n",
            "임팔라_2016_2019\t\t     G80_RG3_2021_2023\n",
            "쿠퍼_컨트리맨_2016_2024\t\t     G80_RG3_2025\n",
            "쿠퍼_컨버터블_2016_2024\t\t     G90_2019_2022\n",
            "쿠퍼_클럽맨_2016_2024\t\t     G90_RS4_2022_2025\n",
            "알티마_2017_2018\t\t     GLA_클래스_H247_2020_2025\n",
            "올_뉴_카마로_2017_2018\t\t     GLA_클래스_X156_2015_2019\n",
            "올_뉴_말리부_2017_2018\t\t     GLB_클래스_X247_2020_2023\n",
            "니로_2017_2019\t\t\t     GLC_클래스_X253_2017_2019\n",
            "더_뉴_모하비_2017_2019\t\t     GLC_클래스_X253_2020_2022\n",
            "콰트로포르테_2017_2022\t\t     GLC_클래스_X253_2023\n",
            "르반떼_2017_2022\t\t     GLC_클래스_X254_2023_2025\n",
            "더_뉴_트랙스_2017_2022\t\t     GLE_클래스_W166_2016_2018\n",
            "레인지로버_벨라_2018_2019\t     GLE_클래스_W167_2019_2024\n",
            "익스플로러_2018_2019\t\t     GLS_클래스_X166_2017_2019\n",
            "티볼리_아머_2018_2019\t\t     GLS_클래스_X167_2020_2024\n",
            "쏘나타_뉴_라이즈_2018_2019\t     그랜저_GN7_2023_2025\n",
            "스토닉_2018_2020\t\t     컨티넨탈_GT_2세대_2012_2017\n",
            "스팅어_2018_2020\t\t     컨티넨탈_GT_3세대_2018_2023\n",
            "코나_2018_2020\t\t\t     파사트_GT_B8_2018_2022\n",
            "더_뉴_쏘렌토_2018_2020\t\t     GV70_2021_2023\n",
            "렉스턴_스포츠_2018_2021\t\t     일렉트리파이드_GV70_2022_2024\n",
            "더_뉴_그랜드_스타렉스_2018_2021      GV80_2020_2022\n",
            "더_뉴_레이_2018_2022\t\t     뉴_GV80_2024_2025\n",
            "티구안_올스페이스_2018_2023\t     GV80_2024_2025\n",
            "아테온_2018_2023\t\t     G_클래스_W463_2009_2017\n",
            "넥쏘_2018_2024\t\t\t     G_클래스_W463b_2019_2025\n",
            "렉스턴_스포츠_칸_2019_2020\t     그랜저_HG_2011_2014\n",
            "더_뉴_카니발_2019_2020\t\t     그랜저_HG_2015_2017\n",
            "마칸_2019_2021\t\t\t     i30_PD_2017_2018\n",
            "팰리세이드_2019_2022\t\t     i4_2022_2024\n",
            "스포티지_더_볼드_2019_2022\t     그랜저_IG_2017_2019\n",
            "더_뉴_말리부_2019_2022\t\t     더_뉴_그랜저_IG_2020_2023\n",
            "더_뉴_스파크_2019_2022\t\t     iX_2022_2024\n",
            "레니게이드_2019_2023\t\t     올_뉴_모닝_JA_2017_2020\n",
            "뷰티풀_코란도_2019_2024\t\t     모닝_어반_JA_2021_2023\n",
            "더_뉴_아이오닉_하이브리드_2020\t     더_뉴_모닝_JA_2024_2025\n",
            "콜로라도_2020_2020\t\t     랭글러_JK_2009_2017\n",
            "코세어_2020_2022\t\t     랭글러_JL_2018_2024\n",
            "더_뉴_니로_2020_2022\t\t     벨로스터_JS_2018_2020\n",
            "트래버스_2020_2023\t\t     글래디에이터_JT_2020_2023\n",
            "셀토스_2020_2023\t\t     K3_2013_2015\n",
            "베리_뉴_티볼리_2020_2023\t     더_뉴_K3_2016_2018\n",
            "모하비_더_마스터_2020_2024\t     올_뉴_K3_2019_2021\n",
            "베뉴_2020_2024\t\t\t     더_뉴_K3_2세대_2022_2024\n",
            "트레일블레이저_2021_2022\t     K5_2세대_2016_2018\n",
            "티볼리_에어_2021_2022\t\t     더_뉴_K5_2세대_2019_2020\n",
            "리얼_뉴_콜로라도_2021_2022\t     K5_3세대_하이브리드_2020_2022\n",
            "스팅어_마이스터_2021_2023\t     K5_하이브리드_3세대_2020_2023\n",
            "더_올뉴투싼_하이브리드_2021_2023     K5_3세대_2020_2023\n",
            "더_뉴_싼타페_2021_2023\t\t     더_뉴_K5_하이브리드_3세대_2023_2025\n",
            "더_뉴_코나_2021_2023\t\t     더_뉴_K5_3세대_2024_2025\n",
            "타이칸_2021_2025\t\t     더_뉴_K7_2013_2016\n",
            "더_뉴_렉스턴_스포츠_칸_2021_2025     올_뉴_K7_2016_2019\n",
            "더_뉴_렉스턴_스포츠_2021_2025\t     올_뉴_K7_하이브리드_2017_2019\n",
            "올_뉴_렉스턴_2021_2025\t\t     K7_프리미어_하이브리드_2020_2021\n",
            "캐스퍼_2022_2024\t\t     K7_프리미어_2020_2021\n",
            "마칸_2022_2024\t\t\t     K8_하이브리드_2022_2024\n",
            "디_올_뉴_스포티지_2022_2024\t     K8_2022_2024\n",
            "스타리아_2022_2025\t\t     더_K9_2019_2021\n",
            "디_올뉴니로_2022_2025\t\t     더_뉴_K9_2세대_2022_2025\n",
            "더_뉴_기아_레이_2022_2025\t     체로키_KL_2019_2023\n",
            "디_올_뉴_니로_2022_2025\t\t     디펜더_L663_2020_2025\n",
            "트레일블레이저_2023\t\t     LF_쏘나타_2015_2017\n",
            "더_뉴_팰리세이드_2023_2024\t     팰리세이드_LX3_2025\n",
            "토레스_2023_2025\t\t     M2_F87_2016_2021\n",
            "디_올뉴그랜저_2023_2025\t\t     M4_F82_2015_2020\n",
            "디_올뉴코나_2023_2025\t\t     M5_F90_2018_2023\n",
            "더_뉴_셀토스_2023_2025\t\t     아반떼_MD_2011_2014\n",
            "트랙스_크로스오버_2024_2025\t     MKC_2015_2018\n",
            "디_올뉴싼타페_2024_2025\t\t     뉴_MKZ_2017_2020\n",
            "그랑_콜레오스_2025\t\t     싼타페_MX5_2024_2025\n",
            "레인지로버_스포츠_2세대_2013_2017    아반떼_N_2022_2023\n",
            "레인지로버_스포츠_2세대_2018_2022    New_XF_2012_2015\n",
            "컴패스_2세대_2018_2022\t\t     투싼_NX4_2021_2023\n",
            "레인지로버_이보크_2세대_2020_2022    더_뉴_투싼_NX4_2023_2025\n",
            "디스커버리_스포츠_2세대_2020_2025    카이엔_PO536_2019_2023\n",
            "에비에이터_2세대_2020_2025\t     Q30_2017_2019\n",
            "레인지로버_이보크_2세대_2023_2024    Q3_F3_2020_2024\n",
            "액티언_2세대_2025\t\t     Q50_2014_2017\n",
            "2시리즈_그란쿠페_F44_2020_2024\t     Q5_FY_2020\n",
            "2시리즈_액티브_투어러_F45_2019_2021  Q5_FY_2021_2024\n",
            "2시리즈_액티브_투어러_U06_2022_2024  Q7_4M_2016_2019\n",
            "3008_2세대_2018_2023\t\t     Q7_4M_2020_2023\n",
            "파일럿_3세대_2016_2018\t\t     Q8_4M_2020_2025\n",
            "모델_3_2019_2022\t\t     QM3_2014_2017\n",
            "투아렉_3세대_2020_2023\t\t     뉴QM3_2018_2019\n",
            "모델_3_2024_2025\t\t     뉴_QM5_2012_2014\n",
            "3시리즈_E90_2005_2012\t\t     QM6_2017_2019\n",
            "3시리즈_F30_2013_2018\t\t     더_뉴_QM6_2020_2023\n",
            "3시리즈_G20_2019_2022\t\t     뉴_QM6_2021_2023\n",
            "3시리즈_G20_2023_2025\t\t     더_뉴_QM6_2024_2025\n",
            "3시리즈_GT_F34_2014_2021\t     QX60_2016_2018\n",
            "디스커버리_4_2010_2016\t\t     뉴쏘렌토_R_2013_2014\n",
            "레인지로버_4세대_2014_2017\t     더_뉴스포티지R_2014_2016\n",
            "몬데오_4세대_2015_2020\t\t     RAV4_2016_2018\n",
            "프리우스_4세대_2016_2018\t     RAV4_5세대_2019_2024\n",
            "스포티지_4세대_2016_2018\t     S60_3세대_2020_2024\n",
            "레인지로버_4세대_2018_2022\t     S90_2017_2020\n",
            "프리우스_4세대_2019_2022\t     S90_2021_2025\n",
            "카니발_4세대_2021\t\t     SM3_네오_2015_2019\n",
            "쏘렌토_4세대_2021_2023\t\t     뉴_SM5_임프레션_2008_2010\n",
            "시에나_4세대_2021_2024\t\t     뉴_SM5_플래티넘_2013_2014\n",
            "카니발_4세대_2022_2023\t\t     SM5_노바_2015_2019\n",
            "더_뉴_카니발_4세대_2024_2025\t     SM6_2016_2020\n",
            "더_뉴_쏘렌토_4세대_2024_2025\t     더_뉴_SM6_2021_2024\n",
            "라브4_4세대_2013_2018\t\t     SM7_뉴아트_2008_2011\n",
            "라브4_5세대_2019_2024\t\t     SM7_노바_2015_2019\n",
            "4시리즈_F32_2014_2020\t\t     S_클래스_W221_2006_2013\n",
            "4시리즈_G22_2021_2023\t\t     S_클래스_W222_2014_2020\n",
            "4시리즈_G22_2024_2025\t\t     S_클래스_W223_2021_2025\n",
            "5008_2세대_2018_2019\t\t     코나_SX2_2023_2025\n",
            "5008_2세대_2021_2024\t\t     그랜저TG_2007_2008\n",
            "디스커버리_5_2017_2020\t\t     올_뉴_투싼_TL_2016_2018\n",
            "에스컬레이드_5세대_2021_2024\t     올_뉴_투싼_TL_2019_2020\n",
            "아이오닉5_2022_2023\t\t     싼타페_TM_2019_2020\n",
            "디스커버리_5_2022_2024\t\t     UX250h_2019_2024\n",
            "스포티지_5세대_2022_2024\t     V40_2015_2018\n",
            "레인지로버_5세대_2023_2024\t     V60_크로스컨트리_2세대_2020_2025\n",
            "5시리즈_F10_2010_2016\t\t     V90_크로스컨트리_2018_2024\n",
            "5시리즈_G30_2017_2023\t\t     뉴_체어맨_W_2012_2016\n",
            "5시리즈_G60_2024_2025\t\t     그랜드_체로키_WL_2021_2023\n",
            "5시리즈_GT_F07_2010_2017\t     X1_F48_2016_2019\n",
            "익스플로러_6세대_2020_2025\t     X1_F48_2020_2022\n",
            "아이오닉6_2023_2025\t\t     X1_U11_2023_2024\n",
            "6시리즈_F12_2011_2018\t\t     X2_F39_2018_2023\n",
            "6시리즈_GT_G32_2018_2020\t     X3_G01_2018_2021\n",
            "6시리즈_GT_G32_2021_2024\t     X3_G01_2022_2024\n",
            "박스터_718_2017_2024\t\t     X4_F26_2015_2018\n",
            "718_카이맨_2017_2024\t\t     X4_G02_2019_2021\n",
            "718_박스터_2017_2024\t\t     X4_G02_2022_2025\n",
            "골프_7세대_2013_2016\t\t     X5_F15_2014_2018\n",
            "7시리즈_F01_2009_2015\t\t     X5_G05_2019_2023\n",
            "7시리즈_G11_2016_2018\t\t     X5_G05_2024_2025\n",
            "7시리즈_G11_2019_2022\t\t     X6_F16_2015_2019\n",
            "7시리즈_G70_2023_2025\t\t     X6_G06_2020_2023\n",
            "8시리즈_G15_2020_2024\t\t     X6_G06_2024_2025\n",
            "911_2003_2019\t\t\t     X7_G07_2019_2022\n",
            "911_992_2020_2024\t\t     X7_G07_2023_2025\n",
            "파나메라_971_2017_2023\t\t     XC40_2019_2022\n",
            "A4_B9_2016_2019\t\t\t     XC60_2세대_2018_2021\n",
            "A4_B9_2020_2024\t\t\t     XC60_2세대_2022_2025\n",
            "A5_F5_2019_2024\t\t\t     XC90_2세대_2017_2019\n",
            "뉴_A6_2012_2014\t\t\t     XC90_2세대_2020_2025\n",
            "뉴_A6_2015_2018\t\t\t     XE_2016_2019\n",
            "A6_C8_2019_2025\t\t\t     XF_X260_2016_2020\n",
            "A7_2012_2016\t\t\t     XJ_8세대_2010_2019\n",
            "A7_4K_2020_2024\t\t\t     XM3_2020_2023\n",
            "A8_D5_2018_2023\t\t\t     XM3_2024\n",
            "아반떼_AD_2016_2018\t\t     캠리_XV70_2018_2024\n",
            "더_뉴_아반떼_AD_2019_2020\t     모델_Y_2021_2025\n",
            "All_New_XJ_2016_2019\t\t     YF쏘나타_2009_2012\n",
            "AMG_GT_2016_2024\t\t     YF쏘나타_하이브리드_2011_2015\n",
            "A_클래스_W176_2015_2018\t\t     Z4_G29_2019_2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import timm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "metadata": {
        "id": "eyLBp4j3i6F1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 경로\n",
        "train_dir = '/content/train'\n",
        "\n",
        "# test 경로\n",
        "test_dir = '/content/test'\n",
        "\n",
        "# sample_submission (추론 때 사용)\n",
        "sample_submission_path = '/content/sample_submission.csv'\n"
      ],
      "metadata": {
        "id": "Ybtf0x5si9CE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def show_memory_status():\n",
        "    allocated = torch.cuda.memory_allocated() / (1024 ** 2)  # MB 단위\n",
        "    reserved = torch.cuda.memory_reserved() / (1024 ** 2)    # MB 단위\n",
        "    print(f\"📊 현재 GPU 메모리 상태: Allocated = {allocated:.2f} MB | Reserved = {reserved:.2f} MB\")\n",
        "\n",
        "# 현재 CUDA 사용 가능 여부 확인\n",
        "if torch.cuda.is_available():\n",
        "    print(\"🔍 초기화 전 GPU 메모리 상태:\")\n",
        "    show_memory_status()\n",
        "\n",
        "    # GPU 캐시 및 메모리 초기화\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.ipc_collect()\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"\\n🧹 GPU 메모리 초기화 완료\")\n",
        "    print(\"🔍 초기화 후 GPU 메모리 상태:\")\n",
        "    show_memory_status()\n",
        "else:\n",
        "    print(\"❌ CUDA 사용 불가\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxuQLgBAmkIm",
        "outputId": "30be1cb4-99e2-4581-f7d0-936f0473cbeb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 초기화 전 GPU 메모리 상태:\n",
            "📊 현재 GPU 메모리 상태: Allocated = 0.00 MB | Reserved = 0.00 MB\n",
            "\n",
            "🧹 GPU 메모리 초기화 완료\n",
            "🔍 초기화 후 GPU 메모리 상태:\n",
            "📊 현재 GPU 메모리 상태: Allocated = 0.00 MB | Reserved = 0.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "# ✅ 전체 JPG 파일 불러오기 (Train)\n",
        "file_list = glob.glob('/content/train/*/*.jpg')\n",
        "\n",
        "# ✅ 클래스명 추출 (폴더명 기준)\n",
        "def extract_class_name_jpg(path):\n",
        "    return os.path.basename(os.path.dirname(path))\n",
        "\n",
        "class_names = sorted(set(extract_class_name_jpg(f) for f in file_list))\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
        "\n",
        "print(f\"✅ 클래스 수: {len(class_to_idx)}\")  # 396개 나와야 정상\n",
        "\n",
        "# ✅ 라벨 생성\n",
        "labels = [class_to_idx[extract_class_name_jpg(f)] for f in file_list]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktvVaB62kWsK",
        "outputId": "66206994-a232-4bc0-ea09-d83b82099290"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 클래스 수: 396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ✅ labeling 기준 (간단 rule 기반 v2 사용 예시)\n",
        "def simple_pose_label_v2(img_path):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    w, h = img.size\n",
        "\n",
        "    # Aspect ratio\n",
        "    aspect_ratio = w / h\n",
        "\n",
        "    # 중앙 crop → 중앙 밝기\n",
        "    crop = img.crop((w * 0.3, h * 0.5, w * 0.7, h * 0.8))\n",
        "    crop_np = np.array(crop).mean()\n",
        "\n",
        "    # 상단 crop → 상단 밝기\n",
        "    crop_top = img.crop((w * 0.3, h * 0.1, w * 0.7, h * 0.4))\n",
        "    crop_top_np = np.array(crop_top).mean()\n",
        "\n",
        "    # Simple rule v2\n",
        "    if crop_np > crop_top_np + 15 and aspect_ratio > 1.1:\n",
        "        return 'Rear'\n",
        "    elif crop_top_np > crop_np + 15 and aspect_ratio > 0.9:\n",
        "        return 'Front'\n",
        "    elif 0.9 < aspect_ratio < 1.1:\n",
        "        return 'Side'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "# ✅ 전체 labeling → Train 전용\n",
        "def run_pose_labeling_train(img_paths):\n",
        "    records = []\n",
        "\n",
        "    for path in tqdm(img_paths, desc='Pose labeling Train'):\n",
        "        fname = os.path.basename(path)\n",
        "        label = simple_pose_label_v2(path)\n",
        "        # class_name 추출 (폴더명)\n",
        "        class_name = extract_class_name_jpg(path)\n",
        "        records.append({\n",
        "            'filename': fname,\n",
        "            'class': class_name,\n",
        "            'pose': label\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "# ✅ 실행\n",
        "df_train_pose = run_pose_labeling_train(file_list)\n",
        "\n",
        "# ✅ 저장\n",
        "SAVE_CSV_PATH = '/content/drive/MyDrive/team_models/pose_labels_for_train.csv'\n",
        "df_train_pose.to_csv(SAVE_CSV_PATH, index=False)\n",
        "\n",
        "print(f\"\\n✅ Pose labeling (Train) 완료 → CSV 저장됨: {SAVE_CSV_PATH}\")\n",
        "print(df_train_pose['pose'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VE8FCPKkqZL",
        "outputId": "9c6868a1-ab7e-4c6d-a429-1f669a014cfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Pose labeling Train: 100%|██████████| 33137/33137 [01:36<00:00, 344.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Pose labeling (Train) 완료 → CSV 저장됨: /content/drive/MyDrive/team_models/pose_labels_for_train.csv\n",
            "pose\n",
            "Front      16134\n",
            "Rear        8769\n",
            "Unknown     7600\n",
            "Side         634\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ✅ 파일 경로\n",
        "POSE_LABEL_CSV = '/content/drive/MyDrive/team_models/pose_labels_for_train.csv'\n",
        "\n",
        "# ✅ CSV 로드\n",
        "df_pose = pd.read_csv(POSE_LABEL_CSV)\n",
        "\n",
        "# ✅ 우선 기존 pose 컬럼 복사\n",
        "df_pose['manual_pose'] = df_pose['pose']\n",
        "\n",
        "# ✅ 적용 순서 (중요!)\n",
        "# ✅ 완전 노이즈\n",
        "manual_noise_list = [\n",
        "    '5시리즈_G60_2024_2025_0010.jpg',\n",
        "    '6시리즈_GT_G32_2018_2020_0018.jpg',\n",
        "    '7시리즈_G11_2016_2018_0040.jpg',\n",
        "    '911_992_2020_2024_0030.jpg',\n",
        "    'E_클래스_W212_2010_2016_0022.jpg',\n",
        "    'K5_2세대_2016_2018_0007.jpg',\n",
        "    'F150_2004_2021_0018.jpg',\n",
        "    'G_클래스_W463b_2019_2025_0030.jpg',\n",
        "    'GLE_클래스_W167_2019_2024_0068.jpg',\n",
        "    'Q5_FY_2021_2024_0032.jpg',\n",
        "    'Q30_2017_2019_0075.jpg',\n",
        "    'Q50_2014_2017_0031.jpg',\n",
        "    'SM7_뉴아트_2008_2011_0053.jpg',\n",
        "    'X3_G01_2022_2024_0029.jpg',\n",
        "    'XF_X260_2016_2020_0023.jpg',\n",
        "    '뉴_ES300h_2013_2015_0000.jpg',\n",
        "    '뉴_G80_2025_2026_0042.jpg',\n",
        "    '뉴_G80_2025_2026_0043.jpg',\n",
        "    '뉴_SM5_임프레션_2008_2010_0033.jpg',\n",
        "    '더_기아_레이_EV_2024_2025_0078.jpg',\n",
        "    '더_뉴_K3_2세대_2022_2024_0001.jpg',\n",
        "    '더_뉴_그랜드_스타렉스_2018_2021_0078.jpg',\n",
        "    '더_뉴_그랜드_스타렉스_2018_2021_0079.jpg',\n",
        "    '더_뉴_그랜드_스타렉스_2018_2021_0080.jpg',\n",
        "    '더_뉴_아반떼_2014_2016_0031.jpg',\n",
        "    '더_뉴_파사트_2012_2019_0067.jpg',\n",
        "    '레니게이드_2019_2023_0041.jpg',\n",
        "    '박스터_718_2017_2024_0011.jpg',\n",
        "    '싼타페_TM_2019_2020_0009.jpg',\n",
        "    '아반떼_MD_2011_2014_0081.jpg',\n",
        "    '아반떼_N_2022_2023_0064.jpg',\n",
        "    '익스플로러_2016_2017_0072.jpg',\n",
        "    '콰트로포르테_2017_2022_0074.jpg',\n",
        "    '프리우스_4세대_2019_2022_0052.jpg',\n",
        "    '아반떼_N_2022_2023_0035.jpg'  # ✅ 추가로 넣으신 것!\n",
        "]\n",
        "\n",
        "# ✅ 차량 내부\n",
        "manual_inside_list = [\n",
        "    'E_클래스_W212_2010_2016_0069.jpg',\n",
        "    'ES300h_7세대_2019_2026_0028.jpg',\n",
        "    'G_클래스_W463_2009_2017_0011.jpg',\n",
        "    'GLB_클래스_X247_2020_2023_0008.jpg',\n",
        "    'GLS_클래스_X167_2020_2024_0013.jpg',\n",
        "    'K3_2013_2015_0045.jpg',\n",
        "    'K5_3세대_2020_2023_0081.jpg',\n",
        "    'Q7_4M_2020_2023_0011.jpg',\n",
        "    'RAV4_5세대_2019_2024_0020.jpg',\n",
        "    'S_클래스_W223_2021_2025_0008.jpg',\n",
        "    'S_클래스_W223_2021_2025_0071.jpg',\n",
        "    'X4_F26_2015_2018_0068.jpg',\n",
        "    '그랜드_체로키_WL_2021_2023_0018.jpg',\n",
        "    '레이_2012_2017_0063.jpg',\n",
        "    '레인지로버_5세대_2023_2024_0030.jpg',\n",
        "    '레인지로버_스포츠_2세대_2018_2022_0014.jpg',\n",
        "    '레인지로버_스포츠_2세대_2018_2022_0017.jpg',\n",
        "    '마칸_2019_2021_0035.jpg',\n",
        "    '머스탱_2015_2023_0086.jpg',\n",
        "    '아반떼_MD_2011_2014_0009.jpg',\n",
        "    '아반떼_MD_2011_2014_0082.jpg',\n",
        "    '컨티넨탈_GT_3세대_2018_2023_0007.jpg',\n",
        "    '타이칸_2021_2025_0065.jpg',\n",
        "    '파나메라_2010_2016_0000.jpg',\n",
        "    '파나메라_2010_2016_0036.jpg',\n",
        "    '3시리즈_F30_2013_2018_0036.jpg',\n",
        "    '4시리즈_F32_2014_2020_0027.jpg',\n",
        "    '5시리즈_G60_2024_2025_0056.jpg',\n",
        "    '7시리즈_F01_2009_2015_0029.jpg',\n",
        "    '7시리즈_F01_2009_2015_0044.jpg',\n",
        "    '911_992_2020_2024_0006.jpg',\n",
        "    'C_클래스_W204_2008_2015_0068.jpg',\n",
        "    'CLS_클래스_C257_2019_2023_0021.jpg'\n",
        "]\n",
        "\n",
        "# ✅ 트렁크 열림\n",
        "manual_trunk_list = [\n",
        "    'Q30_2017_2019_0074.jpg',\n",
        "    '글래디에이터_JT_2020_2023_0075.jpg',\n",
        "    '뉴_CC_2012_2016_0001.jpg',\n",
        "    '뉴_CC_2012_2016_0002.jpg',\n",
        "    '더_뉴_코나_2021_2023_0081.jpg',\n",
        "    '2시리즈_액티브_투어러_U06_2022_2024_0004.jpg',\n",
        "    'A8_D5_2018_2023_0084.jpg'\n",
        "]\n",
        "\n",
        "# ✅ 결과 확인\n",
        "print(df_pose['manual_pose'].value_counts())\n",
        "\n",
        "# ✅ 저장\n",
        "SAVE_MANUAL_CSV = '/content/drive/MyDrive/team_models/pose_labels_for_train_manual_applied.csv'\n",
        "df_pose.to_csv(SAVE_MANUAL_CSV, index=False)\n",
        "\n",
        "print(f\"\\n✅ 자동 적용 완료 → CSV 저장됨: {SAVE_MANUAL_CSV}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTEs2TzCrbZH",
        "outputId": "c3adfe01-acf5-4e57-f025-93f3e2e6451e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "manual_pose\n",
            "Front      16134\n",
            "Rear        8769\n",
            "Unknown     7600\n",
            "Side         634\n",
            "Name: count, dtype: int64\n",
            "\n",
            "✅ 자동 적용 완료 → CSV 저장됨: /content/drive/MyDrive/team_models/pose_labels_for_train_manual_applied.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# ✅ 준비된 Pose Label CSV 경로\n",
        "POSE_CSV_PATH = '/content/drive/MyDrive/team_models/pose_labels_for_train_manual_applied.csv'\n",
        "\n",
        "# ✅ 기존 pose label 로드\n",
        "df_pose = pd.read_csv(POSE_CSV_PATH)\n",
        "\n",
        "# ✅ 현재 file_list 로드 (train image list)\n",
        "train_file_list = glob.glob('/content/train/*/*.jpg')\n",
        "\n",
        "# ✅ \"파일명\" 기준으로 DataFrame 만들기\n",
        "df_train_files = pd.DataFrame({\n",
        "    'filepath': train_file_list,\n",
        "    'filename': [os.path.basename(p) for p in train_file_list],\n",
        "    'class': [os.path.basename(os.path.dirname(p)) for p in train_file_list]\n",
        "})\n",
        "\n",
        "# ✅ Merge → pose 붙이기\n",
        "df_train_merged = pd.merge(df_train_files, df_pose[['filename', 'manual_pose']], on='filename', how='left')\n",
        "\n",
        "# ✅ Null 체크\n",
        "assert df_train_merged['manual_pose'].isnull().sum() == 0, \"🚨 pose 매칭 안된 이미지 있음!\"\n",
        "\n",
        "print(f\"✅ Pose merge 완료 → 총 {len(df_train_merged)}개\")\n",
        "\n",
        "# ✅ One-hot Encoding (추천 사용)\n",
        "df_pose_ohe = pd.get_dummies(df_train_merged['manual_pose'], prefix='pose')\n",
        "\n",
        "# ✅ 최종 DF\n",
        "df_train_final = pd.concat([df_train_merged, df_pose_ohe], axis=1)\n",
        "\n",
        "# ✅ 저장\n",
        "SAVE_TRAIN_FINAL = '/content/drive/MyDrive/team_models/train_with_pose_feature.csv'\n",
        "df_train_final.to_csv(SAVE_TRAIN_FINAL, index=False)\n",
        "\n",
        "print(f\"\\n✅ 최종 Train + Pose feature 저장 완료 → {SAVE_TRAIN_FINAL}\")\n",
        "print(f\"👉 One-hot columns: {df_pose_ohe.columns.tolist()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC6keyKvklC1",
        "outputId": "150cba73-6322-46ac-8a4e-48887fbc51a8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pose merge 완료 → 총 33137개\n",
            "\n",
            "✅ 최종 Train + Pose feature 저장 완료 → /content/drive/MyDrive/team_models/train_with_pose_feature.csv\n",
            "👉 One-hot columns: ['pose_Front', 'pose_Rear', 'pose_Side', 'pose_Unknown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CarImagePoseDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, df_pose, transform=None,\n",
        "                 use_aspect=False, use_color=False, use_pose=False):\n",
        "\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.df_pose = df_pose.set_index('filename')  # 빠른 lookup 위해 index 설정\n",
        "        self.transform = transform\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "        self.use_pose = use_pose\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # Load image\n",
        "        image_pil = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        # Aspect Ratio\n",
        "        width, height = image_pil.size\n",
        "        aspect_ratio = np.array([width / height], dtype=np.float32)\n",
        "\n",
        "        # Color Mean\n",
        "        image_cv2 = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "        color_mean = image_cv2.mean(axis=(0, 1))\n",
        "        color_mean = color_mean[::-1]\n",
        "        color_mean = np.array(color_mean / 255.0, dtype=np.float32)\n",
        "\n",
        "        # Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image_pil)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image_pil)\n",
        "\n",
        "        # Label\n",
        "        class_name = os.path.basename(os.path.dirname(path))\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # Filename\n",
        "        fname = os.path.basename(path)\n",
        "\n",
        "        # Pose feature (4-dim vector)\n",
        "        pose_vec = np.array([\n",
        "            self.df_pose.loc[fname, 'pose_Front'],\n",
        "            self.df_pose.loc[fname, 'pose_Rear'],\n",
        "            self.df_pose.loc[fname, 'pose_Side'],\n",
        "            self.df_pose.loc[fname, 'pose_Unknown']\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "        # Return modes\n",
        "        features = []\n",
        "\n",
        "        if self.use_aspect:\n",
        "            features.append(torch.tensor(aspect_ratio))\n",
        "\n",
        "        if self.use_color:\n",
        "            features.append(torch.tensor(color_mean))\n",
        "\n",
        "        if self.use_pose:\n",
        "            features.append(torch.tensor(pose_vec))\n",
        "\n",
        "        if features:\n",
        "            return image, *features, label\n",
        "        else:\n",
        "            return image, label\n"
      ],
      "metadata": {
        "id": "9a4nTFQ8siE9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import timm\n",
        "import torch\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, use_aspect, use_color, use_pose, num_classes):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "        self.use_pose = use_pose\n",
        "\n",
        "        # ✅ EfficientNet-B5 backbone\n",
        "        self.backbone = timm.create_model('efficientnet_b5', pretrained=True, num_classes=0)  # feature extractor\n",
        "        backbone_out_features = self.backbone.num_features\n",
        "\n",
        "        # ✅ Meta feature dimension 계산\n",
        "        meta_features_dim = 0\n",
        "        if self.use_aspect:\n",
        "            meta_features_dim += 1  # aspect ratio 1개\n",
        "        if self.use_color:\n",
        "            meta_features_dim += 3  # color_mean (R, G, B) 3개\n",
        "        if self.use_pose:\n",
        "            meta_features_dim += 4  # pose one-hot (Front, Rear, Side, Unknown)\n",
        "\n",
        "        # ✅ Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(backbone_out_features + meta_features_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, aspect_ratio=None, color_mean=None, pose_feature=None):\n",
        "        # ✅ EfficientNet feature\n",
        "        x = self.backbone(image)\n",
        "\n",
        "        # ✅ Meta features concat\n",
        "        aux_list = []\n",
        "\n",
        "        if self.use_aspect:\n",
        "            aux_list.append(aspect_ratio)\n",
        "\n",
        "        if self.use_color:\n",
        "            aux_list.append(color_mean)\n",
        "\n",
        "        if self.use_pose:\n",
        "            aux_list.append(pose_feature)\n",
        "\n",
        "        if aux_list:\n",
        "            aux_features = torch.cat(aux_list, dim=1)\n",
        "            x = torch.cat([x, aux_features], dim=1)\n",
        "\n",
        "        # ✅ Final classifier\n",
        "        out = self.classifier(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "-XGDJI0ls9Pk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# EfficientNet-B5 권장 입력 크기 (456x456)\n",
        "IMG_SIZE = 456\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ],
      "metadata": {
        "id": "Xvj8_cOctJJs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class CarImageDataset(Dataset):\n",
        "    def __init__(self, file_list, class_to_idx, df_pose, transform=None, use_aspect=False, use_color=False, use_pose=False):\n",
        "        self.file_list = file_list\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.df_pose = df_pose\n",
        "        self.transform = transform\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "        self.use_pose = use_pose\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "\n",
        "        # 🚗 Load Image\n",
        "        image_pil = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        # 🚗 Aspect Ratio\n",
        "        width, height = image_pil.size\n",
        "        aspect_ratio = np.array([width / height], dtype=np.float32)\n",
        "\n",
        "        # 🚗 Color Mean\n",
        "        image_cv2 = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "        color_mean = image_cv2.mean(axis=(0, 1))\n",
        "        color_mean = color_mean[::-1]\n",
        "        color_mean = np.array(color_mean / 255.0, dtype=np.float32)\n",
        "\n",
        "        # 🚗 Pose One-hot → df_pose lookup\n",
        "        fname = os.path.basename(path)\n",
        "        row = self.df_pose[self.df_pose['filename'] == fname]\n",
        "\n",
        "        if len(row) == 0:\n",
        "            pose_onehot = np.array([0, 0, 0, 1], dtype=np.float32)  # Unknown fallback\n",
        "        else:\n",
        "            pose = row['pose'].values[0]\n",
        "            pose_onehot = np.zeros(4, dtype=np.float32)\n",
        "            if pose == 'Front':\n",
        "                pose_onehot[0] = 1\n",
        "            elif pose == 'Rear':\n",
        "                pose_onehot[1] = 1\n",
        "            elif pose == 'Side':\n",
        "                pose_onehot[2] = 1\n",
        "            else:\n",
        "                pose_onehot[3] = 1  # Unknown\n",
        "\n",
        "        # 🚗 Transform\n",
        "        if self.transform:\n",
        "            image = self.transform(image_pil)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image_pil)\n",
        "\n",
        "        # 🚗 Label\n",
        "        class_name = os.path.basename(os.path.dirname(path))\n",
        "        label = self.class_to_idx[class_name]\n",
        "\n",
        "        # 🚗 Return\n",
        "        meta_list = []\n",
        "\n",
        "        if self.use_aspect:\n",
        "            meta_list.append(torch.tensor(aspect_ratio))\n",
        "        if self.use_color:\n",
        "            meta_list.append(torch.tensor(color_mean))\n",
        "        if self.use_pose:\n",
        "            meta_list.append(torch.tensor(pose_onehot))\n",
        "\n",
        "        if meta_list:\n",
        "            return image, *meta_list, label\n",
        "        else:\n",
        "            return image, label\n"
      ],
      "metadata": {
        "id": "sZcoNxFctUDd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ✅ 디바이스 설정 (GPU 우선)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Device 사용: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLt3GPdlxLPD",
        "outputId": "8dc95b55-4017-450f-a220-29bcf31db23b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Device 사용: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# ✅ StratifiedKFold 정의\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# ✅ 실험명\n",
        "EXPERIMENT = \"C_pose\"\n",
        "\n",
        "use_aspect = False\n",
        "use_color = True\n",
        "use_pose = True\n",
        "\n",
        "print(f\"\\n🚀 실험 설정: {EXPERIMENT} (Aspect={use_aspect}, Color={use_color}, Pose={use_pose})\\n\")\n",
        "\n",
        "# ✅ 5-Fold 루프 시작\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(file_list, labels)):\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\"🔁 Fold {fold + 1} / 5\")\n",
        "    print(f\"==============================\\n\")\n",
        "\n",
        "    # ✅ Fold별 split\n",
        "    train_files = [file_list[i] for i in train_idx]\n",
        "    val_files = [file_list[i] for i in val_idx]\n",
        "\n",
        "    # ✅ Fold별 Dataset & DataLoader\n",
        "    train_dataset = CarImageDataset(train_files, class_to_idx, df_pose, train_transform, use_aspect, use_color, use_pose)\n",
        "    val_dataset = CarImageDataset(val_files, class_to_idx, df_pose, val_transform, use_aspect, use_color, use_pose)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True, persistent_workers=True, prefetch_factor=2)\n",
        "\n",
        "    # ✅ Fold별 model / criterion / optimizer 초기화\n",
        "    model = CustomModel(use_aspect=use_aspect, use_color=use_color, use_pose=use_pose, num_classes=396)\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "    # ✅ EarlyStopping 변수 초기화\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 3\n",
        "    patience_counter = 0\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # ✅ Epoch 루프\n",
        "    for epoch in range(1, 31):\n",
        "        print(f\"\\n📌 Fold {fold+1} | Epoch {epoch}\")\n",
        "\n",
        "        # === 학습 ===\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Train Fold {fold+1}\", leave=False)\n",
        "        for batch in loop:\n",
        "            X = batch[0].to(device)\n",
        "            meta_list = batch[1:-1]\n",
        "            y = batch[-1].to(device)\n",
        "\n",
        "            # Meta 준비\n",
        "            meta_args = {}\n",
        "            cnt = 0\n",
        "            if use_aspect:\n",
        "                meta_args['aspect_ratio'] = meta_list[cnt].to(device)\n",
        "                cnt += 1\n",
        "            if use_color:\n",
        "                meta_args['color_mean'] = meta_list[cnt].to(device)\n",
        "                cnt += 1\n",
        "            if use_pose:\n",
        "                meta_args['pose_feature'] = meta_list[cnt].to(device)\n",
        "                cnt += 1\n",
        "\n",
        "            outputs = model(X, **meta_args)\n",
        "\n",
        "            loss = criterion(outputs, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * X.size(0)\n",
        "            train_correct += (outputs.argmax(1) == y).sum().item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = train_correct / len(train_loader.dataset)\n",
        "\n",
        "        # === 검증 ===\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "\n",
        "        val_loop = tqdm(val_loader, desc=f\"Valid Fold {fold+1}\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loop:\n",
        "                X = batch[0].to(device)\n",
        "                meta_list = batch[1:-1]\n",
        "                y = batch[-1].to(device)\n",
        "\n",
        "                meta_args = {}\n",
        "                cnt = 0\n",
        "                if use_aspect:\n",
        "                    meta_args['aspect_ratio'] = meta_list[cnt].to(device)\n",
        "                    cnt += 1\n",
        "                if use_color:\n",
        "                    meta_args['color_mean'] = meta_list[cnt].to(device)\n",
        "                    cnt += 1\n",
        "                if use_pose:\n",
        "                    meta_args['pose_feature'] = meta_list[cnt].to(device)\n",
        "                    cnt += 1\n",
        "\n",
        "                outputs = model(X, **meta_args)\n",
        "\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item() * X.size(0)\n",
        "                val_correct += (outputs.argmax(1) == y).sum().item()\n",
        "                val_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        # === 로그 출력 ===\n",
        "        print(f\"✅ Fold {fold+1} | Epoch {epoch} | Train Loss: {train_loss:.4f} | Acc: {train_acc:.4f}\")\n",
        "        print(f\"✅ Fold {fold+1} | Epoch {epoch} | Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # === EarlyStopping ===\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            save_path = f\"/content/drive/MyDrive/team_models/EffNetB5_{EXPERIMENT}_fold{fold+1}.pth\"\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f\"📦 Best model saved for Fold {fold+1}!\")\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"⚠️ EarlyStopping patience: {patience_counter}/{patience}\")\n",
        "            if patience_counter >= patience:\n",
        "                print(\"⛔ Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # ✅ Fold 끝나고 Best 모델 로드\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    print(f\"✅ Fold {fold+1} Best model loaded.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r1EJPrSwXcS",
        "outputId": "82acac27-b8fa-47fe-c208-3ef27fa43913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🚀 실험 설정: C_pose (Aspect=False, Color=True, Pose=True)\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 1 / 5\n",
            "==============================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📌 Fold 1 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 1 | Train Loss: 3.2506 | Acc: 0.4787\n",
            "✅ Fold 1 | Epoch 1 | Val   Loss: 0.6897 | Acc: 0.8612\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 2 | Train Loss: 0.5051 | Acc: 0.8977\n",
            "✅ Fold 1 | Epoch 2 | Val   Loss: 0.2809 | Acc: 0.9200\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 3 | Train Loss: 0.2636 | Acc: 0.9286\n",
            "✅ Fold 1 | Epoch 3 | Val   Loss: 0.2432 | Acc: 0.9270\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 4 | Train Loss: 0.1972 | Acc: 0.9428\n",
            "✅ Fold 1 | Epoch 4 | Val   Loss: 0.1978 | Acc: 0.9378\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 5 | Train Loss: 0.1670 | Acc: 0.9495\n",
            "✅ Fold 1 | Epoch 5 | Val   Loss: 0.1760 | Acc: 0.9466\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 6 | Train Loss: 0.1490 | Acc: 0.9541\n",
            "✅ Fold 1 | Epoch 6 | Val   Loss: 0.1889 | Acc: 0.9460\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 1 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 7 | Train Loss: 0.1366 | Acc: 0.9580\n",
            "✅ Fold 1 | Epoch 7 | Val   Loss: 0.1719 | Acc: 0.9519\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 8 | Train Loss: 0.1250 | Acc: 0.9598\n",
            "✅ Fold 1 | Epoch 8 | Val   Loss: 0.1646 | Acc: 0.9526\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 9 | Train Loss: 0.1148 | Acc: 0.9623\n",
            "✅ Fold 1 | Epoch 9 | Val   Loss: 0.1550 | Acc: 0.9561\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 10 | Train Loss: 0.1100 | Acc: 0.9657\n",
            "✅ Fold 1 | Epoch 10 | Val   Loss: 0.1668 | Acc: 0.9567\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 1 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 11 | Train Loss: 0.0990 | Acc: 0.9674\n",
            "✅ Fold 1 | Epoch 11 | Val   Loss: 0.1704 | Acc: 0.9575\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 1 | Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 12 | Train Loss: 0.0932 | Acc: 0.9703\n",
            "✅ Fold 1 | Epoch 12 | Val   Loss: 0.1410 | Acc: 0.9582\n",
            "📦 Best model saved for Fold 1!\n",
            "\n",
            "📌 Fold 1 | Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 13 | Train Loss: 0.0961 | Acc: 0.9689\n",
            "✅ Fold 1 | Epoch 13 | Val   Loss: 0.1444 | Acc: 0.9615\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 1 | Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 14 | Train Loss: 0.0810 | Acc: 0.9725\n",
            "✅ Fold 1 | Epoch 14 | Val   Loss: 0.1478 | Acc: 0.9609\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 1 | Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 1 | Epoch 15 | Train Loss: 0.0847 | Acc: 0.9732\n",
            "✅ Fold 1 | Epoch 15 | Val   Loss: 0.1636 | Acc: 0.9573\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 1 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 2 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 2 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 1 | Train Loss: 3.3691 | Acc: 0.4543\n",
            "✅ Fold 2 | Epoch 1 | Val   Loss: 0.7773 | Acc: 0.8544\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 2 | Train Loss: 0.5291 | Acc: 0.8930\n",
            "✅ Fold 2 | Epoch 2 | Val   Loss: 0.2946 | Acc: 0.9151\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 3 | Train Loss: 0.2692 | Acc: 0.9255\n",
            "✅ Fold 2 | Epoch 3 | Val   Loss: 0.2196 | Acc: 0.9282\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 4 | Train Loss: 0.2101 | Acc: 0.9381\n",
            "✅ Fold 2 | Epoch 4 | Val   Loss: 0.2063 | Acc: 0.9327\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 5 | Train Loss: 0.1752 | Acc: 0.9457\n",
            "✅ Fold 2 | Epoch 5 | Val   Loss: 0.1946 | Acc: 0.9431\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 6 | Train Loss: 0.1511 | Acc: 0.9521\n",
            "✅ Fold 2 | Epoch 6 | Val   Loss: 0.1937 | Acc: 0.9454\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 7 | Train Loss: 0.1379 | Acc: 0.9558\n",
            "✅ Fold 2 | Epoch 7 | Val   Loss: 0.2179 | Acc: 0.9410\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 8 | Train Loss: 0.1228 | Acc: 0.9599\n",
            "✅ Fold 2 | Epoch 8 | Val   Loss: 0.1682 | Acc: 0.9496\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 9 | Train Loss: 0.1203 | Acc: 0.9617\n",
            "✅ Fold 2 | Epoch 9 | Val   Loss: 0.1705 | Acc: 0.9517\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 10 | Train Loss: 0.1044 | Acc: 0.9655\n",
            "✅ Fold 2 | Epoch 10 | Val   Loss: 0.1599 | Acc: 0.9553\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 11 | Train Loss: 0.1058 | Acc: 0.9653\n",
            "✅ Fold 2 | Epoch 11 | Val   Loss: 0.1936 | Acc: 0.9504\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 12 | Train Loss: 0.1058 | Acc: 0.9664\n",
            "✅ Fold 2 | Epoch 12 | Val   Loss: 0.1649 | Acc: 0.9596\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 2 | Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 13 | Train Loss: 0.0953 | Acc: 0.9688\n",
            "✅ Fold 2 | Epoch 13 | Val   Loss: 0.1588 | Acc: 0.9553\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 14 | Train Loss: 0.0890 | Acc: 0.9716\n",
            "✅ Fold 2 | Epoch 14 | Val   Loss: 0.1664 | Acc: 0.9568\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 15 | Train Loss: 0.0828 | Acc: 0.9737\n",
            "✅ Fold 2 | Epoch 15 | Val   Loss: 0.1459 | Acc: 0.9599\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 16 | Train Loss: 0.0777 | Acc: 0.9751\n",
            "✅ Fold 2 | Epoch 16 | Val   Loss: 0.1611 | Acc: 0.9553\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 17 | Train Loss: 0.0827 | Acc: 0.9734\n",
            "✅ Fold 2 | Epoch 17 | Val   Loss: 0.1611 | Acc: 0.9612\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 2 | Epoch 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 18 | Train Loss: 0.0675 | Acc: 0.9785\n",
            "✅ Fold 2 | Epoch 18 | Val   Loss: 0.1447 | Acc: 0.9624\n",
            "📦 Best model saved for Fold 2!\n",
            "\n",
            "📌 Fold 2 | Epoch 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 19 | Train Loss: 0.0768 | Acc: 0.9746\n",
            "✅ Fold 2 | Epoch 19 | Val   Loss: 0.1633 | Acc: 0.9599\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 2 | Epoch 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 20 | Train Loss: 0.0691 | Acc: 0.9785\n",
            "✅ Fold 2 | Epoch 20 | Val   Loss: 0.1468 | Acc: 0.9656\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 2 | Epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 2 | Epoch 21 | Train Loss: 0.0679 | Acc: 0.9779\n",
            "✅ Fold 2 | Epoch 21 | Val   Loss: 0.1461 | Acc: 0.9645\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 2 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 3 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 3 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 1 | Train Loss: 3.2986 | Acc: 0.4768\n",
            "✅ Fold 3 | Epoch 1 | Val   Loss: 0.7558 | Acc: 0.8604\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 2 | Train Loss: 0.5096 | Acc: 0.8985\n",
            "✅ Fold 3 | Epoch 2 | Val   Loss: 0.3435 | Acc: 0.9039\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 3 | Train Loss: 0.2536 | Acc: 0.9312\n",
            "✅ Fold 3 | Epoch 3 | Val   Loss: 0.2391 | Acc: 0.9244\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 4 | Train Loss: 0.2003 | Acc: 0.9414\n",
            "✅ Fold 3 | Epoch 4 | Val   Loss: 0.2137 | Acc: 0.9369\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 5 | Train Loss: 0.1723 | Acc: 0.9476\n",
            "✅ Fold 3 | Epoch 5 | Val   Loss: 0.1877 | Acc: 0.9415\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 6 | Train Loss: 0.1457 | Acc: 0.9540\n",
            "✅ Fold 3 | Epoch 6 | Val   Loss: 0.1924 | Acc: 0.9427\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 3 | Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 7 | Train Loss: 0.1340 | Acc: 0.9579\n",
            "✅ Fold 3 | Epoch 7 | Val   Loss: 0.1996 | Acc: 0.9389\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 3 | Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 8 | Train Loss: 0.1268 | Acc: 0.9587\n",
            "✅ Fold 3 | Epoch 8 | Val   Loss: 0.1635 | Acc: 0.9526\n",
            "📦 Best model saved for Fold 3!\n",
            "\n",
            "📌 Fold 3 | Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 9 | Train Loss: 0.1064 | Acc: 0.9661\n",
            "✅ Fold 3 | Epoch 9 | Val   Loss: 0.1652 | Acc: 0.9501\n",
            "⚠️ EarlyStopping patience: 1/3\n",
            "\n",
            "📌 Fold 3 | Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 10 | Train Loss: 0.1038 | Acc: 0.9661\n",
            "✅ Fold 3 | Epoch 10 | Val   Loss: 0.2045 | Acc: 0.9531\n",
            "⚠️ EarlyStopping patience: 2/3\n",
            "\n",
            "📌 Fold 3 | Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 3 | Epoch 11 | Train Loss: 0.1110 | Acc: 0.9639\n",
            "✅ Fold 3 | Epoch 11 | Val   Loss: 0.1842 | Acc: 0.9513\n",
            "⚠️ EarlyStopping patience: 3/3\n",
            "⛔ Early stopping triggered.\n",
            "✅ Fold 3 Best model loaded.\n",
            "\n",
            "\n",
            "==============================\n",
            "🔁 Fold 4 / 5\n",
            "==============================\n",
            "\n",
            "\n",
            "📌 Fold 4 | Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 1 | Train Loss: 3.2348 | Acc: 0.4814\n",
            "✅ Fold 4 | Epoch 1 | Val   Loss: 0.7080 | Acc: 0.8524\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 2 | Train Loss: 0.5055 | Acc: 0.8971\n",
            "✅ Fold 4 | Epoch 2 | Val   Loss: 0.2851 | Acc: 0.9188\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fold 4 | Epoch 3 | Train Loss: 0.2639 | Acc: 0.9279\n",
            "✅ Fold 4 | Epoch 3 | Val   Loss: 0.2400 | Acc: 0.9301\n",
            "📦 Best model saved for Fold 4!\n",
            "\n",
            "📌 Fold 4 | Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Fold 4:  99%|█████████▊| 1635/1657 [06:18<00:05,  4.33it/s, loss=0.256]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 설정\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import timm\n",
        "\n",
        "# ✅ 하이퍼파라미터\n",
        "IMG_SIZE = 456\n",
        "NUM_CLASSES = 396\n",
        "TEST_DIR = \"/content/test\"\n",
        "SAMPLE_SUB_PATH = \"/content/sample_submission.csv\"\n",
        "exp_name = \"C\"\n",
        "\n",
        "# ✅ 디바이스 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Using device: {device}\")\n",
        "\n",
        "# ✅ 샘플 제출 파일\n",
        "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
        "column_names = sample.columns.tolist()[1:]  # 'ID' 제외\n",
        "\n",
        "# ✅ Transform 고정\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# ✅ Test Dataset (Color만 사용)\n",
        "class TestDataset_ColorOnly(Dataset):\n",
        "    def __init__(self, img_root, transform=None):\n",
        "        self.file_list = sorted([os.path.join(img_root, f) for f in os.listdir(img_root) if f.endswith('.jpg')])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path = self.file_list[idx]\n",
        "        image_pil = Image.open(path).convert(\"RGB\")\n",
        "\n",
        "        # Color Mean\n",
        "        image_cv2 = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "        color_mean = image_cv2.mean(axis=(0, 1))\n",
        "        color_mean = color_mean[::-1]\n",
        "        color_mean = np.array(color_mean / 255.0, dtype=np.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image_pil)\n",
        "        else:\n",
        "            image = transforms.ToTensor()(image_pil)\n",
        "\n",
        "        fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "        return image, torch.tensor(color_mean), fname\n",
        "\n",
        "# ✅ CustomModel (전략 C용)\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, use_aspect, use_color, use_pose, num_classes):\n",
        "        super(CustomModel, self).__init__()\n",
        "\n",
        "        self.use_aspect = use_aspect\n",
        "        self.use_color = use_color\n",
        "        self.use_pose = use_pose\n",
        "\n",
        "        self.backbone = timm.create_model('efficientnet_b5', pretrained=True, num_classes=0)\n",
        "        backbone_out_features = self.backbone.num_features\n",
        "\n",
        "        meta_features_dim = 0\n",
        "        if self.use_aspect:\n",
        "            meta_features_dim += 1\n",
        "        if self.use_color:\n",
        "            meta_features_dim += 3\n",
        "        if self.use_pose:\n",
        "            meta_features_dim += 4\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(backbone_out_features + meta_features_dim, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, image, aspect_ratio=None, color_mean=None, pose_feature=None):\n",
        "        x = self.backbone(image)\n",
        "\n",
        "        aux_list = []\n",
        "        if self.use_aspect:\n",
        "            aux_list.append(aspect_ratio)\n",
        "        if self.use_color:\n",
        "            aux_list.append(color_mean)\n",
        "        if self.use_pose:\n",
        "            aux_list.append(pose_feature)\n",
        "\n",
        "        if aux_list:\n",
        "            aux_features = torch.cat(aux_list, dim=1)\n",
        "            x = torch.cat([x, aux_features], dim=1)\n",
        "\n",
        "        out = self.classifier(x)\n",
        "        return out\n",
        "\n",
        "# ✅ 모델 경로\n",
        "FOLD_MODEL_PATHS = [\n",
        "    f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold1.pth\",\n",
        "    f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold2.pth\",\n",
        "    f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold3.pth\",\n",
        "    f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold4.pth\",\n",
        "    f\"/content/drive/MyDrive/team_models/EffNetB5_{exp_name}_fold5.pth\",\n",
        "]\n",
        "\n",
        "# ✅ DataLoader\n",
        "test_dataset = TestDataset_ColorOnly(TEST_DIR, test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# ✅ 앙상블 결과\n",
        "ensemble_outputs = []\n",
        "\n",
        "# ✅ 추론 루프\n",
        "for fold_idx, model_path in enumerate(FOLD_MODEL_PATHS):\n",
        "    print(f\"\\n🚀 Inference with Fold {fold_idx + 1} Model: {model_path}\")\n",
        "\n",
        "    model = CustomModel(use_aspect=False, use_color=True, use_pose=False, num_classes=NUM_CLASSES)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    fold_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, color_mean, fnames in tqdm(test_loader, desc=f\"🔍 Fold {fold_idx + 1} Inference\"):\n",
        "            imgs, color_mean = imgs.to(device), color_mean.to(device)\n",
        "\n",
        "            outputs = model(imgs, color_mean=color_mean)\n",
        "            probs = F.softmax(outputs, dim=1)\n",
        "            fold_probs.append(probs.cpu().numpy())\n",
        "\n",
        "    fold_probs = np.concatenate(fold_probs, axis=0)\n",
        "    ensemble_outputs.append(fold_probs)\n",
        "\n",
        "# ✅ 앙상블 평균\n",
        "ensemble_outputs = np.stack(ensemble_outputs, axis=0)\n",
        "mean_outputs = np.mean(ensemble_outputs, axis=0)\n",
        "\n",
        "# ✅ 결과 저장\n",
        "results = []\n",
        "for idx, path in enumerate(test_dataset.file_list):\n",
        "    fname = os.path.basename(path).replace(\".jpg\", \"\")\n",
        "    row = {\"ID\": fname}\n",
        "    row.update({class_name: mean_outputs[idx, i] for i, class_name in enumerate(column_names)})\n",
        "    results.append(row)\n",
        "\n",
        "submission_df = pd.DataFrame(results)\n",
        "submission_df = submission_df[[\"ID\"] + column_names]\n",
        "\n",
        "# ✅ 저장\n",
        "SAVE_SUB_PATH = f\"/content/drive/MyDrive/team_models/submission_fold5_ensemble_{exp_name}_IMG{IMG_SIZE}.csv\"\n",
        "submission_df.to_csv(SAVE_SUB_PATH, index=False)\n",
        "\n",
        "print(f\"\\n✅ 최종 제출용 CSV 저장 완료: {SAVE_SUB_PATH}\")\n"
      ],
      "metadata": {
        "id": "IH87wo41Gn3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_3hGyrOFSWR1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}