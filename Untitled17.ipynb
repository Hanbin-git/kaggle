{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1AxpdiDrZkEHwJQOjznN5LtpU6qrxT07Y",
      "authorship_tag": "ABX9TyOZCLWh3ks6XgWB82Qutam/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "494a4a8a515b442d9051e973433b14e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9a80e8ca42f440fb3370e08ea4e0952",
              "IPY_MODEL_7f2b3c13b78b48bbbb7aa43476e811d4",
              "IPY_MODEL_4c4793f8ccc94c7c9290f534d660180d"
            ],
            "layout": "IPY_MODEL_0b328e1c2cf540c58ce7f5c882d29bf9"
          }
        },
        "b9a80e8ca42f440fb3370e08ea4e0952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_636ee67e43a6464cbf2b3fe1e5860c52",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9856204a08b344149440b20b0992e7c1",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "7f2b3c13b78b48bbbb7aa43476e811d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de3ce1ae96e64d7aa539f9b639d69d79",
            "max": 122330162,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23595c33f611464b8742a4e2aec522e8",
            "value": 122330162
          }
        },
        "4c4793f8ccc94c7c9290f534d660180d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5240cf605684afca6170b2753dedd90",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_51dbadeccb984492b8ad8f0177ddc29c",
            "value": "â€‡122M/122Mâ€‡[00:00&lt;00:00,â€‡193MB/s]"
          }
        },
        "0b328e1c2cf540c58ce7f5c882d29bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "636ee67e43a6464cbf2b3fe1e5860c52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9856204a08b344149440b20b0992e7c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de3ce1ae96e64d7aa539f9b639d69d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23595c33f611464b8742a4e2aec522e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5240cf605684afca6170b2753dedd90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51dbadeccb984492b8ad8f0177ddc29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/Untitled17.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜  (ì¬ì‹œì‘ë˜ë©´ ë‹¤ì‹œ ì„¤ì¹˜í•´ì•¼ í•¨)\n",
        "!pip install -q wandb timm==0.9.12 torchvision --upgrade\n",
        "!pip install -q transformers==4.41.2\n"
      ],
      "metadata": {
        "id": "CsJ7vyz-c-r4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f8f0d5-4bd3-41b3-c34d-074b86a39958"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m127.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m127.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m114.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Drive ë§ˆìš´íŠ¸ + ë°ì´í„° unzip\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, zipfile, shutil\n",
        "SRC_ZIP=\"/content/drive/MyDrive/open.zip\"; DST_DIR=\"/content/open\"\n",
        "if os.path.exists(DST_DIR): shutil.rmtree(DST_DIR)\n",
        "shutil.copy(SRC_ZIP, \"/content/open.zip\")\n",
        "with zipfile.ZipFile(\"/content/open.zip\") as z: z.extractall(DST_DIR)\n"
      ],
      "metadata": {
        "id": "uK5TyM3GdOyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498cdae2-b7aa-44c1-ba54-e0d1fdd29719"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_text = \"\"\"\n",
        "SEED: 42\n",
        "IMG_SIZE: 456\n",
        "BATCH_SIZE: 48\n",
        "EPOCHS: 40\n",
        "LEARNING_RATE: 0.0003\n",
        "patience: 8\n",
        "model: \"tf_efficientnet_b5\"\n",
        "ema_decay: 0.9997\n",
        "stochastic_depth: 0.2\n",
        "train_root: \"/content/open/train\"\n",
        "test_root : \"/content/open/test\"\n",
        "\"\"\"\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "    f.write(yaml_text)\n",
        "print(\"âœ… config.yaml ì €ì¥ ì™„ë£Œ\")\n"
      ],
      "metadata": {
        "id": "_P9UuX_fd8BJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ccb636a-874d-478b-ce99-06059b0fec64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… config.yaml ì €ì¥ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"dataload.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import os, yaml, random, math\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, WeightedRandomSampler\n",
        "from torchvision.transforms import v2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ config ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "with open(\"config.yaml\") as cf:\n",
        "    CFG = yaml.safe_load(cf)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì‹œë“œ ê³ ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def seed_everything(seed:int):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Dataset ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, is_test=False):\n",
        "        self.root_dir, self.transform, self.is_test = root_dir, transform, is_test\n",
        "        self.samples = []\n",
        "        if is_test:\n",
        "            for f in sorted(os.listdir(root_dir)):\n",
        "                if f.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "                    self.samples.append((os.path.join(root_dir, f),))\n",
        "        else:\n",
        "            self.classes = sorted(os.listdir(root_dir))\n",
        "            self.class_to_idx = {c:i for i,c in enumerate(self.classes)}\n",
        "            for cls in self.classes:\n",
        "                cls_dir = os.path.join(root_dir, cls)\n",
        "                for f in os.listdir(cls_dir):\n",
        "                    if f.lower().endswith(('.jpg','.jpeg','.png')):\n",
        "                        self.samples.append((os.path.join(cls_dir, f), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self): return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.is_test:\n",
        "            path = self.samples[idx][0]\n",
        "            img  = Image.open(path).convert(\"RGB\")\n",
        "            return self.transform(img) if self.transform else img\n",
        "        path, label = self.samples[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Transform â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def get_transforms():\n",
        "    train_tf = v2.Compose([\n",
        "        v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n",
        "        v2.RandomResizedCrop((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"]), scale=(0.8,1.0)),\n",
        "        v2.RandomHorizontalFlip(),\n",
        "        v2.ColorJitter(0.3,0.3,0.3,0.1),\n",
        "        v2.RandAugment(num_ops=2, magnitude=7),\n",
        "        v2.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    val_tf = v2.Compose([\n",
        "        v2.ToImage(), v2.ToDtype(torch.float32, scale=True),\n",
        "        v2.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n",
        "        v2.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "    ])\n",
        "    return train_tf, val_tf\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Loader â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def get_loaders():\n",
        "    seed_everything(CFG[\"SEED\"])\n",
        "\n",
        "    full = CustomImageDataset(CFG[\"train_root\"])\n",
        "    labels = [y for _, y in full.samples]\n",
        "    tr_idx, val_idx = train_test_split(range(len(labels)),\n",
        "                                       test_size=0.2,\n",
        "                                       stratify=labels,\n",
        "                                       random_state=CFG[\"SEED\"])\n",
        "\n",
        "    tr_tf, val_tf = get_transforms()\n",
        "    train_ds = Subset(CustomImageDataset(CFG[\"train_root\"], tr_tf), tr_idx)\n",
        "    val_ds   = Subset(CustomImageDataset(CFG[\"train_root\"], val_tf), val_idx)\n",
        "\n",
        "    # ---- ë¶ˆê· í˜• ë³´ì • Sampler\n",
        "    cls_cnt   = np.bincount([labels[i] for i in tr_idx])\n",
        "    cls_wt    = 1. / (cls_cnt + 1e-6)\n",
        "    sample_wt = [cls_wt[labels[i]] for i in tr_idx]\n",
        "    sampler   = WeightedRandomSampler(sample_wt, num_samples=len(tr_idx), replacement=True)\n",
        "\n",
        "    # ---- DataLoader íŒŒë¼ë¯¸í„°\n",
        "    n_workers   = CFG.get(\"NUM_WORKERS\", 8)\n",
        "    prefetch    = CFG.get(\"PREFETCH\", 4)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_ds, batch_size=CFG[\"BATCH_SIZE\"], sampler=sampler,\n",
        "        num_workers=n_workers, pin_memory=True, persistent_workers=True,\n",
        "        prefetch_factor=prefetch\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds, batch_size=CFG[\"BATCH_SIZE\"], shuffle=False,\n",
        "        num_workers=max(1, n_workers//2), pin_memory=True,\n",
        "        persistent_workers=True, prefetch_factor=prefetch\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        CustomImageDataset(CFG[\"test_root\"], val_tf, is_test=True),\n",
        "        batch_size=CFG[\"BATCH_SIZE\"], shuffle=False,\n",
        "        num_workers=max(1, n_workers//2), pin_memory=True,\n",
        "        persistent_workers=True, prefetch_factor=prefetch\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader, full.classes\n",
        "''')\n"
      ],
      "metadata": {
        "id": "VGHUPFuKeYqh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "import os, yaml, wandb, torch, timm, gc\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from dataload import get_loaders, CFG\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0. í™˜ê²½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"ğŸš€ Using GPU : {torch.cuda.get_device_name(0)}\")\n",
        "    torch.backends.cudnn.benchmark = True   # ì†ë„ â†‘\n",
        "    torch.cuda.empty_cache()                # â†³ ìºì‹œ ì •ë¦¬\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. ëª¨ë¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.backbone = timm.create_model(\n",
        "            CFG[\"model\"],\n",
        "            pretrained=True,\n",
        "            num_classes=num_classes,\n",
        "            drop_path_rate=CFG.get(\"stochastic_depth\", 0.0)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. í•™ìŠµ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def main():\n",
        "    run = wandb.init(project=\"effb5-color\", config=CFG)\n",
        "    train_loader, val_loader, _, class_names = get_loaders()\n",
        "    model = BaseModel(len(class_names)).to(device)\n",
        "\n",
        "    # íŒŒë¼ë¯¸í„° ê·¸ë£¹ ì„¤ì •: ë¶„ë¥˜ í—¤ë“œ(10Ã—lr)\n",
        "    head, body = [], []\n",
        "    for n, p in model.named_parameters():\n",
        "        (head if \"classifier\" in n or \"head\" in n else body).append(p)\n",
        "    optimizer = optim.AdamW([\n",
        "        {\"params\": body, \"lr\": CFG[\"LEARNING_RATE\"]},\n",
        "        {\"params\": head, \"lr\": CFG[\"LEARNING_RATE\"] * 10}\n",
        "    ], weight_decay=0.05)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    scaler    = GradScaler()\n",
        "\n",
        "    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬\n",
        "    total_steps = len(train_loader) * CFG[\"EPOCHS\"]\n",
        "    scheduler   = get_cosine_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        int(total_steps * 0.1),         # warm-up 10 %\n",
        "        total_steps\n",
        "    )\n",
        "\n",
        "    # íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"ğŸ“Š Params: {total_params:,} (trainable {train_params:,})\")\n",
        "\n",
        "    best_loss, bad_epochs = float(\"inf\"), 0\n",
        "\n",
        "    for epoch in range(CFG[\"EPOCHS\"]):\n",
        "        # â”€â”€â”€ Train â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        model.train(); running = 0\n",
        "        for imgs, labels in tqdm(train_loader, desc=f\"[Train {epoch+1}]\"):\n",
        "            imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast():\n",
        "                loss = criterion(model(imgs), labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer); scaler.update()\n",
        "            scheduler.step()\n",
        "            running += loss.item()\n",
        "        train_loss = running / len(train_loader)\n",
        "\n",
        "        # â”€â”€â”€ Validation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        model.eval(); val_loss = 0; correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in tqdm(val_loader, desc=f\"[Val   {epoch+1}]\"):\n",
        "                imgs, labels = imgs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "                with autocast():\n",
        "                    outs  = model(imgs)\n",
        "                    loss  = criterion(outs, labels)\n",
        "                val_loss += loss.item()\n",
        "                correct  += (outs.argmax(1) == labels).sum().item()\n",
        "                total    += labels.size(0)\n",
        "        val_loss /= len(val_loader)\n",
        "        val_acc   = 100 * correct / total\n",
        "\n",
        "        # â”€â”€â”€ GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        if device.type == \"cuda\":\n",
        "            mem_alloc   = torch.cuda.memory_allocated() / 1024**2\n",
        "            peak_alloc  = torch.cuda.max_memory_allocated() / 1024**2\n",
        "            print(f\"ğŸ§  GPU Mem  : {mem_alloc:.1f} MB (peak {peak_alloc:.1f} MB)\")\n",
        "\n",
        "        # â”€â”€â”€ ë¡œê¹… & EarlyStopping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        wandb.log({\"epoch\": epoch+1,\n",
        "                   \"train_loss\": train_loss,\n",
        "                   \"val_loss\":   val_loss,\n",
        "                   \"val_acc\":    val_acc,\n",
        "                   \"gpu_mem_MB\": mem_alloc if device.type==\"cuda\" else 0})\n",
        "\n",
        "        if val_loss < best_loss:                     # improvement\n",
        "            best_loss, bad_epochs = val_loss, 0\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "            print(f\"ğŸ“¦  Best model saved (val_loss={val_loss:.4f})\")\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            print(f\"âš ï¸  No improvement {bad_epochs}/{CFG['patience']}\")\n",
        "            if bad_epochs >= CFG[\"patience\"]:\n",
        "                print(f\"ğŸ›‘ Early Stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    # í›ˆë ¨ ì¢…ë£Œ í›„ ìºì‹œ ì •ë¦¬\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "        print(\"â™»ï¸  GPU cache cleared\")\n",
        "\n",
        "    run.finish()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "0khwp472gFkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b67efe7-bc9f-4549-8b56-e9dc139e8438"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. í•™ìŠµ ì‹¤í–‰  â† ì£¼ì„ ì œê±°!\n",
        "%cd /content          # ì£¼ì„ ì—†ì´ ì •í™•íˆ\n",
        "import os; os.environ[\"WANDB_MODE\"]=\"offline\"   # WandB ë¡œê·¸ì¸ ìƒëµ\n",
        "from train import main\n",
        "main()\n"
      ],
      "metadata": {
        "id": "cw1Aq4OSecgo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "494a4a8a515b442d9051e973433b14e5",
            "b9a80e8ca42f440fb3370e08ea4e0952",
            "7f2b3c13b78b48bbbb7aa43476e811d4",
            "4c4793f8ccc94c7c9290f534d660180d",
            "0b328e1c2cf540c58ce7f5c882d29bf9",
            "636ee67e43a6464cbf2b3fe1e5860c52",
            "9856204a08b344149440b20b0992e7c1",
            "de3ce1ae96e64d7aa539f9b639d69d79",
            "23595c33f611464b8742a4e2aec522e8",
            "b5240cf605684afca6170b2753dedd90",
            "51dbadeccb984492b8ad8f0177ddc29c"
          ]
        },
        "outputId": "b60629bf-0f2d-407d-d480-5bdbf163338f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content # ì£¼ì„ ì—†ì´ ì •í™•íˆ'\n",
            "/content\n",
            "ğŸš€ Using GPU : NVIDIA A100-SXM4-40GB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "494a4a8a515b442d9051e973433b14e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/train.py:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler    = GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“Š Params: 29,152,188 (trainable 29,152,188)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[Train 1]:   0%|          | 0/553 [00:00<?, ?it/s]/content/train.py:69: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Train 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [04:01<00:00,  2.29it/s]\n",
            "[Val   1]:   0%|          | 0/139 [00:00<?, ?it/s]/content/train.py:82: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "[Val   1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:29<00:00,  4.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 481.7 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=1.0795)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.4162)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.3987)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.46it/s]\n",
            "[Val   4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.3942)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.2676)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:44<00:00,  2.46it/s]\n",
            "[Val   6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.2462)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.46it/s]\n",
            "[Val   8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.46it/s]\n",
            "[Val   9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 3/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.2404)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.46it/s]\n",
            "[Val   11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.2344)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.2158)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 14]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   14]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 15]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   15]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 16]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:44<00:00,  2.46it/s]\n",
            "[Val   16]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 3/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 17]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   17]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1780)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 18]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   18]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1759)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 19]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   19]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 20]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   20]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 21]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.44it/s]\n",
            "[Val   21]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1477)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 22]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.45it/s]\n",
            "[Val   22]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 23]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:47<00:00,  2.43it/s]\n",
            "[Val   23]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 24]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:47<00:00,  2.43it/s]\n",
            "[Val   24]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 3/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 25]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.44it/s]\n",
            "[Val   25]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 4/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 26]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.44it/s]\n",
            "[Val   26]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 5/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 27]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.44it/s]\n",
            "[Val   27]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1452)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 28]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   28]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 29]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   29]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1374)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 31]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.45it/s]\n",
            "[Val   31]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 32]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.45it/s]\n",
            "[Val   32]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 2/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 33]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   33]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 3/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 34]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   34]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  5.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 4/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 35]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   35]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:27<00:00,  4.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 5/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 36]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   36]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1374)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 37]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   37]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1361)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 38]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:46<00:00,  2.45it/s]\n",
            "[Val   38]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "âš ï¸  No improvement 1/8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 39]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 553/553 [03:45<00:00,  2.45it/s]\n",
            "[Val   39]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:28<00:00,  4.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  GPU Mem  : 483.0 MB (peak 30736.9 MB)\n",
            "ğŸ“¦  Best model saved (val_loss=0.1351)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Train 40]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 398/553 [02:43<01:02,  2.47it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) ì¶”ë¡  & ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "!python inference.py\n",
        "!head submission_tta.csv    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n"
      ],
      "metadata": {
        "id": "lotQRmv_gJZo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}