{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 87793,
          "databundleVersionId": 12276181,
          "isSourceIdPinned": false,
          "sourceType": "competition"
        },
        {
          "sourceId": 10855324,
          "sourceType": "datasetVersion",
          "datasetId": 6742586
        },
        {
          "sourceId": 11118830,
          "sourceType": "datasetVersion",
          "datasetId": 6933267
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Randomness",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hanbin-git/kaggle/blob/main/RNA4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "YSeSPSlzXO6T"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "stanford_rna_3d_folding_path = kagglehub.competition_download('stanford-rna-3d-folding')\n",
        "metric_usalign_path = kagglehub.dataset_download('metric/usalign')\n",
        "geraseva_protenix_checkpoints_path = kagglehub.dataset_download('geraseva/protenix-checkpoints')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "FNH_oI_cXO6U"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TYPE='protenix'\n",
        "VALIDATION=False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:03:06.302003Z",
          "iopub.execute_input": "2025-05-22T03:03:06.302434Z",
          "iopub.status.idle": "2025-05-22T03:03:06.306119Z",
          "shell.execute_reply.started": "2025-05-22T03:03:06.302408Z",
          "shell.execute_reply": "2025-05-22T03:03:06.305066Z"
        },
        "id": "G3NrLExuXO6V"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall -y torch torchvision torchaudio protenix"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:00:09.754928Z",
          "iopub.execute_input": "2025-05-22T03:00:09.755211Z",
          "iopub.status.idle": "2025-05-22T03:00:12.010812Z",
          "shell.execute_reply.started": "2025-05-22T03:00:09.755188Z",
          "shell.execute_reply": "2025-05-22T03:00:12.00997Z"
        },
        "id": "azfKfC16XO6V",
        "outputId": "c7e01a57-ed43-4d76-b865-a7bc122f3e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Found existing installation: torch 2.3.1+cu118\nUninstalling torch-2.3.1+cu118:\n  Successfully uninstalled torch-2.3.1+cu118\n\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mFound existing installation: protenix 0.4.6\nUninstalling protenix-0.4.6:\n  Successfully uninstalled protenix-0.4.6\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:00:16.514977Z",
          "iopub.execute_input": "2025-05-22T03:00:16.515266Z",
          "iopub.status.idle": "2025-05-22T03:00:16.858914Z",
          "shell.execute_reply.started": "2025-05-22T03:00:16.515243Z",
          "shell.execute_reply": "2025-05-22T03:00:16.858071Z"
        },
        "id": "3DzGiR7_XO6W",
        "outputId": "e1c7f22d-7320-4ed9-c665-10284d1f2444"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2023 NVIDIA Corporation\nBuilt on Tue_Aug_15_22:02:13_PDT_2023\nCuda compilation tools, release 12.2, V12.2.140\nBuild cuda_12.2.r12.2/compiler.33191640_0\nThu May 22 03:00:16 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   41C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   44C    P8             10W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --extra-index-url https://download.pytorch.org/whl/cu118 torch==2.3.1+cu118"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:00:20.726437Z",
          "iopub.execute_input": "2025-05-22T03:00:20.726747Z",
          "iopub.status.idle": "2025-05-22T03:00:52.395048Z",
          "shell.execute_reply.started": "2025-05-22T03:00:20.726721Z",
          "shell.execute_reply": "2025-05-22T03:00:52.393678Z"
        },
        "id": "9_BA93TdXO6W",
        "outputId": "8225ddbb-2d9b-4ed5-bc89-29528329a607"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118\nCollecting torch==2.3.1+cu118\n  Using cached https://download.pytorch.org/whl/cu118/torch-2.3.1%2Bcu118-cp310-cp310-linux_x86_64.whl (839.7 MB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.8.89)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.8.89)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.8.87)\nRequirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (8.7.0.84)\nRequirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.11.3.6)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (10.3.0.86)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.4.1.48)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.7.5.86)\nRequirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (11.8.86)\nRequirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1+cu118) (2.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1+cu118) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1+cu118) (1.3.0)\nInstalling collected packages: torch\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nfastai 2.7.18 requires torchvision>=0.11, which is not installed.\ntimm 1.0.12 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.3.1+cu118\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --no-deps protenix==0.4.6 einops tqdm gemmi biotite==1.0.1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:01:25.66547Z",
          "iopub.execute_input": "2025-05-22T03:01:25.665809Z",
          "iopub.status.idle": "2025-05-22T03:01:27.064291Z",
          "shell.execute_reply.started": "2025-05-22T03:01:25.66578Z",
          "shell.execute_reply": "2025-05-22T03:01:27.06348Z"
        },
        "id": "UAf1T0HrXO6X",
        "outputId": "466d9b1b-31f3-4d3e-ef29-c42704e21e57"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting protenix==0.4.6\n  Using cached protenix-0.4.6-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: gemmi in /usr/local/lib/python3.10/dist-packages (0.7.1)\nRequirement already satisfied: biotite==1.0.1 in /usr/local/lib/python3.10/dist-packages (1.0.1)\nUsing cached protenix-0.4.6-py3-none-any.whl (441 kB)\nInstalling collected packages: protenix\nSuccessfully installed protenix-0.4.6\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install biopython ml-collections rdkit"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:01:32.4637Z",
          "iopub.execute_input": "2025-05-22T03:01:32.464006Z",
          "iopub.status.idle": "2025-05-22T03:01:35.82879Z",
          "shell.execute_reply.started": "2025-05-22T03:01:32.463983Z",
          "shell.execute_reply": "2025-05-22T03:01:35.827675Z"
        },
        "id": "9oZJcQwcXO6X",
        "outputId": "a54f9c3d-c624-4924-bdce-b79553374f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.85)\nRequirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (1.1.0)\nRequirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2025.3.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections) (1.4.0)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections) (6.0.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (11.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython) (2024.2.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ],
      "metadata": {
        "id": "arI0BcUuXO6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if MODEL_TYPE=='protenix' and VALIDATION:\n",
        "    !pip install biopython\n",
        "    !pip install ml-collections\n",
        "    !pip install rdkit\n",
        "!export PROTENIX_DATA_ROOT_DIR=/kaggle/input/protenix-checkpoints"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:01:59.632924Z",
          "iopub.execute_input": "2025-05-22T03:01:59.633237Z",
          "iopub.status.idle": "2025-05-22T03:02:10.028536Z",
          "shell.execute_reply.started": "2025-05-22T03:01:59.63321Z",
          "shell.execute_reply": "2025-05-22T03:02:10.027489Z"
        },
        "id": "OdYTaZlwXO6Z",
        "outputId": "1a19b238-b228-401b-e37e-67cfed1ea0fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.85)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython) (2024.2.0)\nRequirement already satisfied: ml-collections in /usr/local/lib/python3.10/dist-packages (1.1.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections) (1.4.0)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections) (6.0.2)\nRequirement already satisfied: rdkit in /usr/local/lib/python3.10/dist-packages (2025.3.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (11.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rdkit) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rdkit) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rdkit) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rdkit) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rdkit) (2024.2.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir /af3-dev\n",
        "! ln -s /kaggle/input/protenix-checkpoints /af3-dev/release_data\n",
        "! ls /af3-dev/release_data/"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-22T03:02:39.633296Z",
          "iopub.execute_input": "2025-05-22T03:02:39.633596Z",
          "iopub.status.idle": "2025-05-22T03:02:39.974925Z",
          "shell.execute_reply.started": "2025-05-22T03:02:39.633571Z",
          "shell.execute_reply": "2025-05-22T03:02:39.974107Z"
        },
        "id": "ToTgI-QrXO6Z",
        "outputId": "68dcedef-69b4-4eb4-8bc1-6f93f3fdc808"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "mkdir: cannot create directory ‘/af3-dev’: File exists\nln: failed to create symbolic link '/af3-dev/release_data/protenix-checkpoints': Read-only file system\ncomponents.v20240608.cif\t\tmodel_v0.2.0.pt\ncomponents.v20240608.cif.rdkit_mol.pkl\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper scripts"
      ],
      "metadata": {
        "id": "0c_jUN6jXO6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import Bio\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "import pandas as pd\n",
        "from Bio.PDB import Atom, Model, Chain, Residue, Structure, PDBParser\n",
        "from Bio import SeqIO\n",
        "import os, sys\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "time0=time.time()\n",
        "\n",
        "print('IMPORT OK !!!!')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2025-05-22T03:02:41.751735Z",
          "iopub.execute_input": "2025-05-22T03:02:41.752215Z",
          "iopub.status.idle": "2025-05-22T03:02:43.80947Z",
          "shell.execute_reply.started": "2025-05-22T03:02:41.752173Z",
          "shell.execute_reply": "2025-05-22T03:02:43.808266Z"
        },
        "trusted": true,
        "id": "vX8UqhEFXO6a",
        "outputId": "785cb4be-3c6f-42c5-e680-741cf6cf58ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "IMPORT OK !!!!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "PYTHON = sys.executable\n",
        "print('PYTHON',PYTHON)\n",
        "\n",
        "RHONET_DIR=\\\n",
        "'/kaggle/input/data-for-demo-for-rhofold-plus-with-kaggle-msa/RhoFold-main'\n",
        "#'<your downloaded rhofold repo>/RhoFold-main'\n",
        "\n",
        "USALIGN = \\\n",
        "'/kaggle/working//USalign'\n",
        "#'<your us align path>/USalign'\n",
        "\n",
        "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
        "os.system('sudo chmod u+x /kaggle/working//USalign')\n",
        "sys.path.append(RHONET_DIR)\n",
        "\n",
        "\n",
        "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
        "\n",
        "\n",
        "# helper ----\n",
        "class dotdict(dict):\n",
        "\t__setattr__ = dict.__setitem__\n",
        "\t__delattr__ = dict.__delitem__\n",
        "\n",
        "\tdef __getattr__(self, name):\n",
        "\t\ttry:\n",
        "\t\t\treturn self[name]\n",
        "\t\texcept KeyError:\n",
        "\t\t\traise AttributeError(name)\n",
        "\n",
        "# visualisation helper ----\n",
        "def set_aspect_equal(ax):\n",
        "\tx_limits = ax.get_xlim()\n",
        "\ty_limits = ax.get_ylim()\n",
        "\tz_limits = ax.get_zlim()\n",
        "\n",
        "\t# Compute the mean of each axis\n",
        "\tx_middle = np.mean(x_limits)\n",
        "\ty_middle = np.mean(y_limits)\n",
        "\tz_middle = np.mean(z_limits)\n",
        "\n",
        "\t# Compute the max range across all axes\n",
        "\tmax_range = max(x_limits[1] - x_limits[0],\n",
        "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
        "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
        "\n",
        "\t# Set the new limits to ensure equal scaling\n",
        "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
        "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
        "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T07:33:53.178245Z",
          "iopub.execute_input": "2025-05-20T07:33:53.178532Z",
          "iopub.status.idle": "2025-05-20T07:33:53.203314Z",
          "shell.execute_reply.started": "2025-05-20T07:33:53.178509Z",
          "shell.execute_reply": "2025-05-20T07:33:53.202387Z"
        },
        "id": "y_0IUxXwXO6a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# xyz df helper --------------------\n",
        "def get_truth_df(target_id):\n",
        "    truth_df = LABEL_DF[LABEL_DF['target_id'] == target_id]\n",
        "    truth_df = truth_df.reset_index(drop=True)\n",
        "    return truth_df\n",
        "\n",
        "def parse_output_to_df(output, seq, target_id):\n",
        "    df = []\n",
        "    chain_data = []\n",
        "    for i, res in enumerate(seq):\n",
        "        d=dict(ID = target_id,\n",
        "                    resname=res,\n",
        "                    resid=i+1)\n",
        "        for n in range(len(output)):\n",
        "            d={**d, f'x_{n+1}': round(output[n,i,0].item(),3),\n",
        "                     f'y_{n+1}': round(output[n,i,1].item(),3),\n",
        "                     f'z_{n+1}': round(output[n,i,2].item(),3)}\n",
        "        chain_data.append(d)\n",
        "\n",
        "    if len(chain_data)!=0:\n",
        "        chain_df = pd.DataFrame(chain_data)\n",
        "        df.append(chain_df)\n",
        "        ##print(chain_df)\n",
        "    return df\n",
        "\n",
        "\n",
        "def parse_pdb_to_df(pdb_file, target_id):\n",
        "    parser = PDBParser()\n",
        "    structure = parser.get_structure('', pdb_file)\n",
        "\n",
        "    df = []\n",
        "    for model in structure:\n",
        "        for chain in model:\n",
        "            print(chain)\n",
        "            chain_data = []\n",
        "            for residue in chain:\n",
        "                # print(residue)\n",
        "                if residue.get_resname() in ['A', 'U', 'G', 'C']:\n",
        "                    # Check if the residue has a C1' atom\n",
        "                    if 'C1\\'' in residue:\n",
        "                        atom = residue['C1\\'']\n",
        "                        xyz = atom.get_coord()\n",
        "                        resname = residue.get_resname()\n",
        "                        resid = residue.get_id()[1]\n",
        "\n",
        "                        #todo detect discontinous: resid = prev_resid+1\n",
        "                        #ID\tresname\tresid\tx_1\ty_1\tz_1\n",
        "                        chain_data.append(dict(\n",
        "                            ID = target_id+'_'+str(resid),\n",
        "                            resname=resname,\n",
        "                            resid=resid,\n",
        "                            x_1=xyz[0],\n",
        "                            y_1=xyz[1],\n",
        "                            z_1=xyz[2],\n",
        "                        ))\n",
        "                        ##print(f\"Residue {resname} {resid}, Atom: {atom.get_name()}, xyz: {xyz}\")\n",
        "\n",
        "            if len(chain_data)!=0:\n",
        "                chain_df = pd.DataFrame(chain_data)\n",
        "                df.append(chain_df)\n",
        "                ##print(chain_df)\n",
        "    return df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T07:33:55.874239Z",
          "iopub.execute_input": "2025-05-20T07:33:55.874515Z",
          "iopub.status.idle": "2025-05-20T07:33:55.882929Z",
          "shell.execute_reply.started": "2025-05-20T07:33:55.874492Z",
          "shell.execute_reply": "2025-05-20T07:33:55.88198Z"
        },
        "id": "r0AZw6Z6XO6a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# usalign helper --------------------\n",
        "def write_target_line(\n",
        "    atom_name, atom_serial, residue_name, chain_id, residue_num, x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
        "):\n",
        "    \"\"\"\n",
        "    Writes a single line of PDB format based on provided atom information.\n",
        "\n",
        "    Args:\n",
        "        atom_name (str): Name of the atom (e.g., \"N\", \"CA\").\n",
        "        atom_serial (int): Atom serial number.\n",
        "        residue_name (str): Residue name (e.g., \"ALA\").\n",
        "        chain_id (str): Chain identifier.\n",
        "        residue_num (int): Residue number.\n",
        "        x_coord (float): X coordinate.\n",
        "        y_coord (float): Y coordinate.\n",
        "        z_coord (float): Z coordinate.\n",
        "        occupancy (float, optional): Occupancy value (default: 1.0).\n",
        "        b_factor (float, optional): B-factor value (default: 0.0).\n",
        "\n",
        "    Returns:\n",
        "        str: A single line of PDB string.\n",
        "    \"\"\"\n",
        "    return f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} {residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
        "\n",
        "def write_xyz_to_pdb(df, pdb_file, xyz_id = 1):\n",
        "    resolved_cnt = 0\n",
        "    with open(pdb_file, 'w') as target_file:\n",
        "        for _, row in df.iterrows():\n",
        "            x_coord = row[f'x_{xyz_id}']\n",
        "            y_coord = row[f'y_{xyz_id}']\n",
        "            z_coord = row[f'z_{xyz_id}']\n",
        "\n",
        "            if x_coord > -1e17 and y_coord > -1e17 and z_coord > -1e17:\n",
        "                resolved_cnt += 1\n",
        "                target_line = write_target_line(\n",
        "                    atom_name=\"C1'\",\n",
        "                    atom_serial=int(row['resid']),\n",
        "                    residue_name=row['resname'],\n",
        "                    chain_id='0',\n",
        "                    residue_num=int(row['resid']),\n",
        "                    x_coord=x_coord,\n",
        "                    y_coord=y_coord,\n",
        "                    z_coord=z_coord,\n",
        "                    atom_type='C',\n",
        "                )\n",
        "                target_file.write(target_line)\n",
        "    return resolved_cnt\n",
        "\n",
        "\n",
        "def parse_usalign_for_tm_score(output):\n",
        "    # Extract TM-score based on length of reference structure (second)\n",
        "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
        "    if not tm_score_match:\n",
        "        raise ValueError('No TM score found')\n",
        "    return float(tm_score_match)\n",
        "\n",
        "def parse_usalign_for_transform(output):\n",
        "    # Locate the rotation matrix section\n",
        "    matrix_lines = []\n",
        "    found_matrix = False\n",
        "\n",
        "    for line in output.splitlines():\n",
        "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
        "            found_matrix = True\n",
        "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
        "            matrix_lines.append(line)\n",
        "        elif found_matrix and not line.strip():\n",
        "            break  # Stop parsing if an empty line is encountered after the matrix\n",
        "\n",
        "    # Parse the rotation matrix values\n",
        "    rotation_matrix = []\n",
        "    for line in matrix_lines:\n",
        "        parts = line.split()\n",
        "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
        "        rotation_matrix.append(row_values)\n",
        "\n",
        "    return np.array(rotation_matrix)\n",
        "\n",
        "def call_usalign(predict_df, truth_df, verbose=1):\n",
        "    truth_pdb = '~truth.pdb'\n",
        "    predict_pdb = '~predict.pdb'\n",
        "    write_xyz_to_pdb(predict_df, predict_pdb, xyz_id=1)\n",
        "    write_xyz_to_pdb(truth_df, truth_pdb, xyz_id=1)\n",
        "\n",
        "    command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
        "    output = os.popen(command).read()\n",
        "    if verbose==1:\n",
        "        print(output)\n",
        "    tm_score = parse_usalign_for_tm_score(output)\n",
        "    transform = parse_usalign_for_transform(output)\n",
        "    return tm_score, transform\n",
        "\n",
        "print('HELPER OK!!!')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T07:33:58.690681Z",
          "iopub.execute_input": "2025-05-20T07:33:58.691184Z",
          "iopub.status.idle": "2025-05-20T07:33:58.704252Z",
          "shell.execute_reply.started": "2025-05-20T07:33:58.691136Z",
          "shell.execute_reply": "2025-05-20T07:33:58.703171Z"
        },
        "id": "ikmgFvEoXO6a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if MODEL_TYPE=='protenix':\n",
        "\n",
        "\n",
        "    from runner.batch_inference import get_default_runner\n",
        "    from runner.inference import update_inference_configs, InferenceRunner\n",
        "\n",
        "    from protenix.data.infer_data_pipeline import InferenceDataset\n",
        "\n",
        "    np.random.seed(0)\n",
        "    torch.random.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "    class DictDataset(InferenceDataset):\n",
        "        def __init__(\n",
        "            self,\n",
        "            seq_list: list,\n",
        "            dump_dir: str,\n",
        "            id_list: list = None,\n",
        "            use_msa: bool = False,\n",
        "        ) -> None:\n",
        "\n",
        "            self.dump_dir = dump_dir\n",
        "            self.use_msa = use_msa\n",
        "            if isinstance(id_list,type(None)):\n",
        "                self.inputs = [{\"sequences\":\n",
        "                                [{\"rnaSequence\":\n",
        "                                  {\"sequence\": seq,\n",
        "                                   \"count\": 1}}],\n",
        "                                \"name\": \"query\"} for seq in seq_list]\n",
        "            else:\n",
        "                self.inputs = [{\"sequences\":\n",
        "                                [{\"rnaSequence\":\n",
        "                                  {\"sequence\": seq,\n",
        "                                   \"count\": 1}}],\n",
        "                                \"name\": i} for i, seq in zip(id_list,seq_list)]\n",
        "\n",
        "\n",
        "if MODEL_TYPE=='protenix':\n",
        "\n",
        "    from configs.configs_base import configs as configs_base\n",
        "    from configs.configs_data import data_configs\n",
        "    from configs.configs_inference import inference_configs\n",
        "    from protenix.config.config import parse_configs\n",
        "\n",
        "    configs_base[\"use_deepspeed_evo_attention\"] = (\n",
        "    os.environ.get(\"USE_DEEPSPEED_EVO_ATTENTION\", False) == \"true\")\n",
        "    configs_base[\"model\"][\"N_cycle\"] = 10 #10\n",
        "    configs_base[\"sample_diffusion\"][\"N_sample\"] = (1 if VALIDATION else 10)\n",
        "    configs_base[\"sample_diffusion\"][\"N_step\"] = 200\n",
        "    inference_configs['load_checkpoint_path']='/kaggle/input/protenix-checkpoints/model_v0.2.0.pt'\n",
        "    configs = {**configs_base, **{\"data\": data_configs}, **inference_configs}\n",
        "\n",
        "    configs = parse_configs(\n",
        "            configs=configs,\n",
        "            fill_required_with_null=True,\n",
        "        )\n",
        "\n",
        "    runner=InferenceRunner(configs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T07:34:03.193185Z",
          "iopub.execute_input": "2025-05-20T07:34:03.193507Z",
          "iopub.status.idle": "2025-05-20T07:34:03.201541Z",
          "shell.execute_reply.started": "2025-05-20T07:34:03.193477Z",
          "shell.execute_reply": "2025-05-20T07:34:03.200865Z"
        },
        "id": "MY-8cTnGXO6b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if VALIDATION:\n",
        "    LABEL_DF = pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_labels.csv')\n",
        "    LABEL_DF['target_id'] = LABEL_DF['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
        "    train_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/train_sequences.csv')\n",
        "\n",
        "\n",
        "\n",
        "if MODEL_TYPE=='protenix' and VALIDATION:\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    train_df['protenix_tm_score']=None\n",
        "    dataset = DictDataset(train_df.sequence, dump_dir='output', id_list=train_df.target_id, use_msa=False)\n",
        "    num_data = len(dataset)\n",
        "    for i, seq in tqdm(enumerate(train_df.sequence),total=num_data):\n",
        "        if train_df.loc[i,'protenix_tm_score']!=None:\n",
        "            continue\n",
        "        if len(seq)>300:\n",
        "            continue\n",
        "        target_id = train_df.loc[i,'target_id']\n",
        "        truth_df = get_truth_df(target_id)\n",
        "        if sum(~np.isnan(truth_df.x_1))<3:\n",
        "            continue\n",
        "        data, atom_array, data_error_message=dataset[i]\n",
        "        if data_error_message!='':\n",
        "            continue\n",
        "        new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
        "        runner.update_model_configs(new_configs)\n",
        "        prediction = runner.predict(data)\n",
        "        prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
        "        result = parse_output_to_df(prediction[:1], seq, target_id)[0]\n",
        "        try:\n",
        "            tm_score, transform = call_usalign(result, truth_df, verbose=0)\n",
        "            train_df.loc[i,'protenix_tm_score']=tm_score\n",
        "        except:\n",
        "            pass\n",
        "        if (time.time()-time0)>(12*3600-360):\n",
        "            break\n",
        "    train_df.to_csv('tm_scores.csv', index=False)\n",
        "    print(train_df.protenix_tm_score.mean())\n",
        "    display(train_df.protenix_tm_score.hist())\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "VFlx8m92XO6b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if MODEL_TYPE=='protenix' and not VALIDATION:\n",
        "    test_df=pd.read_csv('/kaggle/input/stanford-rna-3d-folding/test_sequences.csv')\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    dataset = DictDataset(test_df.sequence, dump_dir='output', id_list=test_df.target_id, use_msa=False)\n",
        "    num_data = len(dataset)\n",
        "    for i, seq in tqdm(enumerate(test_df.sequence),total=num_data):\n",
        "        try:\n",
        "            data, atom_array, data_error_message=dataset[i]\n",
        "            target_id = data[\"sample_name\"]\n",
        "            assert target_id==test_df.target_id[i]\n",
        "            assert data_error_message==''\n",
        "\n",
        "            new_configs = update_inference_configs(configs, data[\"N_token\"].item())\n",
        "            runner.update_model_configs(new_configs)\n",
        "            prediction = runner.predict(data)\n",
        "            prediction=prediction['coordinate'][:,data['input_feature_dict']['atom_to_tokatom_idx']==12]\n",
        "\n",
        "            result = parse_output_to_df(prediction, seq, target_id)[0]\n",
        "        except:\n",
        "            target_id==test_df.target_id[i]\n",
        "            print('Failed to predict', target_id)\n",
        "            result=pd.DataFrame(columns=['ID', 'resname', 'resid',\n",
        "                                         'x_1', 'y_1', 'z_1',\n",
        "                                         'x_2', 'y_2', 'z_2',\n",
        "                                         'x_3', 'y_3', 'z_3',\n",
        "                                         'x_4', 'y_4', 'z_4',\n",
        "                                         'x_5', 'y_5', 'z_5'],\n",
        "                                         data=[[target_id, x, j+1] + [0.0]*15 for j, x in enumerate(seq)])\n",
        "\n",
        "        result['ID']=result.apply(lambda x: x.ID + '_' + str(x.resid), axis=1)\n",
        "        result.to_csv('submission.csv', index=False, mode='a', header=(i==0))\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    display(pd.read_csv('submission.csv'))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ryz0xGaKXO6b"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}